{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DenseNet fine tuning 50\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this run for the MobileNet, we froze all layers and added two dense layers after the conv_base.\n",
        "\n",
        "Results>\n",
        "\n",
        "Best Epoch: 99\n",
        "\n",
        "test acc: 0.89666\n",
        "\n",
        "test loss: 3.5623\n",
        "\n",
        "f1_score: 0.8980\n",
        "\n",
        "Precision: 0.8841\n",
        "\n",
        "Recall: 0.916\n",
        "\n",
        "ROC AUC: 0.8980\n",
        "\n",
        "---Training 100 Epochs:  seconds --- 20622 s\n",
        "---Inferense (6000 images):  seconds --- 20.07 s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9F-3tLoS-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install \"tensorflow<2.11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Q0sXDdr-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ze2HI0C1-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eHaZm8sS-6Jk"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip list\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VTJsjK8k-6Jl"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pc4Ak-MX-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9qmltHoh-6Jl"
      },
      "outputs": [],
      "source": [
        "# add headings with ##(space) on the markdowns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oefqb7pK-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflor keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9_5zqcvh-6Jl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp9-KNO_XLJk",
        "outputId": "6744d109-58a8-4e55-860f-55eb54942aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Aug  3 12:35:24 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1660 ...  WDDM  | 00000000:2D:00.0  On |                  N/A |\n",
            "|  0%   46C    P8              16W / 125W |    844MiB /  6144MiB |     12%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A       828    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A      3024    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      3868    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A      3988    C+G   ...soft Office\\root\\Office16\\EXCEL.EXE    N/A      |\n",
            "|    0   N/A  N/A      4952    C+G   ...n\\126.0.2592.113\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A      5892    C+G   ...n\\126.0.2592.113\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A      7376    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A      7448    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
            "|    0   N/A  N/A      8432    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      9852    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     10960    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     16172    C+G   ...e Stream\\94.0.1.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A     16808    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     18956    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     19332    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     19544    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A     21520    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     21908    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     22972    C+G   ...soft Office\\root\\Office16\\EXCEL.EXE    N/A      |\n",
            "|    0   N/A  N/A     23008    C+G   ...am Files\\CyberGhost 8\\Dashboard.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkjlmr5C-6Jl",
        "outputId": "ee4947bd-e593-4a95-d056-cd5c5a96edb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig6dym2M-6Jm",
        "outputId": "9fc23f8a-8818-4670-8a29-5ad344823bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3w44-mIA-6Jm"
      },
      "outputs": [],
      "source": [
        "#! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TuXlkzYf-6Jm"
      },
      "outputs": [],
      "source": [
        "#!pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3sJDXlu-6Jm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-2RGi19W-6Jm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NqDqKYkQ-6Jm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingConfig:\n",
        "    BATCH_SIZE:       int   = 64\n",
        "    EPOCHS:           int   = 100\n",
        "    LEARNING_RATE:    float = 0.001\n",
        "    DROPOUT:          float = 0.5\n",
        "    LAYERS_FINE_TUNE: int   = 50\n",
        "    EPSILON:          float = 1e-07\n",
        "    MOMENTUM:         float = 0.9   \n",
        "    WEIGHT_DECAY:     float = 0.0005 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ0UVyCQ-6Jq"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = r\"C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\READY_BALANCED_SAME_SIZE_Random_Split\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knV1jDUD-6Jq",
        "outputId": "50f1446d-6355-4acd-f509-c5440328e53e"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hf-N_1PI-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\train\\\\Ads'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Ads_dir = os.path.join(train_dir, 'Ads')\n",
        "train_sample_dir = os.path.join(train_dir, 'Sample')\n",
        "train_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4lk-PK-6Jq",
        "outputId": "d9fbbdec-e425-4bd2-af75-32f3fbb86936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\validation\\\\Ads'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_Ads_dir = os.path.join(validation_dir, 'Ads')\n",
        "validation_sample_dir = os.path.join(validation_dir, 'Sample')\n",
        "validation_Ads_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JwHehlf4-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\test\\\\Ads'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Ads_dir = os.path.join(test_dir, 'Ads')\n",
        "test_sample_dir = os.path.join(test_dir, 'Sample')\n",
        "test_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fbi_AoAO-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training Ads images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training Ads images:', len(os.listdir(train_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h4bgQrIL-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training sample images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training sample images:', len(os.listdir(train_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YHrO9Y-6Jq",
        "outputId": "15bf628d-bf34-4ce7-ad11-fe568bf61432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation Ads images: 3650\n"
          ]
        }
      ],
      "source": [
        "print('total validation Ads images:', len(os.listdir(validation_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation sample images: 3950\n"
          ]
        }
      ],
      "source": [
        "print('total validation sample images:', len(os.listdir(validation_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test Ads images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test Ads images:', len(os.listdir(test_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test sample images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test sample images:', len(os.listdir(test_sample_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using data augmentation/ datagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "from tensorflow.keras.utils import img_to_array, array_to_img,  load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for color augmentation\n",
        "def color_jitter(image):\n",
        "    image = ImageEnhance.Brightness(image).enhance(np.random.uniform(0.4, 1.6)) # from -60% to +60%\n",
        "    image = ImageEnhance.Contrast(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    image = ImageEnhance.Color(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for ImageDataGenerator\n",
        "def custom_preprocessing_function(image):\n",
        "    # Convert array to PIL image\n",
        "    image = array_to_img(image)\n",
        "    # Apply color jitter\n",
        "    image = color_jitter(image)\n",
        "    # Convert PIL image back to array\n",
        "    image = img_to_array(image)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 images belonging to 2 classes.\n",
            "Found 7600 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "## with Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=custom_preprocessing_function)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretrained Model Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l38QgkUe-6Js"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4AL2-e8-6Js"
      },
      "source": [
        "# Appling a Pre-trained CNN on our Dataset for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcDjEV1-6Jt"
      },
      "source": [
        "The MobileNet model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OcyKdKno-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras.applications import DenseNet121\n",
        "\n",
        "conv_base = DenseNet121(weights='imagenet',\n",
        "                 include_top=False,\n",
        "                 input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRiAZIlI-6Jt",
        "outputId": "9254a8c6-9f28-4ea9-9b11-6553544bb4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVx8qd9U-6Jt"
      },
      "source": [
        "We will add a dense layer after our conv_base NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NwbCTdFB-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, AveragePooling2D\n",
        "\n",
        "modelPreTMob = models.Sequential()\n",
        "modelPreTMob.add(conv_base)\n",
        "\n",
        "modelPreTMob.add(layers.AveragePooling2D())\n",
        "modelPreTMob.add(layers.Flatten())\n",
        "modelPreTMob.add(layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "modelPreTMob.add(BatchNormalization())\n",
        "modelPreTMob.add(layers.Dropout(TrainingConfig.DROPOUT))\n",
        "modelPreTMob.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULwwwLKQ-6Jt",
        "outputId": "bca81ce0-c589-438d-d7f7-ddc78c5df1fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 9,314,177\n",
            "Non-trainable params: 84,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 True\n",
            "1 zero_padding2d True\n",
            "2 conv1/conv True\n",
            "3 conv1/bn True\n",
            "4 conv1/relu True\n",
            "5 zero_padding2d_1 True\n",
            "6 pool1 True\n",
            "7 conv2_block1_0_bn True\n",
            "8 conv2_block1_0_relu True\n",
            "9 conv2_block1_1_conv True\n",
            "10 conv2_block1_1_bn True\n",
            "11 conv2_block1_1_relu True\n",
            "12 conv2_block1_2_conv True\n",
            "13 conv2_block1_concat True\n",
            "14 conv2_block2_0_bn True\n",
            "15 conv2_block2_0_relu True\n",
            "16 conv2_block2_1_conv True\n",
            "17 conv2_block2_1_bn True\n",
            "18 conv2_block2_1_relu True\n",
            "19 conv2_block2_2_conv True\n",
            "20 conv2_block2_concat True\n",
            "21 conv2_block3_0_bn True\n",
            "22 conv2_block3_0_relu True\n",
            "23 conv2_block3_1_conv True\n",
            "24 conv2_block3_1_bn True\n",
            "25 conv2_block3_1_relu True\n",
            "26 conv2_block3_2_conv True\n",
            "27 conv2_block3_concat True\n",
            "28 conv2_block4_0_bn True\n",
            "29 conv2_block4_0_relu True\n",
            "30 conv2_block4_1_conv True\n",
            "31 conv2_block4_1_bn True\n",
            "32 conv2_block4_1_relu True\n",
            "33 conv2_block4_2_conv True\n",
            "34 conv2_block4_concat True\n",
            "35 conv2_block5_0_bn True\n",
            "36 conv2_block5_0_relu True\n",
            "37 conv2_block5_1_conv True\n",
            "38 conv2_block5_1_bn True\n",
            "39 conv2_block5_1_relu True\n",
            "40 conv2_block5_2_conv True\n",
            "41 conv2_block5_concat True\n",
            "42 conv2_block6_0_bn True\n",
            "43 conv2_block6_0_relu True\n",
            "44 conv2_block6_1_conv True\n",
            "45 conv2_block6_1_bn True\n",
            "46 conv2_block6_1_relu True\n",
            "47 conv2_block6_2_conv True\n",
            "48 conv2_block6_concat True\n",
            "49 pool2_bn True\n",
            "50 pool2_relu True\n",
            "51 pool2_conv True\n",
            "52 pool2_pool True\n",
            "53 conv3_block1_0_bn True\n",
            "54 conv3_block1_0_relu True\n",
            "55 conv3_block1_1_conv True\n",
            "56 conv3_block1_1_bn True\n",
            "57 conv3_block1_1_relu True\n",
            "58 conv3_block1_2_conv True\n",
            "59 conv3_block1_concat True\n",
            "60 conv3_block2_0_bn True\n",
            "61 conv3_block2_0_relu True\n",
            "62 conv3_block2_1_conv True\n",
            "63 conv3_block2_1_bn True\n",
            "64 conv3_block2_1_relu True\n",
            "65 conv3_block2_2_conv True\n",
            "66 conv3_block2_concat True\n",
            "67 conv3_block3_0_bn True\n",
            "68 conv3_block3_0_relu True\n",
            "69 conv3_block3_1_conv True\n",
            "70 conv3_block3_1_bn True\n",
            "71 conv3_block3_1_relu True\n",
            "72 conv3_block3_2_conv True\n",
            "73 conv3_block3_concat True\n",
            "74 conv3_block4_0_bn True\n",
            "75 conv3_block4_0_relu True\n",
            "76 conv3_block4_1_conv True\n",
            "77 conv3_block4_1_bn True\n",
            "78 conv3_block4_1_relu True\n",
            "79 conv3_block4_2_conv True\n",
            "80 conv3_block4_concat True\n",
            "81 conv3_block5_0_bn True\n",
            "82 conv3_block5_0_relu True\n",
            "83 conv3_block5_1_conv True\n",
            "84 conv3_block5_1_bn True\n",
            "85 conv3_block5_1_relu True\n",
            "86 conv3_block5_2_conv True\n",
            "87 conv3_block5_concat True\n",
            "88 conv3_block6_0_bn True\n",
            "89 conv3_block6_0_relu True\n",
            "90 conv3_block6_1_conv True\n",
            "91 conv3_block6_1_bn True\n",
            "92 conv3_block6_1_relu True\n",
            "93 conv3_block6_2_conv True\n",
            "94 conv3_block6_concat True\n",
            "95 conv3_block7_0_bn True\n",
            "96 conv3_block7_0_relu True\n",
            "97 conv3_block7_1_conv True\n",
            "98 conv3_block7_1_bn True\n",
            "99 conv3_block7_1_relu True\n",
            "100 conv3_block7_2_conv True\n",
            "101 conv3_block7_concat True\n",
            "102 conv3_block8_0_bn True\n",
            "103 conv3_block8_0_relu True\n",
            "104 conv3_block8_1_conv True\n",
            "105 conv3_block8_1_bn True\n",
            "106 conv3_block8_1_relu True\n",
            "107 conv3_block8_2_conv True\n",
            "108 conv3_block8_concat True\n",
            "109 conv3_block9_0_bn True\n",
            "110 conv3_block9_0_relu True\n",
            "111 conv3_block9_1_conv True\n",
            "112 conv3_block9_1_bn True\n",
            "113 conv3_block9_1_relu True\n",
            "114 conv3_block9_2_conv True\n",
            "115 conv3_block9_concat True\n",
            "116 conv3_block10_0_bn True\n",
            "117 conv3_block10_0_relu True\n",
            "118 conv3_block10_1_conv True\n",
            "119 conv3_block10_1_bn True\n",
            "120 conv3_block10_1_relu True\n",
            "121 conv3_block10_2_conv True\n",
            "122 conv3_block10_concat True\n",
            "123 conv3_block11_0_bn True\n",
            "124 conv3_block11_0_relu True\n",
            "125 conv3_block11_1_conv True\n",
            "126 conv3_block11_1_bn True\n",
            "127 conv3_block11_1_relu True\n",
            "128 conv3_block11_2_conv True\n",
            "129 conv3_block11_concat True\n",
            "130 conv3_block12_0_bn True\n",
            "131 conv3_block12_0_relu True\n",
            "132 conv3_block12_1_conv True\n",
            "133 conv3_block12_1_bn True\n",
            "134 conv3_block12_1_relu True\n",
            "135 conv3_block12_2_conv True\n",
            "136 conv3_block12_concat True\n",
            "137 pool3_bn True\n",
            "138 pool3_relu True\n",
            "139 pool3_conv True\n",
            "140 pool3_pool True\n",
            "141 conv4_block1_0_bn True\n",
            "142 conv4_block1_0_relu True\n",
            "143 conv4_block1_1_conv True\n",
            "144 conv4_block1_1_bn True\n",
            "145 conv4_block1_1_relu True\n",
            "146 conv4_block1_2_conv True\n",
            "147 conv4_block1_concat True\n",
            "148 conv4_block2_0_bn True\n",
            "149 conv4_block2_0_relu True\n",
            "150 conv4_block2_1_conv True\n",
            "151 conv4_block2_1_bn True\n",
            "152 conv4_block2_1_relu True\n",
            "153 conv4_block2_2_conv True\n",
            "154 conv4_block2_concat True\n",
            "155 conv4_block3_0_bn True\n",
            "156 conv4_block3_0_relu True\n",
            "157 conv4_block3_1_conv True\n",
            "158 conv4_block3_1_bn True\n",
            "159 conv4_block3_1_relu True\n",
            "160 conv4_block3_2_conv True\n",
            "161 conv4_block3_concat True\n",
            "162 conv4_block4_0_bn True\n",
            "163 conv4_block4_0_relu True\n",
            "164 conv4_block4_1_conv True\n",
            "165 conv4_block4_1_bn True\n",
            "166 conv4_block4_1_relu True\n",
            "167 conv4_block4_2_conv True\n",
            "168 conv4_block4_concat True\n",
            "169 conv4_block5_0_bn True\n",
            "170 conv4_block5_0_relu True\n",
            "171 conv4_block5_1_conv True\n",
            "172 conv4_block5_1_bn True\n",
            "173 conv4_block5_1_relu True\n",
            "174 conv4_block5_2_conv True\n",
            "175 conv4_block5_concat True\n",
            "176 conv4_block6_0_bn True\n",
            "177 conv4_block6_0_relu True\n",
            "178 conv4_block6_1_conv True\n",
            "179 conv4_block6_1_bn True\n",
            "180 conv4_block6_1_relu True\n",
            "181 conv4_block6_2_conv True\n",
            "182 conv4_block6_concat True\n",
            "183 conv4_block7_0_bn True\n",
            "184 conv4_block7_0_relu True\n",
            "185 conv4_block7_1_conv True\n",
            "186 conv4_block7_1_bn True\n",
            "187 conv4_block7_1_relu True\n",
            "188 conv4_block7_2_conv True\n",
            "189 conv4_block7_concat True\n",
            "190 conv4_block8_0_bn True\n",
            "191 conv4_block8_0_relu True\n",
            "192 conv4_block8_1_conv True\n",
            "193 conv4_block8_1_bn True\n",
            "194 conv4_block8_1_relu True\n",
            "195 conv4_block8_2_conv True\n",
            "196 conv4_block8_concat True\n",
            "197 conv4_block9_0_bn True\n",
            "198 conv4_block9_0_relu True\n",
            "199 conv4_block9_1_conv True\n",
            "200 conv4_block9_1_bn True\n",
            "201 conv4_block9_1_relu True\n",
            "202 conv4_block9_2_conv True\n",
            "203 conv4_block9_concat True\n",
            "204 conv4_block10_0_bn True\n",
            "205 conv4_block10_0_relu True\n",
            "206 conv4_block10_1_conv True\n",
            "207 conv4_block10_1_bn True\n",
            "208 conv4_block10_1_relu True\n",
            "209 conv4_block10_2_conv True\n",
            "210 conv4_block10_concat True\n",
            "211 conv4_block11_0_bn True\n",
            "212 conv4_block11_0_relu True\n",
            "213 conv4_block11_1_conv True\n",
            "214 conv4_block11_1_bn True\n",
            "215 conv4_block11_1_relu True\n",
            "216 conv4_block11_2_conv True\n",
            "217 conv4_block11_concat True\n",
            "218 conv4_block12_0_bn True\n",
            "219 conv4_block12_0_relu True\n",
            "220 conv4_block12_1_conv True\n",
            "221 conv4_block12_1_bn True\n",
            "222 conv4_block12_1_relu True\n",
            "223 conv4_block12_2_conv True\n",
            "224 conv4_block12_concat True\n",
            "225 conv4_block13_0_bn True\n",
            "226 conv4_block13_0_relu True\n",
            "227 conv4_block13_1_conv True\n",
            "228 conv4_block13_1_bn True\n",
            "229 conv4_block13_1_relu True\n",
            "230 conv4_block13_2_conv True\n",
            "231 conv4_block13_concat True\n",
            "232 conv4_block14_0_bn True\n",
            "233 conv4_block14_0_relu True\n",
            "234 conv4_block14_1_conv True\n",
            "235 conv4_block14_1_bn True\n",
            "236 conv4_block14_1_relu True\n",
            "237 conv4_block14_2_conv True\n",
            "238 conv4_block14_concat True\n",
            "239 conv4_block15_0_bn True\n",
            "240 conv4_block15_0_relu True\n",
            "241 conv4_block15_1_conv True\n",
            "242 conv4_block15_1_bn True\n",
            "243 conv4_block15_1_relu True\n",
            "244 conv4_block15_2_conv True\n",
            "245 conv4_block15_concat True\n",
            "246 conv4_block16_0_bn True\n",
            "247 conv4_block16_0_relu True\n",
            "248 conv4_block16_1_conv True\n",
            "249 conv4_block16_1_bn True\n",
            "250 conv4_block16_1_relu True\n",
            "251 conv4_block16_2_conv True\n",
            "252 conv4_block16_concat True\n",
            "253 conv4_block17_0_bn True\n",
            "254 conv4_block17_0_relu True\n",
            "255 conv4_block17_1_conv True\n",
            "256 conv4_block17_1_bn True\n",
            "257 conv4_block17_1_relu True\n",
            "258 conv4_block17_2_conv True\n",
            "259 conv4_block17_concat True\n",
            "260 conv4_block18_0_bn True\n",
            "261 conv4_block18_0_relu True\n",
            "262 conv4_block18_1_conv True\n",
            "263 conv4_block18_1_bn True\n",
            "264 conv4_block18_1_relu True\n",
            "265 conv4_block18_2_conv True\n",
            "266 conv4_block18_concat True\n",
            "267 conv4_block19_0_bn True\n",
            "268 conv4_block19_0_relu True\n",
            "269 conv4_block19_1_conv True\n",
            "270 conv4_block19_1_bn True\n",
            "271 conv4_block19_1_relu True\n",
            "272 conv4_block19_2_conv True\n",
            "273 conv4_block19_concat True\n",
            "274 conv4_block20_0_bn True\n",
            "275 conv4_block20_0_relu True\n",
            "276 conv4_block20_1_conv True\n",
            "277 conv4_block20_1_bn True\n",
            "278 conv4_block20_1_relu True\n",
            "279 conv4_block20_2_conv True\n",
            "280 conv4_block20_concat True\n",
            "281 conv4_block21_0_bn True\n",
            "282 conv4_block21_0_relu True\n",
            "283 conv4_block21_1_conv True\n",
            "284 conv4_block21_1_bn True\n",
            "285 conv4_block21_1_relu True\n",
            "286 conv4_block21_2_conv True\n",
            "287 conv4_block21_concat True\n",
            "288 conv4_block22_0_bn True\n",
            "289 conv4_block22_0_relu True\n",
            "290 conv4_block22_1_conv True\n",
            "291 conv4_block22_1_bn True\n",
            "292 conv4_block22_1_relu True\n",
            "293 conv4_block22_2_conv True\n",
            "294 conv4_block22_concat True\n",
            "295 conv4_block23_0_bn True\n",
            "296 conv4_block23_0_relu True\n",
            "297 conv4_block23_1_conv True\n",
            "298 conv4_block23_1_bn True\n",
            "299 conv4_block23_1_relu True\n",
            "300 conv4_block23_2_conv True\n",
            "301 conv4_block23_concat True\n",
            "302 conv4_block24_0_bn True\n",
            "303 conv4_block24_0_relu True\n",
            "304 conv4_block24_1_conv True\n",
            "305 conv4_block24_1_bn True\n",
            "306 conv4_block24_1_relu True\n",
            "307 conv4_block24_2_conv True\n",
            "308 conv4_block24_concat True\n",
            "309 pool4_bn True\n",
            "310 pool4_relu True\n",
            "311 pool4_conv True\n",
            "312 pool4_pool True\n",
            "313 conv5_block1_0_bn True\n",
            "314 conv5_block1_0_relu True\n",
            "315 conv5_block1_1_conv True\n",
            "316 conv5_block1_1_bn True\n",
            "317 conv5_block1_1_relu True\n",
            "318 conv5_block1_2_conv True\n",
            "319 conv5_block1_concat True\n",
            "320 conv5_block2_0_bn True\n",
            "321 conv5_block2_0_relu True\n",
            "322 conv5_block2_1_conv True\n",
            "323 conv5_block2_1_bn True\n",
            "324 conv5_block2_1_relu True\n",
            "325 conv5_block2_2_conv True\n",
            "326 conv5_block2_concat True\n",
            "327 conv5_block3_0_bn True\n",
            "328 conv5_block3_0_relu True\n",
            "329 conv5_block3_1_conv True\n",
            "330 conv5_block3_1_bn True\n",
            "331 conv5_block3_1_relu True\n",
            "332 conv5_block3_2_conv True\n",
            "333 conv5_block3_concat True\n",
            "334 conv5_block4_0_bn True\n",
            "335 conv5_block4_0_relu True\n",
            "336 conv5_block4_1_conv True\n",
            "337 conv5_block4_1_bn True\n",
            "338 conv5_block4_1_relu True\n",
            "339 conv5_block4_2_conv True\n",
            "340 conv5_block4_concat True\n",
            "341 conv5_block5_0_bn True\n",
            "342 conv5_block5_0_relu True\n",
            "343 conv5_block5_1_conv True\n",
            "344 conv5_block5_1_bn True\n",
            "345 conv5_block5_1_relu True\n",
            "346 conv5_block5_2_conv True\n",
            "347 conv5_block5_concat True\n",
            "348 conv5_block6_0_bn True\n",
            "349 conv5_block6_0_relu True\n",
            "350 conv5_block6_1_conv True\n",
            "351 conv5_block6_1_bn True\n",
            "352 conv5_block6_1_relu True\n",
            "353 conv5_block6_2_conv True\n",
            "354 conv5_block6_concat True\n",
            "355 conv5_block7_0_bn True\n",
            "356 conv5_block7_0_relu True\n",
            "357 conv5_block7_1_conv True\n",
            "358 conv5_block7_1_bn True\n",
            "359 conv5_block7_1_relu True\n",
            "360 conv5_block7_2_conv True\n",
            "361 conv5_block7_concat True\n",
            "362 conv5_block8_0_bn True\n",
            "363 conv5_block8_0_relu True\n",
            "364 conv5_block8_1_conv True\n",
            "365 conv5_block8_1_bn True\n",
            "366 conv5_block8_1_relu True\n",
            "367 conv5_block8_2_conv True\n",
            "368 conv5_block8_concat True\n",
            "369 conv5_block9_0_bn True\n",
            "370 conv5_block9_0_relu True\n",
            "371 conv5_block9_1_conv True\n",
            "372 conv5_block9_1_bn True\n",
            "373 conv5_block9_1_relu True\n",
            "374 conv5_block9_2_conv True\n",
            "375 conv5_block9_concat True\n",
            "376 conv5_block10_0_bn True\n",
            "377 conv5_block10_0_relu True\n",
            "378 conv5_block10_1_conv True\n",
            "379 conv5_block10_1_bn True\n",
            "380 conv5_block10_1_relu True\n",
            "381 conv5_block10_2_conv True\n",
            "382 conv5_block10_concat True\n",
            "383 conv5_block11_0_bn True\n",
            "384 conv5_block11_0_relu True\n",
            "385 conv5_block11_1_conv True\n",
            "386 conv5_block11_1_bn True\n",
            "387 conv5_block11_1_relu True\n",
            "388 conv5_block11_2_conv True\n",
            "389 conv5_block11_concat True\n",
            "390 conv5_block12_0_bn True\n",
            "391 conv5_block12_0_relu True\n",
            "392 conv5_block12_1_conv True\n",
            "393 conv5_block12_1_bn True\n",
            "394 conv5_block12_1_relu True\n",
            "395 conv5_block12_2_conv True\n",
            "396 conv5_block12_concat True\n",
            "397 conv5_block13_0_bn True\n",
            "398 conv5_block13_0_relu True\n",
            "399 conv5_block13_1_conv True\n",
            "400 conv5_block13_1_bn True\n",
            "401 conv5_block13_1_relu True\n",
            "402 conv5_block13_2_conv True\n",
            "403 conv5_block13_concat True\n",
            "404 conv5_block14_0_bn True\n",
            "405 conv5_block14_0_relu True\n",
            "406 conv5_block14_1_conv True\n",
            "407 conv5_block14_1_bn True\n",
            "408 conv5_block14_1_relu True\n",
            "409 conv5_block14_2_conv True\n",
            "410 conv5_block14_concat True\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the number of layers to fine tune at the end of the convolutional base.\n",
        "num_layers_fine_tune = TrainingConfig.LAYERS_FINE_TUNE\n",
        "num_layers = len(conv_base.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg5O_dq-6Jt",
        "outputId": "0b8e8703-9f13-4415-d6a7-fc5af46bc1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 368\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'before freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FREEZING LAYER: <keras.engine.input_layer.InputLayer object at 0x000001BC5512F310>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000001BC7658F310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC551D02B0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC551D82B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC551D0C10>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000001BC551DE130>\n",
            "FREEZING LAYER: <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001BC551E36D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC551E3AF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC551E3160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC551EDD30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1B0580>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC551ED880>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1B3E50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC5B1C0790>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1C0D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1B69D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1CA550>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1CEA60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC551EDA60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1C0EB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC5B1B6C70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1D2D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1CDEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1D9730>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1E6490>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1D9040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1D2100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70000820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70000220>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70000C70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70008910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7000FCD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70008190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700003A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC5B1ED7C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70019550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70017E20>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70022A00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70025EB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70022100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70019670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7002FD90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700315E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70031430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70038BE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7003EE80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70038430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70031820>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC5B1E6400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1D2970>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1D26A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1C0460>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001BC70043CA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC551ED820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC551E3F40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1ABB80>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70046E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70022280>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC5B1CE4F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70051E50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70051AF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70051430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70055E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70059850>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70055520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7005EEE0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70051520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70066640>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7004DFA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7006CD90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70071070>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70071D30>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700763D0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70079A90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70079DC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70076370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70081370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7008CE50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700813A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70082CD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7009A7F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7009ADC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70082520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700A15B0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700A6910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700A10A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7009A220>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700B4670>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700B4F40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700B4AC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7009A7C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700793D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7008C820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700B4430>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700B1640>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1ED040>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1D9250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700BE2E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700BEE80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1D21C0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700BF4C0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700C1BE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700C1520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1AB190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700CB4C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700D1FA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700CB520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700C5FA0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700C59D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700DCCA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC5B1AB430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700DE6A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700E93D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700CB310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700DCFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700F4790>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC700F4EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700F2F10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700FE8E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70103CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700FE1C0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700F4400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700F20A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7010E5B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7010CFD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70115970>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7011E3D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7011E130>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7010E730>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7011CB50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7011C3D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70127370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC700F4AF0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC5B1AB3D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC700FE760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7010EBB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC700BFD30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70131CA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70076AC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70134880>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001BC70129A60>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70129B20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701290A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70137A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7013AD00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701372E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC701341F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70134760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70144850>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701448E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7014DCD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70151520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7014D310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70144400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7015C700>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7015C610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7015C520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70164DF0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70169550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC4CCCF820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7015C760>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC4CCE7670>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701780D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC4D294F70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7017F310>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70170AF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70178F40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70178AF0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70192190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701922E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70170F70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC70197370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7019EEE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7019EEB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC701976A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70170A00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70164160>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70157520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7017F820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7010E790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701649D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7010EAC0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70144430>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70192A00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701972B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC701A91C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC70178A90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC70192DC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC701ACAC0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC701AC9D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701B7E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701ACD60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC701AEF40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76856C10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701AEDF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76856E50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC70137B20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7685DEB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701BEE80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76864040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701A9D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701B7A00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7686DF70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7685D400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76878A00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76864FD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76881160>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76856670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76878FA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76881700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7686DEE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76893220>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76881340>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768816A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7689FF40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76893A60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76898220>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76864CD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76856A30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7689F0D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76881550>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76888DF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768643D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7015CFA0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768981F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768A8D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7013AE50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768A8490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76898A60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701BE370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768A8850>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768ADAC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701AC190>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768ADE50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768C00A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768C7CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768C7CA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768C7F10>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768B7C10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768810D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768C0F70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768D70D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768B0880>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768CEF10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768D7700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768C7AC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768C00D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768CE1F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768ED3A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768F7EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768E7040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768D7100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768D7F70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768DEF10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768E7370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768D7FA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7690F160>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76900BE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76900FD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768D7EB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768C7D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7690F310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768F7D30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76900910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768D7460>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7685DC40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC768B7DC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76919D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76906940>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7691E040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768AD5E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768C7430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76920EB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76919490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76928F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7691EEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7692F070>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768A8FA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76928EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76934FD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76928520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76920550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7692F250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76947190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76920520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76938430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76934670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76934F40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7692FF40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76938310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76934220>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76967130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76957B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769506A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76971400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76971610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76967100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769477F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7697F9D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7697F190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76974C70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76947F10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76938F70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7697F430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769670A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768C03D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769475E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC768C7970>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76928C10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC768DE820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76920BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7698D040>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000001BC7698FD00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701151F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769749A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7698D6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC76919AC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76919DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76997A00>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC76919820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC769A5A60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC768DEB50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769A5B50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC769B08E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7691EE50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769B0BE0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC769B07F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC769BF250>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769B0B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769BFB20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC769C62E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769B2D90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769BFC40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC769C6910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC77408100>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769C6CA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC769B26D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC77410B50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769C6D00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC77410460>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC77418910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC77418130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC77410DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC774101F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC769A5910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC769A5760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76997100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC769CC940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC701A9AC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC77408C40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7699B280>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC774089D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC701BE2E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC77426A30>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC77408A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC774309D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC77418BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC76934C70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC774267C0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC76947220>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7742DB50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC774309A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC77444790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC77435AF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC77444610>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7699B5B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC77435850>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7744CCD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC7744C880>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC7745D370>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC7744CC70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC7742DC10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC77444E20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000001BC77444400>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000001BC77466CA0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000001BC77466A00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001BC774750D0>\n"
          ]
        }
      ],
      "source": [
        "# Freeze the initial layers in the convolutional base.\n",
        "for model_layer in conv_base.layers[:num_layers - num_layers_fine_tune]:\n",
        "    print(f\"FREEZING LAYER: {model_layer}\")\n",
        "    model_layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 zero_padding2d False\n",
            "2 conv1/conv False\n",
            "3 conv1/bn False\n",
            "4 conv1/relu False\n",
            "5 zero_padding2d_1 False\n",
            "6 pool1 False\n",
            "7 conv2_block1_0_bn False\n",
            "8 conv2_block1_0_relu False\n",
            "9 conv2_block1_1_conv False\n",
            "10 conv2_block1_1_bn False\n",
            "11 conv2_block1_1_relu False\n",
            "12 conv2_block1_2_conv False\n",
            "13 conv2_block1_concat False\n",
            "14 conv2_block2_0_bn False\n",
            "15 conv2_block2_0_relu False\n",
            "16 conv2_block2_1_conv False\n",
            "17 conv2_block2_1_bn False\n",
            "18 conv2_block2_1_relu False\n",
            "19 conv2_block2_2_conv False\n",
            "20 conv2_block2_concat False\n",
            "21 conv2_block3_0_bn False\n",
            "22 conv2_block3_0_relu False\n",
            "23 conv2_block3_1_conv False\n",
            "24 conv2_block3_1_bn False\n",
            "25 conv2_block3_1_relu False\n",
            "26 conv2_block3_2_conv False\n",
            "27 conv2_block3_concat False\n",
            "28 conv2_block4_0_bn False\n",
            "29 conv2_block4_0_relu False\n",
            "30 conv2_block4_1_conv False\n",
            "31 conv2_block4_1_bn False\n",
            "32 conv2_block4_1_relu False\n",
            "33 conv2_block4_2_conv False\n",
            "34 conv2_block4_concat False\n",
            "35 conv2_block5_0_bn False\n",
            "36 conv2_block5_0_relu False\n",
            "37 conv2_block5_1_conv False\n",
            "38 conv2_block5_1_bn False\n",
            "39 conv2_block5_1_relu False\n",
            "40 conv2_block5_2_conv False\n",
            "41 conv2_block5_concat False\n",
            "42 conv2_block6_0_bn False\n",
            "43 conv2_block6_0_relu False\n",
            "44 conv2_block6_1_conv False\n",
            "45 conv2_block6_1_bn False\n",
            "46 conv2_block6_1_relu False\n",
            "47 conv2_block6_2_conv False\n",
            "48 conv2_block6_concat False\n",
            "49 pool2_bn False\n",
            "50 pool2_relu False\n",
            "51 pool2_conv False\n",
            "52 pool2_pool False\n",
            "53 conv3_block1_0_bn False\n",
            "54 conv3_block1_0_relu False\n",
            "55 conv3_block1_1_conv False\n",
            "56 conv3_block1_1_bn False\n",
            "57 conv3_block1_1_relu False\n",
            "58 conv3_block1_2_conv False\n",
            "59 conv3_block1_concat False\n",
            "60 conv3_block2_0_bn False\n",
            "61 conv3_block2_0_relu False\n",
            "62 conv3_block2_1_conv False\n",
            "63 conv3_block2_1_bn False\n",
            "64 conv3_block2_1_relu False\n",
            "65 conv3_block2_2_conv False\n",
            "66 conv3_block2_concat False\n",
            "67 conv3_block3_0_bn False\n",
            "68 conv3_block3_0_relu False\n",
            "69 conv3_block3_1_conv False\n",
            "70 conv3_block3_1_bn False\n",
            "71 conv3_block3_1_relu False\n",
            "72 conv3_block3_2_conv False\n",
            "73 conv3_block3_concat False\n",
            "74 conv3_block4_0_bn False\n",
            "75 conv3_block4_0_relu False\n",
            "76 conv3_block4_1_conv False\n",
            "77 conv3_block4_1_bn False\n",
            "78 conv3_block4_1_relu False\n",
            "79 conv3_block4_2_conv False\n",
            "80 conv3_block4_concat False\n",
            "81 conv3_block5_0_bn False\n",
            "82 conv3_block5_0_relu False\n",
            "83 conv3_block5_1_conv False\n",
            "84 conv3_block5_1_bn False\n",
            "85 conv3_block5_1_relu False\n",
            "86 conv3_block5_2_conv False\n",
            "87 conv3_block5_concat False\n",
            "88 conv3_block6_0_bn False\n",
            "89 conv3_block6_0_relu False\n",
            "90 conv3_block6_1_conv False\n",
            "91 conv3_block6_1_bn False\n",
            "92 conv3_block6_1_relu False\n",
            "93 conv3_block6_2_conv False\n",
            "94 conv3_block6_concat False\n",
            "95 conv3_block7_0_bn False\n",
            "96 conv3_block7_0_relu False\n",
            "97 conv3_block7_1_conv False\n",
            "98 conv3_block7_1_bn False\n",
            "99 conv3_block7_1_relu False\n",
            "100 conv3_block7_2_conv False\n",
            "101 conv3_block7_concat False\n",
            "102 conv3_block8_0_bn False\n",
            "103 conv3_block8_0_relu False\n",
            "104 conv3_block8_1_conv False\n",
            "105 conv3_block8_1_bn False\n",
            "106 conv3_block8_1_relu False\n",
            "107 conv3_block8_2_conv False\n",
            "108 conv3_block8_concat False\n",
            "109 conv3_block9_0_bn False\n",
            "110 conv3_block9_0_relu False\n",
            "111 conv3_block9_1_conv False\n",
            "112 conv3_block9_1_bn False\n",
            "113 conv3_block9_1_relu False\n",
            "114 conv3_block9_2_conv False\n",
            "115 conv3_block9_concat False\n",
            "116 conv3_block10_0_bn False\n",
            "117 conv3_block10_0_relu False\n",
            "118 conv3_block10_1_conv False\n",
            "119 conv3_block10_1_bn False\n",
            "120 conv3_block10_1_relu False\n",
            "121 conv3_block10_2_conv False\n",
            "122 conv3_block10_concat False\n",
            "123 conv3_block11_0_bn False\n",
            "124 conv3_block11_0_relu False\n",
            "125 conv3_block11_1_conv False\n",
            "126 conv3_block11_1_bn False\n",
            "127 conv3_block11_1_relu False\n",
            "128 conv3_block11_2_conv False\n",
            "129 conv3_block11_concat False\n",
            "130 conv3_block12_0_bn False\n",
            "131 conv3_block12_0_relu False\n",
            "132 conv3_block12_1_conv False\n",
            "133 conv3_block12_1_bn False\n",
            "134 conv3_block12_1_relu False\n",
            "135 conv3_block12_2_conv False\n",
            "136 conv3_block12_concat False\n",
            "137 pool3_bn False\n",
            "138 pool3_relu False\n",
            "139 pool3_conv False\n",
            "140 pool3_pool False\n",
            "141 conv4_block1_0_bn False\n",
            "142 conv4_block1_0_relu False\n",
            "143 conv4_block1_1_conv False\n",
            "144 conv4_block1_1_bn False\n",
            "145 conv4_block1_1_relu False\n",
            "146 conv4_block1_2_conv False\n",
            "147 conv4_block1_concat False\n",
            "148 conv4_block2_0_bn False\n",
            "149 conv4_block2_0_relu False\n",
            "150 conv4_block2_1_conv False\n",
            "151 conv4_block2_1_bn False\n",
            "152 conv4_block2_1_relu False\n",
            "153 conv4_block2_2_conv False\n",
            "154 conv4_block2_concat False\n",
            "155 conv4_block3_0_bn False\n",
            "156 conv4_block3_0_relu False\n",
            "157 conv4_block3_1_conv False\n",
            "158 conv4_block3_1_bn False\n",
            "159 conv4_block3_1_relu False\n",
            "160 conv4_block3_2_conv False\n",
            "161 conv4_block3_concat False\n",
            "162 conv4_block4_0_bn False\n",
            "163 conv4_block4_0_relu False\n",
            "164 conv4_block4_1_conv False\n",
            "165 conv4_block4_1_bn False\n",
            "166 conv4_block4_1_relu False\n",
            "167 conv4_block4_2_conv False\n",
            "168 conv4_block4_concat False\n",
            "169 conv4_block5_0_bn False\n",
            "170 conv4_block5_0_relu False\n",
            "171 conv4_block5_1_conv False\n",
            "172 conv4_block5_1_bn False\n",
            "173 conv4_block5_1_relu False\n",
            "174 conv4_block5_2_conv False\n",
            "175 conv4_block5_concat False\n",
            "176 conv4_block6_0_bn False\n",
            "177 conv4_block6_0_relu False\n",
            "178 conv4_block6_1_conv False\n",
            "179 conv4_block6_1_bn False\n",
            "180 conv4_block6_1_relu False\n",
            "181 conv4_block6_2_conv False\n",
            "182 conv4_block6_concat False\n",
            "183 conv4_block7_0_bn False\n",
            "184 conv4_block7_0_relu False\n",
            "185 conv4_block7_1_conv False\n",
            "186 conv4_block7_1_bn False\n",
            "187 conv4_block7_1_relu False\n",
            "188 conv4_block7_2_conv False\n",
            "189 conv4_block7_concat False\n",
            "190 conv4_block8_0_bn False\n",
            "191 conv4_block8_0_relu False\n",
            "192 conv4_block8_1_conv False\n",
            "193 conv4_block8_1_bn False\n",
            "194 conv4_block8_1_relu False\n",
            "195 conv4_block8_2_conv False\n",
            "196 conv4_block8_concat False\n",
            "197 conv4_block9_0_bn False\n",
            "198 conv4_block9_0_relu False\n",
            "199 conv4_block9_1_conv False\n",
            "200 conv4_block9_1_bn False\n",
            "201 conv4_block9_1_relu False\n",
            "202 conv4_block9_2_conv False\n",
            "203 conv4_block9_concat False\n",
            "204 conv4_block10_0_bn False\n",
            "205 conv4_block10_0_relu False\n",
            "206 conv4_block10_1_conv False\n",
            "207 conv4_block10_1_bn False\n",
            "208 conv4_block10_1_relu False\n",
            "209 conv4_block10_2_conv False\n",
            "210 conv4_block10_concat False\n",
            "211 conv4_block11_0_bn False\n",
            "212 conv4_block11_0_relu False\n",
            "213 conv4_block11_1_conv False\n",
            "214 conv4_block11_1_bn False\n",
            "215 conv4_block11_1_relu False\n",
            "216 conv4_block11_2_conv False\n",
            "217 conv4_block11_concat False\n",
            "218 conv4_block12_0_bn False\n",
            "219 conv4_block12_0_relu False\n",
            "220 conv4_block12_1_conv False\n",
            "221 conv4_block12_1_bn False\n",
            "222 conv4_block12_1_relu False\n",
            "223 conv4_block12_2_conv False\n",
            "224 conv4_block12_concat False\n",
            "225 conv4_block13_0_bn False\n",
            "226 conv4_block13_0_relu False\n",
            "227 conv4_block13_1_conv False\n",
            "228 conv4_block13_1_bn False\n",
            "229 conv4_block13_1_relu False\n",
            "230 conv4_block13_2_conv False\n",
            "231 conv4_block13_concat False\n",
            "232 conv4_block14_0_bn False\n",
            "233 conv4_block14_0_relu False\n",
            "234 conv4_block14_1_conv False\n",
            "235 conv4_block14_1_bn False\n",
            "236 conv4_block14_1_relu False\n",
            "237 conv4_block14_2_conv False\n",
            "238 conv4_block14_concat False\n",
            "239 conv4_block15_0_bn False\n",
            "240 conv4_block15_0_relu False\n",
            "241 conv4_block15_1_conv False\n",
            "242 conv4_block15_1_bn False\n",
            "243 conv4_block15_1_relu False\n",
            "244 conv4_block15_2_conv False\n",
            "245 conv4_block15_concat False\n",
            "246 conv4_block16_0_bn False\n",
            "247 conv4_block16_0_relu False\n",
            "248 conv4_block16_1_conv False\n",
            "249 conv4_block16_1_bn False\n",
            "250 conv4_block16_1_relu False\n",
            "251 conv4_block16_2_conv False\n",
            "252 conv4_block16_concat False\n",
            "253 conv4_block17_0_bn False\n",
            "254 conv4_block17_0_relu False\n",
            "255 conv4_block17_1_conv False\n",
            "256 conv4_block17_1_bn False\n",
            "257 conv4_block17_1_relu False\n",
            "258 conv4_block17_2_conv False\n",
            "259 conv4_block17_concat False\n",
            "260 conv4_block18_0_bn False\n",
            "261 conv4_block18_0_relu False\n",
            "262 conv4_block18_1_conv False\n",
            "263 conv4_block18_1_bn False\n",
            "264 conv4_block18_1_relu False\n",
            "265 conv4_block18_2_conv False\n",
            "266 conv4_block18_concat False\n",
            "267 conv4_block19_0_bn False\n",
            "268 conv4_block19_0_relu False\n",
            "269 conv4_block19_1_conv False\n",
            "270 conv4_block19_1_bn False\n",
            "271 conv4_block19_1_relu False\n",
            "272 conv4_block19_2_conv False\n",
            "273 conv4_block19_concat False\n",
            "274 conv4_block20_0_bn False\n",
            "275 conv4_block20_0_relu False\n",
            "276 conv4_block20_1_conv False\n",
            "277 conv4_block20_1_bn False\n",
            "278 conv4_block20_1_relu False\n",
            "279 conv4_block20_2_conv False\n",
            "280 conv4_block20_concat False\n",
            "281 conv4_block21_0_bn False\n",
            "282 conv4_block21_0_relu False\n",
            "283 conv4_block21_1_conv False\n",
            "284 conv4_block21_1_bn False\n",
            "285 conv4_block21_1_relu False\n",
            "286 conv4_block21_2_conv False\n",
            "287 conv4_block21_concat False\n",
            "288 conv4_block22_0_bn False\n",
            "289 conv4_block22_0_relu False\n",
            "290 conv4_block22_1_conv False\n",
            "291 conv4_block22_1_bn False\n",
            "292 conv4_block22_1_relu False\n",
            "293 conv4_block22_2_conv False\n",
            "294 conv4_block22_concat False\n",
            "295 conv4_block23_0_bn False\n",
            "296 conv4_block23_0_relu False\n",
            "297 conv4_block23_1_conv False\n",
            "298 conv4_block23_1_bn False\n",
            "299 conv4_block23_1_relu False\n",
            "300 conv4_block23_2_conv False\n",
            "301 conv4_block23_concat False\n",
            "302 conv4_block24_0_bn False\n",
            "303 conv4_block24_0_relu False\n",
            "304 conv4_block24_1_conv False\n",
            "305 conv4_block24_1_bn False\n",
            "306 conv4_block24_1_relu False\n",
            "307 conv4_block24_2_conv False\n",
            "308 conv4_block24_concat False\n",
            "309 pool4_bn False\n",
            "310 pool4_relu False\n",
            "311 pool4_conv False\n",
            "312 pool4_pool False\n",
            "313 conv5_block1_0_bn False\n",
            "314 conv5_block1_0_relu False\n",
            "315 conv5_block1_1_conv False\n",
            "316 conv5_block1_1_bn False\n",
            "317 conv5_block1_1_relu False\n",
            "318 conv5_block1_2_conv False\n",
            "319 conv5_block1_concat False\n",
            "320 conv5_block2_0_bn False\n",
            "321 conv5_block2_0_relu False\n",
            "322 conv5_block2_1_conv False\n",
            "323 conv5_block2_1_bn False\n",
            "324 conv5_block2_1_relu False\n",
            "325 conv5_block2_2_conv False\n",
            "326 conv5_block2_concat False\n",
            "327 conv5_block3_0_bn False\n",
            "328 conv5_block3_0_relu False\n",
            "329 conv5_block3_1_conv False\n",
            "330 conv5_block3_1_bn False\n",
            "331 conv5_block3_1_relu False\n",
            "332 conv5_block3_2_conv False\n",
            "333 conv5_block3_concat False\n",
            "334 conv5_block4_0_bn False\n",
            "335 conv5_block4_0_relu False\n",
            "336 conv5_block4_1_conv False\n",
            "337 conv5_block4_1_bn False\n",
            "338 conv5_block4_1_relu False\n",
            "339 conv5_block4_2_conv False\n",
            "340 conv5_block4_concat False\n",
            "341 conv5_block5_0_bn False\n",
            "342 conv5_block5_0_relu False\n",
            "343 conv5_block5_1_conv False\n",
            "344 conv5_block5_1_bn False\n",
            "345 conv5_block5_1_relu False\n",
            "346 conv5_block5_2_conv False\n",
            "347 conv5_block5_concat False\n",
            "348 conv5_block6_0_bn False\n",
            "349 conv5_block6_0_relu False\n",
            "350 conv5_block6_1_conv False\n",
            "351 conv5_block6_1_bn False\n",
            "352 conv5_block6_1_relu False\n",
            "353 conv5_block6_2_conv False\n",
            "354 conv5_block6_concat False\n",
            "355 conv5_block7_0_bn False\n",
            "356 conv5_block7_0_relu False\n",
            "357 conv5_block7_1_conv False\n",
            "358 conv5_block7_1_bn False\n",
            "359 conv5_block7_1_relu False\n",
            "360 conv5_block7_2_conv False\n",
            "361 conv5_block7_concat False\n",
            "362 conv5_block8_0_bn False\n",
            "363 conv5_block8_0_relu False\n",
            "364 conv5_block8_1_conv False\n",
            "365 conv5_block8_1_bn False\n",
            "366 conv5_block8_1_relu False\n",
            "367 conv5_block8_2_conv False\n",
            "368 conv5_block8_concat False\n",
            "369 conv5_block9_0_bn False\n",
            "370 conv5_block9_0_relu False\n",
            "371 conv5_block9_1_conv False\n",
            "372 conv5_block9_1_bn False\n",
            "373 conv5_block9_1_relu False\n",
            "374 conv5_block9_2_conv False\n",
            "375 conv5_block9_concat False\n",
            "376 conv5_block10_0_bn False\n",
            "377 conv5_block10_0_relu True\n",
            "378 conv5_block10_1_conv True\n",
            "379 conv5_block10_1_bn True\n",
            "380 conv5_block10_1_relu True\n",
            "381 conv5_block10_2_conv True\n",
            "382 conv5_block10_concat True\n",
            "383 conv5_block11_0_bn True\n",
            "384 conv5_block11_0_relu True\n",
            "385 conv5_block11_1_conv True\n",
            "386 conv5_block11_1_bn True\n",
            "387 conv5_block11_1_relu True\n",
            "388 conv5_block11_2_conv True\n",
            "389 conv5_block11_concat True\n",
            "390 conv5_block12_0_bn True\n",
            "391 conv5_block12_0_relu True\n",
            "392 conv5_block12_1_conv True\n",
            "393 conv5_block12_1_bn True\n",
            "394 conv5_block12_1_relu True\n",
            "395 conv5_block12_2_conv True\n",
            "396 conv5_block12_concat True\n",
            "397 conv5_block13_0_bn True\n",
            "398 conv5_block13_0_relu True\n",
            "399 conv5_block13_1_conv True\n",
            "400 conv5_block13_1_bn True\n",
            "401 conv5_block13_1_relu True\n",
            "402 conv5_block13_2_conv True\n",
            "403 conv5_block13_concat True\n",
            "404 conv5_block14_0_bn True\n",
            "405 conv5_block14_0_relu True\n",
            "406 conv5_block14_1_conv True\n",
            "407 conv5_block14_1_bn True\n",
            "408 conv5_block14_1_relu True\n",
            "409 conv5_block14_2_conv True\n",
            "410 conv5_block14_concat True\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KcDo2VlW-6Jt"
      },
      "outputs": [],
      "source": [
        "#conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6prLuQV--6Jt",
        "outputId": "21272876-2976-4870-ca8a-f63126fc18c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 48\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 3,435,969\n",
            "Non-trainable params: 5,962,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "adagrad = optimizers.Adagrad(learning_rate=TrainingConfig.LEARNING_RATE, initial_accumulator_value=0.1, epsilon=TrainingConfig.EPSILON, decay =TrainingConfig.WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "P4qDSomz-6Jt"
      },
      "outputs": [],
      "source": [
        "modelPreTMob.compile(optimizer= adagrad, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])# Adagrad, adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add checkpoint to store the model on the best epoch for Val acc.\n",
        "checkpoint_filepath = r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-{epoch:02d}-{val_accuracy:.4f}.keras'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "print(TrainingConfig.EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.3855 - accuracy: 0.8013\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86684, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-01-0.8668.keras\n",
            "329/329 [==============================] - 238s 692ms/step - loss: 5.3855 - accuracy: 0.8013 - val_loss: 5.1520 - val_accuracy: 0.8668\n",
            "Epoch 2/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.1392 - accuracy: 0.8402\n",
            "Epoch 2: val_accuracy improved from 0.86684 to 0.87158, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-02-0.8716.keras\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 5.1392 - accuracy: 0.8402 - val_loss: 4.9795 - val_accuracy: 0.8716\n",
            "Epoch 3/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.9814 - accuracy: 0.8500\n",
            "Epoch 3: val_accuracy improved from 0.87158 to 0.88289, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-03-0.8829.keras\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.9814 - accuracy: 0.8500 - val_loss: 4.8444 - val_accuracy: 0.8829\n",
            "Epoch 4/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.8454 - accuracy: 0.8556\n",
            "Epoch 4: val_accuracy did not improve from 0.88289\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 4.8454 - accuracy: 0.8556 - val_loss: 4.7326 - val_accuracy: 0.8817\n",
            "Epoch 5/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.7345 - accuracy: 0.8605\n",
            "Epoch 5: val_accuracy improved from 0.88289 to 0.88539, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-05-0.8854.keras\n",
            "329/329 [==============================] - 207s 630ms/step - loss: 4.7345 - accuracy: 0.8605 - val_loss: 4.6307 - val_accuracy: 0.8854\n",
            "Epoch 6/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.6402 - accuracy: 0.8610\n",
            "Epoch 6: val_accuracy improved from 0.88539 to 0.88658, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-06-0.8866.keras\n",
            "329/329 [==============================] - 219s 667ms/step - loss: 4.6402 - accuracy: 0.8610 - val_loss: 4.5425 - val_accuracy: 0.8866\n",
            "Epoch 7/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.5513 - accuracy: 0.8657\n",
            "Epoch 7: val_accuracy improved from 0.88658 to 0.88855, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-07-0.8886.keras\n",
            "329/329 [==============================] - 214s 651ms/step - loss: 4.5513 - accuracy: 0.8657 - val_loss: 4.4641 - val_accuracy: 0.8886\n",
            "Epoch 8/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4832 - accuracy: 0.8637\n",
            "Epoch 8: val_accuracy improved from 0.88855 to 0.89079, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-08-0.8908.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 4.4832 - accuracy: 0.8637 - val_loss: 4.3944 - val_accuracy: 0.8908\n",
            "Epoch 9/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4089 - accuracy: 0.8674\n",
            "Epoch 9: val_accuracy did not improve from 0.89079\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.4089 - accuracy: 0.8674 - val_loss: 4.3293 - val_accuracy: 0.8891\n",
            "Epoch 10/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.3530 - accuracy: 0.8657\n",
            "Epoch 10: val_accuracy did not improve from 0.89079\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 4.3530 - accuracy: 0.8657 - val_loss: 4.2728 - val_accuracy: 0.8899\n",
            "Epoch 11/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2921 - accuracy: 0.8697\n",
            "Epoch 11: val_accuracy did not improve from 0.89079\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 4.2921 - accuracy: 0.8697 - val_loss: 4.2190 - val_accuracy: 0.8903\n",
            "Epoch 12/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2433 - accuracy: 0.8677\n",
            "Epoch 12: val_accuracy did not improve from 0.89079\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.2433 - accuracy: 0.8677 - val_loss: 4.1704 - val_accuracy: 0.8907\n",
            "Epoch 13/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1893 - accuracy: 0.8703\n",
            "Epoch 13: val_accuracy improved from 0.89079 to 0.89197, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-13-0.8920.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 4.1893 - accuracy: 0.8703 - val_loss: 4.1237 - val_accuracy: 0.8920\n",
            "Epoch 14/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1462 - accuracy: 0.8718\n",
            "Epoch 14: val_accuracy improved from 0.89197 to 0.89316, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-14-0.8932.keras\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.1462 - accuracy: 0.8718 - val_loss: 4.0806 - val_accuracy: 0.8932\n",
            "Epoch 15/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1005 - accuracy: 0.8729\n",
            "Epoch 15: val_accuracy did not improve from 0.89316\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.1005 - accuracy: 0.8729 - val_loss: 4.0407 - val_accuracy: 0.8926\n",
            "Epoch 16/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0709 - accuracy: 0.8683\n",
            "Epoch 16: val_accuracy did not improve from 0.89316\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.0709 - accuracy: 0.8683 - val_loss: 4.0048 - val_accuracy: 0.8924\n",
            "Epoch 17/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0321 - accuracy: 0.8762\n",
            "Epoch 17: val_accuracy did not improve from 0.89316\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 4.0321 - accuracy: 0.8762 - val_loss: 3.9702 - val_accuracy: 0.8926\n",
            "Epoch 18/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9933 - accuracy: 0.8734\n",
            "Epoch 18: val_accuracy did not improve from 0.89316\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.9933 - accuracy: 0.8734 - val_loss: 3.9375 - val_accuracy: 0.8930\n",
            "Epoch 19/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9605 - accuracy: 0.8755\n",
            "Epoch 19: val_accuracy improved from 0.89316 to 0.89382, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-19-0.8938.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.9605 - accuracy: 0.8755 - val_loss: 3.9058 - val_accuracy: 0.8938\n",
            "Epoch 20/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9378 - accuracy: 0.8720\n",
            "Epoch 20: val_accuracy improved from 0.89382 to 0.89461, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-20-0.8946.keras\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.9378 - accuracy: 0.8720 - val_loss: 3.8758 - val_accuracy: 0.8946\n",
            "Epoch 21/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9018 - accuracy: 0.8738\n",
            "Epoch 21: val_accuracy did not improve from 0.89461\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.9018 - accuracy: 0.8738 - val_loss: 3.8483 - val_accuracy: 0.8942\n",
            "Epoch 22/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8758 - accuracy: 0.8737\n",
            "Epoch 22: val_accuracy improved from 0.89461 to 0.89474, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-22-0.8947.keras\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.8758 - accuracy: 0.8737 - val_loss: 3.8206 - val_accuracy: 0.8947\n",
            "Epoch 23/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8529 - accuracy: 0.8712\n",
            "Epoch 23: val_accuracy improved from 0.89474 to 0.89526, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-23-0.8953.keras\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.8529 - accuracy: 0.8712 - val_loss: 3.7956 - val_accuracy: 0.8953\n",
            "Epoch 24/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8224 - accuracy: 0.8763\n",
            "Epoch 24: val_accuracy improved from 0.89526 to 0.89566, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-24-0.8957.keras\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.8224 - accuracy: 0.8763 - val_loss: 3.7711 - val_accuracy: 0.8957\n",
            "Epoch 25/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7949 - accuracy: 0.8752\n",
            "Epoch 25: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.7949 - accuracy: 0.8752 - val_loss: 3.7479 - val_accuracy: 0.8949\n",
            "Epoch 26/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7785 - accuracy: 0.8773\n",
            "Epoch 26: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.7785 - accuracy: 0.8773 - val_loss: 3.7259 - val_accuracy: 0.8953\n",
            "Epoch 27/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7510 - accuracy: 0.8776\n",
            "Epoch 27: val_accuracy improved from 0.89566 to 0.89618, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-27-0.8962.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.7510 - accuracy: 0.8776 - val_loss: 3.7035 - val_accuracy: 0.8962\n",
            "Epoch 28/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7297 - accuracy: 0.8772\n",
            "Epoch 28: val_accuracy improved from 0.89618 to 0.89711, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-28-0.8971.keras\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.7297 - accuracy: 0.8772 - val_loss: 3.6832 - val_accuracy: 0.8971\n",
            "Epoch 29/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7166 - accuracy: 0.8757\n",
            "Epoch 29: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.7166 - accuracy: 0.8757 - val_loss: 3.6637 - val_accuracy: 0.8959\n",
            "Epoch 30/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6936 - accuracy: 0.8770\n",
            "Epoch 30: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.6936 - accuracy: 0.8770 - val_loss: 3.6437 - val_accuracy: 0.8970\n",
            "Epoch 31/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6745 - accuracy: 0.8783\n",
            "Epoch 31: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.6745 - accuracy: 0.8783 - val_loss: 3.6261 - val_accuracy: 0.8961\n",
            "Epoch 32/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6551 - accuracy: 0.8789\n",
            "Epoch 32: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.6551 - accuracy: 0.8789 - val_loss: 3.6083 - val_accuracy: 0.8955\n",
            "Epoch 33/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6385 - accuracy: 0.8744\n",
            "Epoch 33: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.6385 - accuracy: 0.8744 - val_loss: 3.5904 - val_accuracy: 0.8961\n",
            "Epoch 34/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6180 - accuracy: 0.8778\n",
            "Epoch 34: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 207s 627ms/step - loss: 3.6180 - accuracy: 0.8778 - val_loss: 3.5749 - val_accuracy: 0.8966\n",
            "Epoch 35/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6039 - accuracy: 0.8786\n",
            "Epoch 35: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 207s 629ms/step - loss: 3.6039 - accuracy: 0.8786 - val_loss: 3.5594 - val_accuracy: 0.8967\n",
            "Epoch 36/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5863 - accuracy: 0.8810\n",
            "Epoch 36: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 3.5863 - accuracy: 0.8810 - val_loss: 3.5441 - val_accuracy: 0.8964\n",
            "Epoch 37/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5751 - accuracy: 0.8775\n",
            "Epoch 37: val_accuracy improved from 0.89711 to 0.89724, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-37-0.8972.keras\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.5751 - accuracy: 0.8775 - val_loss: 3.5278 - val_accuracy: 0.8972\n",
            "Epoch 38/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5561 - accuracy: 0.8804\n",
            "Epoch 38: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.5561 - accuracy: 0.8804 - val_loss: 3.5132 - val_accuracy: 0.8961\n",
            "Epoch 39/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5430 - accuracy: 0.8768\n",
            "Epoch 39: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.5430 - accuracy: 0.8768 - val_loss: 3.4998 - val_accuracy: 0.8957\n",
            "Epoch 40/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5294 - accuracy: 0.8774\n",
            "Epoch 40: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.5294 - accuracy: 0.8774 - val_loss: 3.4855 - val_accuracy: 0.8966\n",
            "Epoch 41/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5151 - accuracy: 0.8780\n",
            "Epoch 41: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.5151 - accuracy: 0.8780 - val_loss: 3.4719 - val_accuracy: 0.8958\n",
            "Epoch 42/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4985 - accuracy: 0.8796\n",
            "Epoch 42: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.4985 - accuracy: 0.8796 - val_loss: 3.4589 - val_accuracy: 0.8972\n",
            "Epoch 43/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4943 - accuracy: 0.8766\n",
            "Epoch 43: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4943 - accuracy: 0.8766 - val_loss: 3.4467 - val_accuracy: 0.8959\n",
            "Epoch 44/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4804 - accuracy: 0.8794\n",
            "Epoch 44: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.4804 - accuracy: 0.8794 - val_loss: 3.4348 - val_accuracy: 0.8970\n",
            "Epoch 45/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4677 - accuracy: 0.8793\n",
            "Epoch 45: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.4677 - accuracy: 0.8793 - val_loss: 3.4233 - val_accuracy: 0.8963\n",
            "Epoch 46/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4505 - accuracy: 0.8806\n",
            "Epoch 46: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4505 - accuracy: 0.8806 - val_loss: 3.4110 - val_accuracy: 0.8971\n",
            "Epoch 47/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4439 - accuracy: 0.8803\n",
            "Epoch 47: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.4439 - accuracy: 0.8803 - val_loss: 3.3992 - val_accuracy: 0.8968\n",
            "Epoch 48/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4269 - accuracy: 0.8800\n",
            "Epoch 48: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.4269 - accuracy: 0.8800 - val_loss: 3.3887 - val_accuracy: 0.8972\n",
            "Epoch 49/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4177 - accuracy: 0.8795\n",
            "Epoch 49: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4177 - accuracy: 0.8795 - val_loss: 3.3786 - val_accuracy: 0.8971\n",
            "Epoch 50/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4035 - accuracy: 0.8809\n",
            "Epoch 50: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4035 - accuracy: 0.8809 - val_loss: 3.3678 - val_accuracy: 0.8966\n",
            "Epoch 51/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4030 - accuracy: 0.8792\n",
            "Epoch 51: val_accuracy did not improve from 0.89724\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.4030 - accuracy: 0.8792 - val_loss: 3.3575 - val_accuracy: 0.8970\n",
            "Epoch 52/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3828 - accuracy: 0.8827\n",
            "Epoch 52: val_accuracy improved from 0.89724 to 0.89750, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-52-0.8975.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.3828 - accuracy: 0.8827 - val_loss: 3.3471 - val_accuracy: 0.8975\n",
            "Epoch 53/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3835 - accuracy: 0.8782\n",
            "Epoch 53: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.3835 - accuracy: 0.8782 - val_loss: 3.3370 - val_accuracy: 0.8963\n",
            "Epoch 54/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3658 - accuracy: 0.8813\n",
            "Epoch 54: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.3658 - accuracy: 0.8813 - val_loss: 3.3275 - val_accuracy: 0.8968\n",
            "Epoch 55/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3512 - accuracy: 0.8841\n",
            "Epoch 55: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.3512 - accuracy: 0.8841 - val_loss: 3.3186 - val_accuracy: 0.8971\n",
            "Epoch 56/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3499 - accuracy: 0.8800\n",
            "Epoch 56: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.3499 - accuracy: 0.8800 - val_loss: 3.3097 - val_accuracy: 0.8963\n",
            "Epoch 57/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3366 - accuracy: 0.8817\n",
            "Epoch 57: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.3366 - accuracy: 0.8817 - val_loss: 3.3012 - val_accuracy: 0.8971\n",
            "Epoch 58/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3291 - accuracy: 0.8806\n",
            "Epoch 58: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.3291 - accuracy: 0.8806 - val_loss: 3.2924 - val_accuracy: 0.8971\n",
            "Epoch 59/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3231 - accuracy: 0.8806\n",
            "Epoch 59: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.3231 - accuracy: 0.8806 - val_loss: 3.2838 - val_accuracy: 0.8970\n",
            "Epoch 60/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3132 - accuracy: 0.8825\n",
            "Epoch 60: val_accuracy did not improve from 0.89750\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.3132 - accuracy: 0.8825 - val_loss: 3.2748 - val_accuracy: 0.8967\n",
            "Epoch 61/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2991 - accuracy: 0.8834\n",
            "Epoch 61: val_accuracy improved from 0.89750 to 0.89763, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-61-0.8976.keras\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.2991 - accuracy: 0.8834 - val_loss: 3.2667 - val_accuracy: 0.8976\n",
            "Epoch 62/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3023 - accuracy: 0.8810\n",
            "Epoch 62: val_accuracy improved from 0.89763 to 0.89789, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-62-0.8979.keras\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.3023 - accuracy: 0.8810 - val_loss: 3.2586 - val_accuracy: 0.8979\n",
            "Epoch 63/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2888 - accuracy: 0.8828\n",
            "Epoch 63: val_accuracy did not improve from 0.89789\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.2888 - accuracy: 0.8828 - val_loss: 3.2503 - val_accuracy: 0.8976\n",
            "Epoch 64/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2875 - accuracy: 0.8801\n",
            "Epoch 64: val_accuracy did not improve from 0.89789\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.2875 - accuracy: 0.8801 - val_loss: 3.2428 - val_accuracy: 0.8976\n",
            "Epoch 65/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2707 - accuracy: 0.8830\n",
            "Epoch 65: val_accuracy improved from 0.89789 to 0.89803, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-65-0.8980.keras\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.2707 - accuracy: 0.8830 - val_loss: 3.2353 - val_accuracy: 0.8980\n",
            "Epoch 66/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2593 - accuracy: 0.8837\n",
            "Epoch 66: val_accuracy did not improve from 0.89803\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.2593 - accuracy: 0.8837 - val_loss: 3.2278 - val_accuracy: 0.8978\n",
            "Epoch 67/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2573 - accuracy: 0.8790\n",
            "Epoch 67: val_accuracy did not improve from 0.89803\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.2573 - accuracy: 0.8790 - val_loss: 3.2206 - val_accuracy: 0.8979\n",
            "Epoch 68/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2551 - accuracy: 0.8810\n",
            "Epoch 68: val_accuracy improved from 0.89803 to 0.89816, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-68-0.8982.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.2551 - accuracy: 0.8810 - val_loss: 3.2134 - val_accuracy: 0.8982\n",
            "Epoch 69/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2424 - accuracy: 0.8816\n",
            "Epoch 69: val_accuracy improved from 0.89816 to 0.89829, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-69-0.8983.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.2424 - accuracy: 0.8816 - val_loss: 3.2060 - val_accuracy: 0.8983\n",
            "Epoch 70/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2378 - accuracy: 0.8820\n",
            "Epoch 70: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.2378 - accuracy: 0.8820 - val_loss: 3.1991 - val_accuracy: 0.8978\n",
            "Epoch 71/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2226 - accuracy: 0.8867\n",
            "Epoch 71: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.2226 - accuracy: 0.8867 - val_loss: 3.1924 - val_accuracy: 0.8982\n",
            "Epoch 72/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2226 - accuracy: 0.8793\n",
            "Epoch 72: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.2226 - accuracy: 0.8793 - val_loss: 3.1857 - val_accuracy: 0.8983\n",
            "Epoch 73/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2113 - accuracy: 0.8851\n",
            "Epoch 73: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.2113 - accuracy: 0.8851 - val_loss: 3.1794 - val_accuracy: 0.8982\n",
            "Epoch 74/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2122 - accuracy: 0.8825\n",
            "Epoch 74: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.2122 - accuracy: 0.8825 - val_loss: 3.1727 - val_accuracy: 0.8982\n",
            "Epoch 75/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2019 - accuracy: 0.8816\n",
            "Epoch 75: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.2019 - accuracy: 0.8816 - val_loss: 3.1667 - val_accuracy: 0.8979\n",
            "Epoch 76/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1950 - accuracy: 0.8819\n",
            "Epoch 76: val_accuracy did not improve from 0.89829\n",
            "329/329 [==============================] - 205s 621ms/step - loss: 3.1950 - accuracy: 0.8819 - val_loss: 3.1597 - val_accuracy: 0.8982\n",
            "Epoch 77/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1862 - accuracy: 0.8821\n",
            "Epoch 77: val_accuracy improved from 0.89829 to 0.89842, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-77-0.8984.keras\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.1862 - accuracy: 0.8821 - val_loss: 3.1536 - val_accuracy: 0.8984\n",
            "Epoch 78/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1800 - accuracy: 0.8859\n",
            "Epoch 78: val_accuracy improved from 0.89842 to 0.89895, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-78-0.8989.keras\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.1800 - accuracy: 0.8859 - val_loss: 3.1476 - val_accuracy: 0.8989\n",
            "Epoch 79/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1722 - accuracy: 0.8846\n",
            "Epoch 79: val_accuracy did not improve from 0.89895\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.1722 - accuracy: 0.8846 - val_loss: 3.1422 - val_accuracy: 0.8978\n",
            "Epoch 80/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1680 - accuracy: 0.8848\n",
            "Epoch 80: val_accuracy did not improve from 0.89895\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.1680 - accuracy: 0.8848 - val_loss: 3.1361 - val_accuracy: 0.8988\n",
            "Epoch 81/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1585 - accuracy: 0.8843\n",
            "Epoch 81: val_accuracy did not improve from 0.89895\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.1585 - accuracy: 0.8843 - val_loss: 3.1304 - val_accuracy: 0.8982\n",
            "Epoch 82/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1639 - accuracy: 0.8801\n",
            "Epoch 82: val_accuracy did not improve from 0.89895\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.1639 - accuracy: 0.8801 - val_loss: 3.1246 - val_accuracy: 0.8978\n",
            "Epoch 83/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1501 - accuracy: 0.8832\n",
            "Epoch 83: val_accuracy did not improve from 0.89895\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.1501 - accuracy: 0.8832 - val_loss: 3.1191 - val_accuracy: 0.8982\n",
            "Epoch 84/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1496 - accuracy: 0.8800\n",
            "Epoch 84: val_accuracy did not improve from 0.89895\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.1496 - accuracy: 0.8800 - val_loss: 3.1136 - val_accuracy: 0.8980\n",
            "Epoch 85/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1424 - accuracy: 0.8820\n",
            "Epoch 85: val_accuracy improved from 0.89895 to 0.89908, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-85-0.8991.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.1424 - accuracy: 0.8820 - val_loss: 3.1080 - val_accuracy: 0.8991\n",
            "Epoch 86/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1348 - accuracy: 0.8820\n",
            "Epoch 86: val_accuracy improved from 0.89908 to 0.89921, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-86-0.8992.keras\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.1348 - accuracy: 0.8820 - val_loss: 3.1028 - val_accuracy: 0.8992\n",
            "Epoch 87/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1343 - accuracy: 0.8819\n",
            "Epoch 87: val_accuracy improved from 0.89921 to 0.89934, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-87-0.8993.keras\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1343 - accuracy: 0.8819 - val_loss: 3.0970 - val_accuracy: 0.8993\n",
            "Epoch 88/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1260 - accuracy: 0.8827\n",
            "Epoch 88: val_accuracy improved from 0.89934 to 0.89974, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-88-0.8997.keras\n",
            "329/329 [==============================] - 205s 621ms/step - loss: 3.1260 - accuracy: 0.8827 - val_loss: 3.0918 - val_accuracy: 0.8997\n",
            "Epoch 89/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1189 - accuracy: 0.8830\n",
            "Epoch 89: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.1189 - accuracy: 0.8830 - val_loss: 3.0864 - val_accuracy: 0.8992\n",
            "Epoch 90/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1131 - accuracy: 0.8852\n",
            "Epoch 90: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 208s 633ms/step - loss: 3.1131 - accuracy: 0.8852 - val_loss: 3.0815 - val_accuracy: 0.8993\n",
            "Epoch 91/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1184 - accuracy: 0.8794\n",
            "Epoch 91: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 214s 651ms/step - loss: 3.1184 - accuracy: 0.8794 - val_loss: 3.0764 - val_accuracy: 0.8991\n",
            "Epoch 92/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1069 - accuracy: 0.8821\n",
            "Epoch 92: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 213s 646ms/step - loss: 3.1069 - accuracy: 0.8821 - val_loss: 3.0721 - val_accuracy: 0.8992\n",
            "Epoch 93/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0999 - accuracy: 0.8837\n",
            "Epoch 93: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 211s 641ms/step - loss: 3.0999 - accuracy: 0.8837 - val_loss: 3.0668 - val_accuracy: 0.8995\n",
            "Epoch 94/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0942 - accuracy: 0.8847\n",
            "Epoch 94: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 208s 633ms/step - loss: 3.0942 - accuracy: 0.8847 - val_loss: 3.0623 - val_accuracy: 0.8987\n",
            "Epoch 95/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0859 - accuracy: 0.8846\n",
            "Epoch 95: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 213s 647ms/step - loss: 3.0859 - accuracy: 0.8846 - val_loss: 3.0574 - val_accuracy: 0.8997\n",
            "Epoch 96/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0868 - accuracy: 0.8840\n",
            "Epoch 96: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 216s 656ms/step - loss: 3.0868 - accuracy: 0.8840 - val_loss: 3.0532 - val_accuracy: 0.8991\n",
            "Epoch 97/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0775 - accuracy: 0.8834\n",
            "Epoch 97: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 228s 692ms/step - loss: 3.0775 - accuracy: 0.8834 - val_loss: 3.0483 - val_accuracy: 0.8993\n",
            "Epoch 98/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0780 - accuracy: 0.8827\n",
            "Epoch 98: val_accuracy did not improve from 0.89974\n",
            "329/329 [==============================] - 218s 662ms/step - loss: 3.0780 - accuracy: 0.8827 - val_loss: 3.0434 - val_accuracy: 0.8997\n",
            "Epoch 99/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0713 - accuracy: 0.8830\n",
            "Epoch 99: val_accuracy improved from 0.89974 to 0.90026, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT50-99-0.9003.keras\n",
            "329/329 [==============================] - 216s 655ms/step - loss: 3.0713 - accuracy: 0.8830 - val_loss: 3.0389 - val_accuracy: 0.9003\n",
            "Epoch 100/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0676 - accuracy: 0.8860\n",
            "Epoch 100: val_accuracy did not improve from 0.90026\n",
            "329/329 [==============================] - 214s 650ms/step - loss: 3.0676 - accuracy: 0.8860 - val_loss: 3.0347 - val_accuracy: 0.8997\n"
          ]
        }
      ],
      "source": [
        "histPreT = modelPreTMob.fit(train_generator, epochs = TrainingConfig.EPOCHS, validation_data=validation_generator, callbacks=[model_checkpoint_callback]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 20622.02314901352 seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(Current_dir, 'History')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(r'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History\\\\HistoryDict_DenseNEt_FT50', 'wb') as file_pi:\n",
        "    pickle.dump(histPreT.history, file_pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 99\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "START_PLOT_FROM_EPOCH= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "e3wZrd90-6Jt",
        "outputId": "0630124c-9747-4688-f755-aaf80997102f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc = histPreT.history['accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "val_acc = histPreT.history['val_accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "loss = histPreT.history['loss'][START_PLOT_FROM_EPOCH:]\n",
        "val_loss = histPreT.history['val_loss'][START_PLOT_FROM_EPOCH:]\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, color='teal', label='Training acc')\n",
        "plt.plot(epochs, val_acc, color='orange', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, color='teal', label='Training loss')\n",
        "plt.plot(epochs, val_loss, color='orange', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 99\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading best epoch in our model using the checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dir= r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints' # C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model file: model-99-0.9003.keras\n"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = max(val_acc_per_epoch)\n",
        "best_model_file = f'model-{best_epoch:02d}-{best_val_accuracy:.4f}.keras'\n",
        "\n",
        "print(f'Best model file: {best_model_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\checkpoints'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(model_dir)\n",
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['checkpoints.lnk',\n",
              " 'ConvNextTiny_FT20-01-0.8195.keras',\n",
              " 'ConvNextTiny_FT20-04-0.8350.keras',\n",
              " 'ConvNextTiny_FT20-06-0.8462.keras',\n",
              " 'ConvNextTiny_FT20-07-0.8566.keras',\n",
              " 'ConvNextTiny_FT20-09-0.8584.keras',\n",
              " 'ConvNextTiny_FT20-27-0.8608.keras',\n",
              " 'ConvNextTiny_FT20-70-0.8611.keras',\n",
              " 'model-01-0.8824.keras',\n",
              " 'model-02-0.8867.keras',\n",
              " 'model-03-0.8893.keras',\n",
              " 'model-05-0.8895.keras',\n",
              " 'model-06-0.8934.keras',\n",
              " 'model-09-0.8961.keras',\n",
              " 'model-11-0.8966.keras',\n",
              " 'modelAlexNetFT10-01-0.8759.keras',\n",
              " 'modelAlexNetFT10-02-0.8841.keras',\n",
              " 'modelAlexNetFT10-06-0.8904.keras',\n",
              " 'modelAlexNetFT10-08-0.8968.keras',\n",
              " 'modelAlexNetFT10-13-0.8987.keras',\n",
              " 'modelAlexNetFT10-14-0.9022.keras',\n",
              " 'modelAlexNetFT10-24-0.9043.keras',\n",
              " 'modelDenseNet-01-0.8676.keras',\n",
              " 'modelDenseNet-02-0.8737.keras',\n",
              " 'modelDenseNet-03-0.8803.keras',\n",
              " 'modelDenseNet-04-0.8824.keras',\n",
              " 'modelDenseNet-05-0.8826.keras',\n",
              " 'modelDenseNet-08-0.8837.keras',\n",
              " 'modelDenseNet-12-0.8843.keras',\n",
              " 'modelDenseNet-14-0.8854.keras',\n",
              " 'modelDenseNet-15-0.8857.keras',\n",
              " 'modelDenseNet-16-0.8862.keras',\n",
              " 'modelDenseNet-22-0.8863.keras',\n",
              " 'modelDenseNet-23-0.8875.keras',\n",
              " 'modelDenseNet-39-0.8878.keras',\n",
              " 'modelDenseNet-40-0.8884.keras',\n",
              " 'modelDenseNet-43-0.8886.keras',\n",
              " 'modelDenseNet-49-0.8888.keras',\n",
              " 'modelDenseNet-59-0.8893.keras',\n",
              " 'modelDenseNet-75-0.8897.keras',\n",
              " 'modelDenseNet-81-0.8901.keras',\n",
              " 'modelDenseNet-87-0.8903.keras',\n",
              " 'modelDenseNetFT15-01-0.8609.keras',\n",
              " 'modelDenseNetFT15-02-0.8750.keras',\n",
              " 'modelDenseNetFT15-03-0.8783.keras',\n",
              " 'modelDenseNetFT15-04-0.8796.keras',\n",
              " 'modelDenseNetFT15-05-0.8816.keras',\n",
              " 'modelDenseNetFT15-06-0.8826.keras',\n",
              " 'modelDenseNetFT15-07-0.8833.keras',\n",
              " 'modelDenseNetFT15-08-0.8858.keras',\n",
              " 'modelDenseNetFT15-09-0.8864.keras',\n",
              " 'modelDenseNetFT15-11-0.8887.keras',\n",
              " 'modelDenseNetFT15-14-0.8888.keras',\n",
              " 'modelDenseNetFT15-16-0.8900.keras',\n",
              " 'modelDenseNetFT15-19-0.8917.keras',\n",
              " 'modelDenseNetFT15-42-0.8922.keras',\n",
              " 'modelDenseNetFT15-47-0.8924.keras',\n",
              " 'modelDenseNetFT15-50-0.8926.keras',\n",
              " 'modelDenseNetFT15-53-0.8928.keras',\n",
              " 'modelDenseNetFT15-55-0.8930.keras',\n",
              " 'modelDenseNetFT15-61-0.8933.keras',\n",
              " 'modelDenseNetFT15-66-0.8936.keras',\n",
              " 'modelDenseNetFT15-67-0.8939.keras',\n",
              " 'modelDenseNetFT15-74-0.8942.keras',\n",
              " 'modelDenseNetFT15-86-0.8943.keras',\n",
              " 'modelDenseNetFT30-01-0.8667.keras',\n",
              " 'modelDenseNetFT30-02-0.8717.keras',\n",
              " 'modelDenseNetFT30-03-0.8796.keras',\n",
              " 'modelDenseNetFT30-04-0.8845.keras',\n",
              " 'modelDenseNetFT30-05-0.8854.keras',\n",
              " 'modelDenseNetFT30-06-0.8855.keras',\n",
              " 'modelDenseNetFT30-07-0.8872.keras',\n",
              " 'modelDenseNetFT30-09-0.8882.keras',\n",
              " 'modelDenseNetFT30-10-0.8893.keras',\n",
              " 'modelDenseNetFT30-12-0.8896.keras',\n",
              " 'modelDenseNetFT30-13-0.8904.keras',\n",
              " 'modelDenseNetFT30-14-0.8905.keras',\n",
              " 'modelDenseNetFT30-15-0.8909.keras',\n",
              " 'modelDenseNetFT30-19-0.8920.keras',\n",
              " 'modelDenseNetFT30-20-0.8924.keras',\n",
              " 'modelDenseNetFT30-26-0.8933.keras',\n",
              " 'modelDenseNetFT30-31-0.8934.keras',\n",
              " 'modelDenseNetFT30-43-0.8938.keras',\n",
              " 'modelDenseNetFT30-57-0.8941.keras',\n",
              " 'modelDenseNetFT30-62-0.8943.keras',\n",
              " 'modelDenseNetFT30-64-0.8957.keras',\n",
              " 'modelDenseNetFT30-84-0.8961.keras',\n",
              " 'modelDenseNetFT30-97-0.8971.keras',\n",
              " 'modelDenseNetFT50-01-0.8668.keras',\n",
              " 'modelDenseNetFT50-02-0.8716.keras',\n",
              " 'modelDenseNetFT50-03-0.8829.keras',\n",
              " 'modelDenseNetFT50-05-0.8854.keras',\n",
              " 'modelDenseNetFT50-06-0.8866.keras',\n",
              " 'modelDenseNetFT50-07-0.8886.keras',\n",
              " 'modelDenseNetFT50-08-0.8908.keras',\n",
              " 'modelDenseNetFT50-13-0.8920.keras',\n",
              " 'modelDenseNetFT50-14-0.8932.keras',\n",
              " 'modelDenseNetFT50-19-0.8938.keras',\n",
              " 'modelDenseNetFT50-20-0.8946.keras',\n",
              " 'modelDenseNetFT50-22-0.8947.keras',\n",
              " 'modelDenseNetFT50-23-0.8953.keras',\n",
              " 'modelDenseNetFT50-24-0.8957.keras',\n",
              " 'modelDenseNetFT50-27-0.8962.keras',\n",
              " 'modelDenseNetFT50-28-0.8971.keras',\n",
              " 'modelDenseNetFT50-37-0.8972.keras',\n",
              " 'modelDenseNetFT50-52-0.8975.keras',\n",
              " 'modelDenseNetFT50-61-0.8976.keras',\n",
              " 'modelDenseNetFT50-62-0.8979.keras',\n",
              " 'modelDenseNetFT50-65-0.8980.keras',\n",
              " 'modelDenseNetFT50-68-0.8982.keras',\n",
              " 'modelDenseNetFT50-69-0.8983.keras',\n",
              " 'modelDenseNetFT50-77-0.8984.keras',\n",
              " 'modelDenseNetFT50-78-0.8989.keras',\n",
              " 'modelDenseNetFT50-85-0.8991.keras',\n",
              " 'modelDenseNetFT50-86-0.8992.keras',\n",
              " 'modelDenseNetFT50-87-0.8993.keras',\n",
              " 'modelDenseNetFT50-88-0.8997.keras',\n",
              " 'modelDenseNetFT50-99-0.9003.keras',\n",
              " 'modelMobileNetV2FT20-01-0.7942.keras',\n",
              " 'modelMobileNetV2FT20-02-0.8239.keras',\n",
              " 'modelMobileNetV2FT20-03-0.8364.keras',\n",
              " 'modelMobileNetV2FT20-04-0.8528.keras',\n",
              " 'modelMobileNetV2FT20-05-0.8658.keras',\n",
              " 'modelMobileNetV2FT20-06-0.8661.keras',\n",
              " 'modelMobileNetV2FT20-07-0.8704.keras',\n",
              " 'modelMobileNetV2FT20-08-0.8721.keras',\n",
              " 'modelMobileNetV2FT20-09-0.8774.keras',\n",
              " 'modelMobileNetV2FT20-10-0.8797.keras',\n",
              " 'modelMobileNetV2FT20-11-0.8807.keras',\n",
              " 'modelMobileNetV2FT20-12-0.8820.keras',\n",
              " 'modelMobileNetV2FT20-13-0.8822.keras',\n",
              " 'modelMobileNetV2FT20-14-0.8833.keras',\n",
              " 'modelMobileNetV2FT20-15-0.8838.keras',\n",
              " 'modelMobileNetV2FT20-16-0.8851.keras',\n",
              " 'modelMobileNetV2FT20-18-0.8858.keras',\n",
              " 'modelMobileNetV2FT20-19-0.8859.keras',\n",
              " 'modelMobileNetV2FT20-21-0.8876.keras',\n",
              " 'modelMobileNetV2FT20-23-0.8879.keras',\n",
              " 'modelMobileNetV2FT20-24-0.8880.keras',\n",
              " 'modelMobileNetV2FT20-26-0.8882.keras',\n",
              " 'modelMobileNetV2FT20-27-0.8887.keras',\n",
              " 'modelMobileNetV2FT20-31-0.8888.keras',\n",
              " 'modelMobileNetV2FT20-32-0.8891.keras',\n",
              " 'modelMobileNetV2FT20-33-0.8892.keras',\n",
              " 'modelMobileNetV2FT20-36-0.8901.keras',\n",
              " 'modelMobileNetV2FT20-47-0.8905.keras',\n",
              " 'modelMobileNetV2FT20-54-0.8907.keras',\n",
              " 'modelMobileNetV2FT20-57-0.8908.keras',\n",
              " 'modelMobileNetV2FT20-58-0.8911.keras',\n",
              " 'modelMobileNetV2FT20-62-0.8914.keras',\n",
              " 'modelMobileNetV2FT20-64-0.8916.keras',\n",
              " 'modelMobileNetV2FT20-66-0.8918.keras',\n",
              " 'modelMobileNetV2FT20-68-0.8924.keras',\n",
              " 'modelResNet50_FT20-01-0.8026.keras',\n",
              " 'modelResNet50_FT20-03-0.8136.keras',\n",
              " 'modelResNet50_FT20-08-0.8170.keras',\n",
              " 'modelResNet50_FT20-20-0.8295.keras',\n",
              " 'modelResNet50_FT20-24-0.8329.keras',\n",
              " 'modelResNet50_FT20-44-0.8339.keras',\n",
              " 'model_AlexNet-86-0.8629.keras']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(model_dir) if isfile(join(model_dir, f))]\n",
        "onlyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 3,038,593\n",
            "Non-trainable params: 6,359,744\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "#loaded_model = load_model(os.path.join('checkpoints',best_model_file))\n",
        "loaded_model = load_model('modelDenseNetFT50-99-0.9003.keras') \n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "r_Nq7Xip7rrJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "tgHLiCoC-6Jt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "17/60 [=======>......................] - ETA: 12s - loss: 3.0493 - accuracy: 0.8941"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[67], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m      2\u001b[0m         test_dir,\n\u001b[0;32m      3\u001b[0m         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m      4\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mTrainingConfig\u001b[38;5;241m.\u001b[39mEPOCHS,\n\u001b[0;32m      5\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# steps_per_epoch * epochs\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest acc:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_loss)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.EPOCHS,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = loaded_model.evaluate(test_generator, steps=len(test_generator))  # steps_per_epoch * epochs\n",
        "print('test acc:', test_acc)\n",
        "print('test loss:', test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 20.070415258407593 Training set > seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s Training set > seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize lists to collect true labels and predictions\n",
        "true_labels = []\n",
        "predicted_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 93ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 99ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 94ms/step\n",
            "4/4 [==============================] - 0s 93ms/step\n",
            "4/4 [==============================] - 0s 98ms/step\n",
            "4/4 [==============================] - 0s 99ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 99ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 94ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 97ms/step\n",
            "4/4 [==============================] - 0s 98ms/step\n",
            "4/4 [==============================] - 0s 95ms/step\n",
            "4/4 [==============================] - 0s 97ms/step\n",
            "4/4 [==============================] - 0s 98ms/step\n",
            "4/4 [==============================] - 0s 97ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 93ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n"
          ]
        }
      ],
      "source": [
        "for _ in range(len(test_generator)):\n",
        "    X, y = next(test_generator)\n",
        "\n",
        "    yhat = modelPreTMob.predict(X)\n",
        "    \n",
        "    y_true_batch = y # Labels\n",
        "    \n",
        "    # Convert probabilities to class labels using a threshold of 0.5\n",
        "    y_pred_batch = (yhat > 0.5).astype(int)\n",
        "\n",
        "    # Append the true labels and predictions for this batch to the lists\n",
        "    true_labels.extend(y_true_batch)\n",
        "    predicted_labels.extend(y_pred_batch)\n",
        "\n",
        "    if len(true_labels) >= test_generator.n:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2640,  360],\n",
              "       [ 252, 2748]], dtype=int64)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the confusion matrix\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm/cm_sum.astype(float), display_labels=['Ads', 'non-Ads'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.899803536345776"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "f1_score(true_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8841698841698842"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.916"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.898000\n"
          ]
        }
      ],
      "source": [
        "# ROC AUC\n",
        "auc = roc_auc_score(true_labels, predicted_labels)\n",
        "print('ROC AUC: %f' % auc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
