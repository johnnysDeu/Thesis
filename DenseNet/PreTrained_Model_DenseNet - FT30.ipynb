{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DenseNet no fine tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this run for the MobileNet, we froze all layers and added two dense layers after the conv_base.\n",
        "\n",
        "Results>\n",
        "\n",
        "Best Epoch: 97\n",
        "\n",
        "test acc:  0.8985\n",
        "\n",
        "test loss: 3.03835\n",
        "\n",
        "f1_score: 0.89980\n",
        "\n",
        "Precision: 0.8841\n",
        "\n",
        "Recall: 0.916\n",
        "\n",
        "ROC AUC: 0.8980\n",
        "\n",
        "---Training 100 Epochs: seconds --- 20374 s\n",
        "---Inferense (6000 images):  seconds --- 20.07 s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9F-3tLoS-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install \"tensorflow<2.11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Q0sXDdr-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ze2HI0C1-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eHaZm8sS-6Jk"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip list\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VTJsjK8k-6Jl"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pc4Ak-MX-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9qmltHoh-6Jl"
      },
      "outputs": [],
      "source": [
        "# add headings with ##(space) on the markdowns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oefqb7pK-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflor keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9_5zqcvh-6Jl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp9-KNO_XLJk",
        "outputId": "6744d109-58a8-4e55-860f-55eb54942aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Aug  1 07:37:21 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1660 ...  WDDM  | 00000000:2D:00.0  On |                  N/A |\n",
            "|  0%   43C    P0              39W / 125W |    500MiB /  6144MiB |      6%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1060    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      6376    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      7596    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A      7908    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     10784    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     12588    C+G   ...n\\126.0.2592.113\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     12832    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     12944    C+G   ...e Stream\\94.0.1.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A     14304    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A     14464    C+G   ...n\\126.0.2592.113\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     14788    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     20672    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
            "|    0   N/A  N/A     22224    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     22452    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A     22616    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     23268    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     23376    C+G   ...am Files\\CyberGhost 8\\Dashboard.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkjlmr5C-6Jl",
        "outputId": "ee4947bd-e593-4a95-d056-cd5c5a96edb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig6dym2M-6Jm",
        "outputId": "9fc23f8a-8818-4670-8a29-5ad344823bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3w44-mIA-6Jm"
      },
      "outputs": [],
      "source": [
        "#! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TuXlkzYf-6Jm"
      },
      "outputs": [],
      "source": [
        "#!pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3sJDXlu-6Jm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-2RGi19W-6Jm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NqDqKYkQ-6Jm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingConfig:\n",
        "    BATCH_SIZE:       int   = 64\n",
        "    EPOCHS:           int   = 100\n",
        "    LEARNING_RATE:    float = 0.001\n",
        "    DROPOUT:          float = 0.5\n",
        "    LAYERS_FINE_TUNE: int   = 32\n",
        "    EPSILON:          float = 1e-07\n",
        "    MOMENTUM:         float = 0.9   \n",
        "    WEIGHT_DECAY:     float = 0.0005 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ0UVyCQ-6Jq"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = r\"C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\READY_BALANCED_SAME_SIZE_Random_Split\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knV1jDUD-6Jq",
        "outputId": "50f1446d-6355-4acd-f509-c5440328e53e"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hf-N_1PI-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\train\\\\Ads'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Ads_dir = os.path.join(train_dir, 'Ads')\n",
        "train_sample_dir = os.path.join(train_dir, 'Sample')\n",
        "train_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4lk-PK-6Jq",
        "outputId": "d9fbbdec-e425-4bd2-af75-32f3fbb86936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\validation\\\\Ads'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_Ads_dir = os.path.join(validation_dir, 'Ads')\n",
        "validation_sample_dir = os.path.join(validation_dir, 'Sample')\n",
        "validation_Ads_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JwHehlf4-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\test\\\\Ads'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Ads_dir = os.path.join(test_dir, 'Ads')\n",
        "test_sample_dir = os.path.join(test_dir, 'Sample')\n",
        "test_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fbi_AoAO-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training Ads images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training Ads images:', len(os.listdir(train_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h4bgQrIL-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training sample images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training sample images:', len(os.listdir(train_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YHrO9Y-6Jq",
        "outputId": "15bf628d-bf34-4ce7-ad11-fe568bf61432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation Ads images: 3650\n"
          ]
        }
      ],
      "source": [
        "print('total validation Ads images:', len(os.listdir(validation_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation sample images: 3950\n"
          ]
        }
      ],
      "source": [
        "print('total validation sample images:', len(os.listdir(validation_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test Ads images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test Ads images:', len(os.listdir(test_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test sample images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test sample images:', len(os.listdir(test_sample_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using data augmentation/ datagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "from tensorflow.keras.utils import img_to_array, array_to_img,  load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for color augmentation\n",
        "def color_jitter(image):\n",
        "    image = ImageEnhance.Brightness(image).enhance(np.random.uniform(0.4, 1.6)) # from -60% to +60%\n",
        "    image = ImageEnhance.Contrast(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    image = ImageEnhance.Color(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for ImageDataGenerator\n",
        "def custom_preprocessing_function(image):\n",
        "    # Convert array to PIL image\n",
        "    image = array_to_img(image)\n",
        "    # Apply color jitter\n",
        "    image = color_jitter(image)\n",
        "    # Convert PIL image back to array\n",
        "    image = img_to_array(image)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 images belonging to 2 classes.\n",
            "Found 7600 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "## with Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=custom_preprocessing_function)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretrained Model Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l38QgkUe-6Js"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4AL2-e8-6Js"
      },
      "source": [
        "# Appling a Pre-trained CNN on our Dataset for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcDjEV1-6Jt"
      },
      "source": [
        "The MobileNet model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OcyKdKno-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras.applications import DenseNet121\n",
        "\n",
        "conv_base = DenseNet121(weights='imagenet',\n",
        "                 include_top=False,\n",
        "                 input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRiAZIlI-6Jt",
        "outputId": "9254a8c6-9f28-4ea9-9b11-6553544bb4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVx8qd9U-6Jt"
      },
      "source": [
        "We will add a dense layer after our conv_base NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NwbCTdFB-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, AveragePooling2D\n",
        "\n",
        "modelPreTMob = models.Sequential()\n",
        "modelPreTMob.add(conv_base)\n",
        "\n",
        "modelPreTMob.add(layers.AveragePooling2D())\n",
        "modelPreTMob.add(layers.Flatten())\n",
        "modelPreTMob.add(layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "modelPreTMob.add(BatchNormalization())\n",
        "modelPreTMob.add(layers.Dropout(TrainingConfig.DROPOUT))\n",
        "modelPreTMob.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULwwwLKQ-6Jt",
        "outputId": "bca81ce0-c589-438d-d7f7-ddc78c5df1fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 9,314,177\n",
            "Non-trainable params: 84,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 True\n",
            "1 zero_padding2d True\n",
            "2 conv1/conv True\n",
            "3 conv1/bn True\n",
            "4 conv1/relu True\n",
            "5 zero_padding2d_1 True\n",
            "6 pool1 True\n",
            "7 conv2_block1_0_bn True\n",
            "8 conv2_block1_0_relu True\n",
            "9 conv2_block1_1_conv True\n",
            "10 conv2_block1_1_bn True\n",
            "11 conv2_block1_1_relu True\n",
            "12 conv2_block1_2_conv True\n",
            "13 conv2_block1_concat True\n",
            "14 conv2_block2_0_bn True\n",
            "15 conv2_block2_0_relu True\n",
            "16 conv2_block2_1_conv True\n",
            "17 conv2_block2_1_bn True\n",
            "18 conv2_block2_1_relu True\n",
            "19 conv2_block2_2_conv True\n",
            "20 conv2_block2_concat True\n",
            "21 conv2_block3_0_bn True\n",
            "22 conv2_block3_0_relu True\n",
            "23 conv2_block3_1_conv True\n",
            "24 conv2_block3_1_bn True\n",
            "25 conv2_block3_1_relu True\n",
            "26 conv2_block3_2_conv True\n",
            "27 conv2_block3_concat True\n",
            "28 conv2_block4_0_bn True\n",
            "29 conv2_block4_0_relu True\n",
            "30 conv2_block4_1_conv True\n",
            "31 conv2_block4_1_bn True\n",
            "32 conv2_block4_1_relu True\n",
            "33 conv2_block4_2_conv True\n",
            "34 conv2_block4_concat True\n",
            "35 conv2_block5_0_bn True\n",
            "36 conv2_block5_0_relu True\n",
            "37 conv2_block5_1_conv True\n",
            "38 conv2_block5_1_bn True\n",
            "39 conv2_block5_1_relu True\n",
            "40 conv2_block5_2_conv True\n",
            "41 conv2_block5_concat True\n",
            "42 conv2_block6_0_bn True\n",
            "43 conv2_block6_0_relu True\n",
            "44 conv2_block6_1_conv True\n",
            "45 conv2_block6_1_bn True\n",
            "46 conv2_block6_1_relu True\n",
            "47 conv2_block6_2_conv True\n",
            "48 conv2_block6_concat True\n",
            "49 pool2_bn True\n",
            "50 pool2_relu True\n",
            "51 pool2_conv True\n",
            "52 pool2_pool True\n",
            "53 conv3_block1_0_bn True\n",
            "54 conv3_block1_0_relu True\n",
            "55 conv3_block1_1_conv True\n",
            "56 conv3_block1_1_bn True\n",
            "57 conv3_block1_1_relu True\n",
            "58 conv3_block1_2_conv True\n",
            "59 conv3_block1_concat True\n",
            "60 conv3_block2_0_bn True\n",
            "61 conv3_block2_0_relu True\n",
            "62 conv3_block2_1_conv True\n",
            "63 conv3_block2_1_bn True\n",
            "64 conv3_block2_1_relu True\n",
            "65 conv3_block2_2_conv True\n",
            "66 conv3_block2_concat True\n",
            "67 conv3_block3_0_bn True\n",
            "68 conv3_block3_0_relu True\n",
            "69 conv3_block3_1_conv True\n",
            "70 conv3_block3_1_bn True\n",
            "71 conv3_block3_1_relu True\n",
            "72 conv3_block3_2_conv True\n",
            "73 conv3_block3_concat True\n",
            "74 conv3_block4_0_bn True\n",
            "75 conv3_block4_0_relu True\n",
            "76 conv3_block4_1_conv True\n",
            "77 conv3_block4_1_bn True\n",
            "78 conv3_block4_1_relu True\n",
            "79 conv3_block4_2_conv True\n",
            "80 conv3_block4_concat True\n",
            "81 conv3_block5_0_bn True\n",
            "82 conv3_block5_0_relu True\n",
            "83 conv3_block5_1_conv True\n",
            "84 conv3_block5_1_bn True\n",
            "85 conv3_block5_1_relu True\n",
            "86 conv3_block5_2_conv True\n",
            "87 conv3_block5_concat True\n",
            "88 conv3_block6_0_bn True\n",
            "89 conv3_block6_0_relu True\n",
            "90 conv3_block6_1_conv True\n",
            "91 conv3_block6_1_bn True\n",
            "92 conv3_block6_1_relu True\n",
            "93 conv3_block6_2_conv True\n",
            "94 conv3_block6_concat True\n",
            "95 conv3_block7_0_bn True\n",
            "96 conv3_block7_0_relu True\n",
            "97 conv3_block7_1_conv True\n",
            "98 conv3_block7_1_bn True\n",
            "99 conv3_block7_1_relu True\n",
            "100 conv3_block7_2_conv True\n",
            "101 conv3_block7_concat True\n",
            "102 conv3_block8_0_bn True\n",
            "103 conv3_block8_0_relu True\n",
            "104 conv3_block8_1_conv True\n",
            "105 conv3_block8_1_bn True\n",
            "106 conv3_block8_1_relu True\n",
            "107 conv3_block8_2_conv True\n",
            "108 conv3_block8_concat True\n",
            "109 conv3_block9_0_bn True\n",
            "110 conv3_block9_0_relu True\n",
            "111 conv3_block9_1_conv True\n",
            "112 conv3_block9_1_bn True\n",
            "113 conv3_block9_1_relu True\n",
            "114 conv3_block9_2_conv True\n",
            "115 conv3_block9_concat True\n",
            "116 conv3_block10_0_bn True\n",
            "117 conv3_block10_0_relu True\n",
            "118 conv3_block10_1_conv True\n",
            "119 conv3_block10_1_bn True\n",
            "120 conv3_block10_1_relu True\n",
            "121 conv3_block10_2_conv True\n",
            "122 conv3_block10_concat True\n",
            "123 conv3_block11_0_bn True\n",
            "124 conv3_block11_0_relu True\n",
            "125 conv3_block11_1_conv True\n",
            "126 conv3_block11_1_bn True\n",
            "127 conv3_block11_1_relu True\n",
            "128 conv3_block11_2_conv True\n",
            "129 conv3_block11_concat True\n",
            "130 conv3_block12_0_bn True\n",
            "131 conv3_block12_0_relu True\n",
            "132 conv3_block12_1_conv True\n",
            "133 conv3_block12_1_bn True\n",
            "134 conv3_block12_1_relu True\n",
            "135 conv3_block12_2_conv True\n",
            "136 conv3_block12_concat True\n",
            "137 pool3_bn True\n",
            "138 pool3_relu True\n",
            "139 pool3_conv True\n",
            "140 pool3_pool True\n",
            "141 conv4_block1_0_bn True\n",
            "142 conv4_block1_0_relu True\n",
            "143 conv4_block1_1_conv True\n",
            "144 conv4_block1_1_bn True\n",
            "145 conv4_block1_1_relu True\n",
            "146 conv4_block1_2_conv True\n",
            "147 conv4_block1_concat True\n",
            "148 conv4_block2_0_bn True\n",
            "149 conv4_block2_0_relu True\n",
            "150 conv4_block2_1_conv True\n",
            "151 conv4_block2_1_bn True\n",
            "152 conv4_block2_1_relu True\n",
            "153 conv4_block2_2_conv True\n",
            "154 conv4_block2_concat True\n",
            "155 conv4_block3_0_bn True\n",
            "156 conv4_block3_0_relu True\n",
            "157 conv4_block3_1_conv True\n",
            "158 conv4_block3_1_bn True\n",
            "159 conv4_block3_1_relu True\n",
            "160 conv4_block3_2_conv True\n",
            "161 conv4_block3_concat True\n",
            "162 conv4_block4_0_bn True\n",
            "163 conv4_block4_0_relu True\n",
            "164 conv4_block4_1_conv True\n",
            "165 conv4_block4_1_bn True\n",
            "166 conv4_block4_1_relu True\n",
            "167 conv4_block4_2_conv True\n",
            "168 conv4_block4_concat True\n",
            "169 conv4_block5_0_bn True\n",
            "170 conv4_block5_0_relu True\n",
            "171 conv4_block5_1_conv True\n",
            "172 conv4_block5_1_bn True\n",
            "173 conv4_block5_1_relu True\n",
            "174 conv4_block5_2_conv True\n",
            "175 conv4_block5_concat True\n",
            "176 conv4_block6_0_bn True\n",
            "177 conv4_block6_0_relu True\n",
            "178 conv4_block6_1_conv True\n",
            "179 conv4_block6_1_bn True\n",
            "180 conv4_block6_1_relu True\n",
            "181 conv4_block6_2_conv True\n",
            "182 conv4_block6_concat True\n",
            "183 conv4_block7_0_bn True\n",
            "184 conv4_block7_0_relu True\n",
            "185 conv4_block7_1_conv True\n",
            "186 conv4_block7_1_bn True\n",
            "187 conv4_block7_1_relu True\n",
            "188 conv4_block7_2_conv True\n",
            "189 conv4_block7_concat True\n",
            "190 conv4_block8_0_bn True\n",
            "191 conv4_block8_0_relu True\n",
            "192 conv4_block8_1_conv True\n",
            "193 conv4_block8_1_bn True\n",
            "194 conv4_block8_1_relu True\n",
            "195 conv4_block8_2_conv True\n",
            "196 conv4_block8_concat True\n",
            "197 conv4_block9_0_bn True\n",
            "198 conv4_block9_0_relu True\n",
            "199 conv4_block9_1_conv True\n",
            "200 conv4_block9_1_bn True\n",
            "201 conv4_block9_1_relu True\n",
            "202 conv4_block9_2_conv True\n",
            "203 conv4_block9_concat True\n",
            "204 conv4_block10_0_bn True\n",
            "205 conv4_block10_0_relu True\n",
            "206 conv4_block10_1_conv True\n",
            "207 conv4_block10_1_bn True\n",
            "208 conv4_block10_1_relu True\n",
            "209 conv4_block10_2_conv True\n",
            "210 conv4_block10_concat True\n",
            "211 conv4_block11_0_bn True\n",
            "212 conv4_block11_0_relu True\n",
            "213 conv4_block11_1_conv True\n",
            "214 conv4_block11_1_bn True\n",
            "215 conv4_block11_1_relu True\n",
            "216 conv4_block11_2_conv True\n",
            "217 conv4_block11_concat True\n",
            "218 conv4_block12_0_bn True\n",
            "219 conv4_block12_0_relu True\n",
            "220 conv4_block12_1_conv True\n",
            "221 conv4_block12_1_bn True\n",
            "222 conv4_block12_1_relu True\n",
            "223 conv4_block12_2_conv True\n",
            "224 conv4_block12_concat True\n",
            "225 conv4_block13_0_bn True\n",
            "226 conv4_block13_0_relu True\n",
            "227 conv4_block13_1_conv True\n",
            "228 conv4_block13_1_bn True\n",
            "229 conv4_block13_1_relu True\n",
            "230 conv4_block13_2_conv True\n",
            "231 conv4_block13_concat True\n",
            "232 conv4_block14_0_bn True\n",
            "233 conv4_block14_0_relu True\n",
            "234 conv4_block14_1_conv True\n",
            "235 conv4_block14_1_bn True\n",
            "236 conv4_block14_1_relu True\n",
            "237 conv4_block14_2_conv True\n",
            "238 conv4_block14_concat True\n",
            "239 conv4_block15_0_bn True\n",
            "240 conv4_block15_0_relu True\n",
            "241 conv4_block15_1_conv True\n",
            "242 conv4_block15_1_bn True\n",
            "243 conv4_block15_1_relu True\n",
            "244 conv4_block15_2_conv True\n",
            "245 conv4_block15_concat True\n",
            "246 conv4_block16_0_bn True\n",
            "247 conv4_block16_0_relu True\n",
            "248 conv4_block16_1_conv True\n",
            "249 conv4_block16_1_bn True\n",
            "250 conv4_block16_1_relu True\n",
            "251 conv4_block16_2_conv True\n",
            "252 conv4_block16_concat True\n",
            "253 conv4_block17_0_bn True\n",
            "254 conv4_block17_0_relu True\n",
            "255 conv4_block17_1_conv True\n",
            "256 conv4_block17_1_bn True\n",
            "257 conv4_block17_1_relu True\n",
            "258 conv4_block17_2_conv True\n",
            "259 conv4_block17_concat True\n",
            "260 conv4_block18_0_bn True\n",
            "261 conv4_block18_0_relu True\n",
            "262 conv4_block18_1_conv True\n",
            "263 conv4_block18_1_bn True\n",
            "264 conv4_block18_1_relu True\n",
            "265 conv4_block18_2_conv True\n",
            "266 conv4_block18_concat True\n",
            "267 conv4_block19_0_bn True\n",
            "268 conv4_block19_0_relu True\n",
            "269 conv4_block19_1_conv True\n",
            "270 conv4_block19_1_bn True\n",
            "271 conv4_block19_1_relu True\n",
            "272 conv4_block19_2_conv True\n",
            "273 conv4_block19_concat True\n",
            "274 conv4_block20_0_bn True\n",
            "275 conv4_block20_0_relu True\n",
            "276 conv4_block20_1_conv True\n",
            "277 conv4_block20_1_bn True\n",
            "278 conv4_block20_1_relu True\n",
            "279 conv4_block20_2_conv True\n",
            "280 conv4_block20_concat True\n",
            "281 conv4_block21_0_bn True\n",
            "282 conv4_block21_0_relu True\n",
            "283 conv4_block21_1_conv True\n",
            "284 conv4_block21_1_bn True\n",
            "285 conv4_block21_1_relu True\n",
            "286 conv4_block21_2_conv True\n",
            "287 conv4_block21_concat True\n",
            "288 conv4_block22_0_bn True\n",
            "289 conv4_block22_0_relu True\n",
            "290 conv4_block22_1_conv True\n",
            "291 conv4_block22_1_bn True\n",
            "292 conv4_block22_1_relu True\n",
            "293 conv4_block22_2_conv True\n",
            "294 conv4_block22_concat True\n",
            "295 conv4_block23_0_bn True\n",
            "296 conv4_block23_0_relu True\n",
            "297 conv4_block23_1_conv True\n",
            "298 conv4_block23_1_bn True\n",
            "299 conv4_block23_1_relu True\n",
            "300 conv4_block23_2_conv True\n",
            "301 conv4_block23_concat True\n",
            "302 conv4_block24_0_bn True\n",
            "303 conv4_block24_0_relu True\n",
            "304 conv4_block24_1_conv True\n",
            "305 conv4_block24_1_bn True\n",
            "306 conv4_block24_1_relu True\n",
            "307 conv4_block24_2_conv True\n",
            "308 conv4_block24_concat True\n",
            "309 pool4_bn True\n",
            "310 pool4_relu True\n",
            "311 pool4_conv True\n",
            "312 pool4_pool True\n",
            "313 conv5_block1_0_bn True\n",
            "314 conv5_block1_0_relu True\n",
            "315 conv5_block1_1_conv True\n",
            "316 conv5_block1_1_bn True\n",
            "317 conv5_block1_1_relu True\n",
            "318 conv5_block1_2_conv True\n",
            "319 conv5_block1_concat True\n",
            "320 conv5_block2_0_bn True\n",
            "321 conv5_block2_0_relu True\n",
            "322 conv5_block2_1_conv True\n",
            "323 conv5_block2_1_bn True\n",
            "324 conv5_block2_1_relu True\n",
            "325 conv5_block2_2_conv True\n",
            "326 conv5_block2_concat True\n",
            "327 conv5_block3_0_bn True\n",
            "328 conv5_block3_0_relu True\n",
            "329 conv5_block3_1_conv True\n",
            "330 conv5_block3_1_bn True\n",
            "331 conv5_block3_1_relu True\n",
            "332 conv5_block3_2_conv True\n",
            "333 conv5_block3_concat True\n",
            "334 conv5_block4_0_bn True\n",
            "335 conv5_block4_0_relu True\n",
            "336 conv5_block4_1_conv True\n",
            "337 conv5_block4_1_bn True\n",
            "338 conv5_block4_1_relu True\n",
            "339 conv5_block4_2_conv True\n",
            "340 conv5_block4_concat True\n",
            "341 conv5_block5_0_bn True\n",
            "342 conv5_block5_0_relu True\n",
            "343 conv5_block5_1_conv True\n",
            "344 conv5_block5_1_bn True\n",
            "345 conv5_block5_1_relu True\n",
            "346 conv5_block5_2_conv True\n",
            "347 conv5_block5_concat True\n",
            "348 conv5_block6_0_bn True\n",
            "349 conv5_block6_0_relu True\n",
            "350 conv5_block6_1_conv True\n",
            "351 conv5_block6_1_bn True\n",
            "352 conv5_block6_1_relu True\n",
            "353 conv5_block6_2_conv True\n",
            "354 conv5_block6_concat True\n",
            "355 conv5_block7_0_bn True\n",
            "356 conv5_block7_0_relu True\n",
            "357 conv5_block7_1_conv True\n",
            "358 conv5_block7_1_bn True\n",
            "359 conv5_block7_1_relu True\n",
            "360 conv5_block7_2_conv True\n",
            "361 conv5_block7_concat True\n",
            "362 conv5_block8_0_bn True\n",
            "363 conv5_block8_0_relu True\n",
            "364 conv5_block8_1_conv True\n",
            "365 conv5_block8_1_bn True\n",
            "366 conv5_block8_1_relu True\n",
            "367 conv5_block8_2_conv True\n",
            "368 conv5_block8_concat True\n",
            "369 conv5_block9_0_bn True\n",
            "370 conv5_block9_0_relu True\n",
            "371 conv5_block9_1_conv True\n",
            "372 conv5_block9_1_bn True\n",
            "373 conv5_block9_1_relu True\n",
            "374 conv5_block9_2_conv True\n",
            "375 conv5_block9_concat True\n",
            "376 conv5_block10_0_bn True\n",
            "377 conv5_block10_0_relu True\n",
            "378 conv5_block10_1_conv True\n",
            "379 conv5_block10_1_bn True\n",
            "380 conv5_block10_1_relu True\n",
            "381 conv5_block10_2_conv True\n",
            "382 conv5_block10_concat True\n",
            "383 conv5_block11_0_bn True\n",
            "384 conv5_block11_0_relu True\n",
            "385 conv5_block11_1_conv True\n",
            "386 conv5_block11_1_bn True\n",
            "387 conv5_block11_1_relu True\n",
            "388 conv5_block11_2_conv True\n",
            "389 conv5_block11_concat True\n",
            "390 conv5_block12_0_bn True\n",
            "391 conv5_block12_0_relu True\n",
            "392 conv5_block12_1_conv True\n",
            "393 conv5_block12_1_bn True\n",
            "394 conv5_block12_1_relu True\n",
            "395 conv5_block12_2_conv True\n",
            "396 conv5_block12_concat True\n",
            "397 conv5_block13_0_bn True\n",
            "398 conv5_block13_0_relu True\n",
            "399 conv5_block13_1_conv True\n",
            "400 conv5_block13_1_bn True\n",
            "401 conv5_block13_1_relu True\n",
            "402 conv5_block13_2_conv True\n",
            "403 conv5_block13_concat True\n",
            "404 conv5_block14_0_bn True\n",
            "405 conv5_block14_0_relu True\n",
            "406 conv5_block14_1_conv True\n",
            "407 conv5_block14_1_bn True\n",
            "408 conv5_block14_1_relu True\n",
            "409 conv5_block14_2_conv True\n",
            "410 conv5_block14_concat True\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the number of layers to fine tune at the end of the convolutional base.\n",
        "num_layers_fine_tune = TrainingConfig.LAYERS_FINE_TUNE\n",
        "num_layers = len(conv_base.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg5O_dq-6Jt",
        "outputId": "0b8e8703-9f13-4415-d6a7-fc5af46bc1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 368\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'before freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FREEZING LAYER: <keras.engine.input_layer.InputLayer object at 0x0000023461F4ACD0>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x0000023461F809A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023461F672E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023461F6F2E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023461F67C10>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x0000023461F76130>\n",
            "FREEZING LAYER: <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000023461F7B6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023461F7B2E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023461F7B160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023461F87D30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234681CC580>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023461F87880>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681CFE50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234681DC790>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234681DCD60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234681D29D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681E5550>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234681E9A60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023461F87A60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681DCEB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234681D2CA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234681F3D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234681EBEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681FB730>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C00490>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234681FB040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681F3100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C0B820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C0B220>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C0BC70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C14970>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C19CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C14190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C0B3A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C087C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C1D040>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C22F40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C2CA00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C2FEB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C2C100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C1D670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C22BB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C35FD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C35F70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C43BE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C49E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C43430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C35460>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C00760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234681F3970>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C14550>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681DC220>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x0000023472C4EE80>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234681E93A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023461F7BB80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681C8B80>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C54E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234681F3610>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C4ECD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C5AE50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C5AAF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C5A430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C5FE20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C64850>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C5F520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C68EE0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C5A520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C70640>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C57FA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C76D90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C7B070>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C7BD30>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C805E0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C82A90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C82DC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C80370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C933D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C96E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C93370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472C8DCD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472CA47F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CA4DC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C8D550>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CAF5B0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CA6910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CAF0A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CA4220>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472CBF670>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CBFF40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CBFAC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CA47C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C823D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C965E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023461F878E0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472C574C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C0BA60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C080D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CC72E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CC7E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CC45B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CCA730>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472CCC370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CCCF40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CCCEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CD64C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CDBFA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CD6520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CCFF40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472CE6940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CE6E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CE4C40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CE86A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CF23D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CD6310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CE63D0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472CFE790>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CFEEE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CFBF10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806088E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348060CAC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806081C0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CFE400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023472CFB0A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806185B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480615FD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002348061F970>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806273D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480627130>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480618730>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023480632B50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806323D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002348062F370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CFEAF0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C00610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480608760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023472CCAAF0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234681C81F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348063BD30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C686D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480634820>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x0000023480640C70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023480640B20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806400A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480642A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023480644D00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806422E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806341F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023480634760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348064F850>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002348064F8E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480657CD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348065B520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480657310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002348064F400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023480667700>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023480667610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480667520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002348066FDF0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023480673550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023459D17820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480667760>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023459D30670>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806810D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023461F76070>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480688310>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348067AAF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480681F40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480681AF0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002348069A190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348069A2E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002348067AF70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806A0370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806A7EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806A7EB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806A06A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002348067AA00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348066F160>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023480662520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480688820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472CE6820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002348066F9D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480618A30>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002348064F430>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348069AA00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806A02B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806B31C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023480681A90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002348069ADC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806B7AC0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234806B79D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806C2E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806B7D60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806B9F40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806D1C10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806B9DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806D1E50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000023480642B50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806D8EB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806C9E80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806DF040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806B3D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806C2A00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806E8F70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234806D8400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806F1A00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806DFFD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806FA160>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806D1670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806F1FA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806FA700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234806E8EE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB0B220>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806FA340>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806FA6A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB19F40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB0BA60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB11220>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234806DFCD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806D1A30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB190D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806FA550>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB02DF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806DF3D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000023480667640>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB111F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB20D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472CFBC70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB20490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB11A60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806C9370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB20850>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB26AC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806B7190>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB26E50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB390A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB41CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB41CA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB41F10>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB32C10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x00000234806FA0D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB39F70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB4F0D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB28880>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB47F10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB4F700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB413D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB390D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB471F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB673A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB70EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB60040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB4F100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB4FF70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB57880>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB60370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB4FFA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB88160>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB79BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB79FD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB4FEB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB41D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB88310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB70D30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB79910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB4F460>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234806D8C40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB32DC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB92D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB7F940>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB97040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB265E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB41430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB99EB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB92490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BBA1F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB97EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBA8070>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB20FA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBA1EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBADFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BBA1520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB99550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBA8250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBBF190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB99520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBB8430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBAD670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BBADF40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BBA8F40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBB8310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBAD220>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BBDE130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBCFB80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBC86A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BBE9400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BBE9610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBDE100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBBF7F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BBF89D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBF8190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBEFCD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BBBFF10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BBB8F70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBF8430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBDE0A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB39400>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBBF5B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BB41610>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BBA1C10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB57790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB99BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C206040>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000002359C209D00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002348061F460>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBEF9A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C2066D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB92CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB92DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C20FA00>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359BB92820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C21EA60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB57B50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C21EB50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2268E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BB97E50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C226BE0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C2267F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C238250>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C226B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C238B20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C23F310>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C22DDC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C238C40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C23F910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C250100>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C23FCA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C22D6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C258B50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C23FD00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C258370>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C260910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C260130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C258DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C2581F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C21E910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C21E760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C20F040>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C244940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359BB28B20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C250C40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C215280>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2509D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234806C92E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C26FA30>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C250A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2789D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C260BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359BBADC70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C26F7C0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359BBBF220>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C274B50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C2789A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C28C790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C27EAF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C28C610>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2155B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C27E850>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C294CD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C294880>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2A5370>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C294C70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C274C10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C28CE20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C28C400>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C2ADCA0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C2ADA00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2BE0D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C2ADD90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C2B3A90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2CDC10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C2B3EB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C2CDE50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002359C2D69D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2D61F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002359C2CD0A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002359C2BE9D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002359C2858B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002340CB7E310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681D2400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x00000234681F3910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C3ABE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000023472C3A760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000234681E5EB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000023472C3AC70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x00000234681E5CD0>\n"
          ]
        }
      ],
      "source": [
        "# Freeze the initial layers in the convolutional base.\n",
        "for model_layer in conv_base.layers[:num_layers - num_layers_fine_tune]:\n",
        "    print(f\"FREEZING LAYER: {model_layer}\")\n",
        "    model_layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 zero_padding2d False\n",
            "2 conv1/conv False\n",
            "3 conv1/bn False\n",
            "4 conv1/relu False\n",
            "5 zero_padding2d_1 False\n",
            "6 pool1 False\n",
            "7 conv2_block1_0_bn False\n",
            "8 conv2_block1_0_relu False\n",
            "9 conv2_block1_1_conv False\n",
            "10 conv2_block1_1_bn False\n",
            "11 conv2_block1_1_relu False\n",
            "12 conv2_block1_2_conv False\n",
            "13 conv2_block1_concat False\n",
            "14 conv2_block2_0_bn False\n",
            "15 conv2_block2_0_relu False\n",
            "16 conv2_block2_1_conv False\n",
            "17 conv2_block2_1_bn False\n",
            "18 conv2_block2_1_relu False\n",
            "19 conv2_block2_2_conv False\n",
            "20 conv2_block2_concat False\n",
            "21 conv2_block3_0_bn False\n",
            "22 conv2_block3_0_relu False\n",
            "23 conv2_block3_1_conv False\n",
            "24 conv2_block3_1_bn False\n",
            "25 conv2_block3_1_relu False\n",
            "26 conv2_block3_2_conv False\n",
            "27 conv2_block3_concat False\n",
            "28 conv2_block4_0_bn False\n",
            "29 conv2_block4_0_relu False\n",
            "30 conv2_block4_1_conv False\n",
            "31 conv2_block4_1_bn False\n",
            "32 conv2_block4_1_relu False\n",
            "33 conv2_block4_2_conv False\n",
            "34 conv2_block4_concat False\n",
            "35 conv2_block5_0_bn False\n",
            "36 conv2_block5_0_relu False\n",
            "37 conv2_block5_1_conv False\n",
            "38 conv2_block5_1_bn False\n",
            "39 conv2_block5_1_relu False\n",
            "40 conv2_block5_2_conv False\n",
            "41 conv2_block5_concat False\n",
            "42 conv2_block6_0_bn False\n",
            "43 conv2_block6_0_relu False\n",
            "44 conv2_block6_1_conv False\n",
            "45 conv2_block6_1_bn False\n",
            "46 conv2_block6_1_relu False\n",
            "47 conv2_block6_2_conv False\n",
            "48 conv2_block6_concat False\n",
            "49 pool2_bn False\n",
            "50 pool2_relu False\n",
            "51 pool2_conv False\n",
            "52 pool2_pool False\n",
            "53 conv3_block1_0_bn False\n",
            "54 conv3_block1_0_relu False\n",
            "55 conv3_block1_1_conv False\n",
            "56 conv3_block1_1_bn False\n",
            "57 conv3_block1_1_relu False\n",
            "58 conv3_block1_2_conv False\n",
            "59 conv3_block1_concat False\n",
            "60 conv3_block2_0_bn False\n",
            "61 conv3_block2_0_relu False\n",
            "62 conv3_block2_1_conv False\n",
            "63 conv3_block2_1_bn False\n",
            "64 conv3_block2_1_relu False\n",
            "65 conv3_block2_2_conv False\n",
            "66 conv3_block2_concat False\n",
            "67 conv3_block3_0_bn False\n",
            "68 conv3_block3_0_relu False\n",
            "69 conv3_block3_1_conv False\n",
            "70 conv3_block3_1_bn False\n",
            "71 conv3_block3_1_relu False\n",
            "72 conv3_block3_2_conv False\n",
            "73 conv3_block3_concat False\n",
            "74 conv3_block4_0_bn False\n",
            "75 conv3_block4_0_relu False\n",
            "76 conv3_block4_1_conv False\n",
            "77 conv3_block4_1_bn False\n",
            "78 conv3_block4_1_relu False\n",
            "79 conv3_block4_2_conv False\n",
            "80 conv3_block4_concat False\n",
            "81 conv3_block5_0_bn False\n",
            "82 conv3_block5_0_relu False\n",
            "83 conv3_block5_1_conv False\n",
            "84 conv3_block5_1_bn False\n",
            "85 conv3_block5_1_relu False\n",
            "86 conv3_block5_2_conv False\n",
            "87 conv3_block5_concat False\n",
            "88 conv3_block6_0_bn False\n",
            "89 conv3_block6_0_relu False\n",
            "90 conv3_block6_1_conv False\n",
            "91 conv3_block6_1_bn False\n",
            "92 conv3_block6_1_relu False\n",
            "93 conv3_block6_2_conv False\n",
            "94 conv3_block6_concat False\n",
            "95 conv3_block7_0_bn False\n",
            "96 conv3_block7_0_relu False\n",
            "97 conv3_block7_1_conv False\n",
            "98 conv3_block7_1_bn False\n",
            "99 conv3_block7_1_relu False\n",
            "100 conv3_block7_2_conv False\n",
            "101 conv3_block7_concat False\n",
            "102 conv3_block8_0_bn False\n",
            "103 conv3_block8_0_relu False\n",
            "104 conv3_block8_1_conv False\n",
            "105 conv3_block8_1_bn False\n",
            "106 conv3_block8_1_relu False\n",
            "107 conv3_block8_2_conv False\n",
            "108 conv3_block8_concat False\n",
            "109 conv3_block9_0_bn False\n",
            "110 conv3_block9_0_relu False\n",
            "111 conv3_block9_1_conv False\n",
            "112 conv3_block9_1_bn False\n",
            "113 conv3_block9_1_relu False\n",
            "114 conv3_block9_2_conv False\n",
            "115 conv3_block9_concat False\n",
            "116 conv3_block10_0_bn False\n",
            "117 conv3_block10_0_relu False\n",
            "118 conv3_block10_1_conv False\n",
            "119 conv3_block10_1_bn False\n",
            "120 conv3_block10_1_relu False\n",
            "121 conv3_block10_2_conv False\n",
            "122 conv3_block10_concat False\n",
            "123 conv3_block11_0_bn False\n",
            "124 conv3_block11_0_relu False\n",
            "125 conv3_block11_1_conv False\n",
            "126 conv3_block11_1_bn False\n",
            "127 conv3_block11_1_relu False\n",
            "128 conv3_block11_2_conv False\n",
            "129 conv3_block11_concat False\n",
            "130 conv3_block12_0_bn False\n",
            "131 conv3_block12_0_relu False\n",
            "132 conv3_block12_1_conv False\n",
            "133 conv3_block12_1_bn False\n",
            "134 conv3_block12_1_relu False\n",
            "135 conv3_block12_2_conv False\n",
            "136 conv3_block12_concat False\n",
            "137 pool3_bn False\n",
            "138 pool3_relu False\n",
            "139 pool3_conv False\n",
            "140 pool3_pool False\n",
            "141 conv4_block1_0_bn False\n",
            "142 conv4_block1_0_relu False\n",
            "143 conv4_block1_1_conv False\n",
            "144 conv4_block1_1_bn False\n",
            "145 conv4_block1_1_relu False\n",
            "146 conv4_block1_2_conv False\n",
            "147 conv4_block1_concat False\n",
            "148 conv4_block2_0_bn False\n",
            "149 conv4_block2_0_relu False\n",
            "150 conv4_block2_1_conv False\n",
            "151 conv4_block2_1_bn False\n",
            "152 conv4_block2_1_relu False\n",
            "153 conv4_block2_2_conv False\n",
            "154 conv4_block2_concat False\n",
            "155 conv4_block3_0_bn False\n",
            "156 conv4_block3_0_relu False\n",
            "157 conv4_block3_1_conv False\n",
            "158 conv4_block3_1_bn False\n",
            "159 conv4_block3_1_relu False\n",
            "160 conv4_block3_2_conv False\n",
            "161 conv4_block3_concat False\n",
            "162 conv4_block4_0_bn False\n",
            "163 conv4_block4_0_relu False\n",
            "164 conv4_block4_1_conv False\n",
            "165 conv4_block4_1_bn False\n",
            "166 conv4_block4_1_relu False\n",
            "167 conv4_block4_2_conv False\n",
            "168 conv4_block4_concat False\n",
            "169 conv4_block5_0_bn False\n",
            "170 conv4_block5_0_relu False\n",
            "171 conv4_block5_1_conv False\n",
            "172 conv4_block5_1_bn False\n",
            "173 conv4_block5_1_relu False\n",
            "174 conv4_block5_2_conv False\n",
            "175 conv4_block5_concat False\n",
            "176 conv4_block6_0_bn False\n",
            "177 conv4_block6_0_relu False\n",
            "178 conv4_block6_1_conv False\n",
            "179 conv4_block6_1_bn False\n",
            "180 conv4_block6_1_relu False\n",
            "181 conv4_block6_2_conv False\n",
            "182 conv4_block6_concat False\n",
            "183 conv4_block7_0_bn False\n",
            "184 conv4_block7_0_relu False\n",
            "185 conv4_block7_1_conv False\n",
            "186 conv4_block7_1_bn False\n",
            "187 conv4_block7_1_relu False\n",
            "188 conv4_block7_2_conv False\n",
            "189 conv4_block7_concat False\n",
            "190 conv4_block8_0_bn False\n",
            "191 conv4_block8_0_relu False\n",
            "192 conv4_block8_1_conv False\n",
            "193 conv4_block8_1_bn False\n",
            "194 conv4_block8_1_relu False\n",
            "195 conv4_block8_2_conv False\n",
            "196 conv4_block8_concat False\n",
            "197 conv4_block9_0_bn False\n",
            "198 conv4_block9_0_relu False\n",
            "199 conv4_block9_1_conv False\n",
            "200 conv4_block9_1_bn False\n",
            "201 conv4_block9_1_relu False\n",
            "202 conv4_block9_2_conv False\n",
            "203 conv4_block9_concat False\n",
            "204 conv4_block10_0_bn False\n",
            "205 conv4_block10_0_relu False\n",
            "206 conv4_block10_1_conv False\n",
            "207 conv4_block10_1_bn False\n",
            "208 conv4_block10_1_relu False\n",
            "209 conv4_block10_2_conv False\n",
            "210 conv4_block10_concat False\n",
            "211 conv4_block11_0_bn False\n",
            "212 conv4_block11_0_relu False\n",
            "213 conv4_block11_1_conv False\n",
            "214 conv4_block11_1_bn False\n",
            "215 conv4_block11_1_relu False\n",
            "216 conv4_block11_2_conv False\n",
            "217 conv4_block11_concat False\n",
            "218 conv4_block12_0_bn False\n",
            "219 conv4_block12_0_relu False\n",
            "220 conv4_block12_1_conv False\n",
            "221 conv4_block12_1_bn False\n",
            "222 conv4_block12_1_relu False\n",
            "223 conv4_block12_2_conv False\n",
            "224 conv4_block12_concat False\n",
            "225 conv4_block13_0_bn False\n",
            "226 conv4_block13_0_relu False\n",
            "227 conv4_block13_1_conv False\n",
            "228 conv4_block13_1_bn False\n",
            "229 conv4_block13_1_relu False\n",
            "230 conv4_block13_2_conv False\n",
            "231 conv4_block13_concat False\n",
            "232 conv4_block14_0_bn False\n",
            "233 conv4_block14_0_relu False\n",
            "234 conv4_block14_1_conv False\n",
            "235 conv4_block14_1_bn False\n",
            "236 conv4_block14_1_relu False\n",
            "237 conv4_block14_2_conv False\n",
            "238 conv4_block14_concat False\n",
            "239 conv4_block15_0_bn False\n",
            "240 conv4_block15_0_relu False\n",
            "241 conv4_block15_1_conv False\n",
            "242 conv4_block15_1_bn False\n",
            "243 conv4_block15_1_relu False\n",
            "244 conv4_block15_2_conv False\n",
            "245 conv4_block15_concat False\n",
            "246 conv4_block16_0_bn False\n",
            "247 conv4_block16_0_relu False\n",
            "248 conv4_block16_1_conv False\n",
            "249 conv4_block16_1_bn False\n",
            "250 conv4_block16_1_relu False\n",
            "251 conv4_block16_2_conv False\n",
            "252 conv4_block16_concat False\n",
            "253 conv4_block17_0_bn False\n",
            "254 conv4_block17_0_relu False\n",
            "255 conv4_block17_1_conv False\n",
            "256 conv4_block17_1_bn False\n",
            "257 conv4_block17_1_relu False\n",
            "258 conv4_block17_2_conv False\n",
            "259 conv4_block17_concat False\n",
            "260 conv4_block18_0_bn False\n",
            "261 conv4_block18_0_relu False\n",
            "262 conv4_block18_1_conv False\n",
            "263 conv4_block18_1_bn False\n",
            "264 conv4_block18_1_relu False\n",
            "265 conv4_block18_2_conv False\n",
            "266 conv4_block18_concat False\n",
            "267 conv4_block19_0_bn False\n",
            "268 conv4_block19_0_relu False\n",
            "269 conv4_block19_1_conv False\n",
            "270 conv4_block19_1_bn False\n",
            "271 conv4_block19_1_relu False\n",
            "272 conv4_block19_2_conv False\n",
            "273 conv4_block19_concat False\n",
            "274 conv4_block20_0_bn False\n",
            "275 conv4_block20_0_relu False\n",
            "276 conv4_block20_1_conv False\n",
            "277 conv4_block20_1_bn False\n",
            "278 conv4_block20_1_relu False\n",
            "279 conv4_block20_2_conv False\n",
            "280 conv4_block20_concat False\n",
            "281 conv4_block21_0_bn False\n",
            "282 conv4_block21_0_relu False\n",
            "283 conv4_block21_1_conv False\n",
            "284 conv4_block21_1_bn False\n",
            "285 conv4_block21_1_relu False\n",
            "286 conv4_block21_2_conv False\n",
            "287 conv4_block21_concat False\n",
            "288 conv4_block22_0_bn False\n",
            "289 conv4_block22_0_relu False\n",
            "290 conv4_block22_1_conv False\n",
            "291 conv4_block22_1_bn False\n",
            "292 conv4_block22_1_relu False\n",
            "293 conv4_block22_2_conv False\n",
            "294 conv4_block22_concat False\n",
            "295 conv4_block23_0_bn False\n",
            "296 conv4_block23_0_relu False\n",
            "297 conv4_block23_1_conv False\n",
            "298 conv4_block23_1_bn False\n",
            "299 conv4_block23_1_relu False\n",
            "300 conv4_block23_2_conv False\n",
            "301 conv4_block23_concat False\n",
            "302 conv4_block24_0_bn False\n",
            "303 conv4_block24_0_relu False\n",
            "304 conv4_block24_1_conv False\n",
            "305 conv4_block24_1_bn False\n",
            "306 conv4_block24_1_relu False\n",
            "307 conv4_block24_2_conv False\n",
            "308 conv4_block24_concat False\n",
            "309 pool4_bn False\n",
            "310 pool4_relu False\n",
            "311 pool4_conv False\n",
            "312 pool4_pool False\n",
            "313 conv5_block1_0_bn False\n",
            "314 conv5_block1_0_relu False\n",
            "315 conv5_block1_1_conv False\n",
            "316 conv5_block1_1_bn False\n",
            "317 conv5_block1_1_relu False\n",
            "318 conv5_block1_2_conv False\n",
            "319 conv5_block1_concat False\n",
            "320 conv5_block2_0_bn False\n",
            "321 conv5_block2_0_relu False\n",
            "322 conv5_block2_1_conv False\n",
            "323 conv5_block2_1_bn False\n",
            "324 conv5_block2_1_relu False\n",
            "325 conv5_block2_2_conv False\n",
            "326 conv5_block2_concat False\n",
            "327 conv5_block3_0_bn False\n",
            "328 conv5_block3_0_relu False\n",
            "329 conv5_block3_1_conv False\n",
            "330 conv5_block3_1_bn False\n",
            "331 conv5_block3_1_relu False\n",
            "332 conv5_block3_2_conv False\n",
            "333 conv5_block3_concat False\n",
            "334 conv5_block4_0_bn False\n",
            "335 conv5_block4_0_relu False\n",
            "336 conv5_block4_1_conv False\n",
            "337 conv5_block4_1_bn False\n",
            "338 conv5_block4_1_relu False\n",
            "339 conv5_block4_2_conv False\n",
            "340 conv5_block4_concat False\n",
            "341 conv5_block5_0_bn False\n",
            "342 conv5_block5_0_relu False\n",
            "343 conv5_block5_1_conv False\n",
            "344 conv5_block5_1_bn False\n",
            "345 conv5_block5_1_relu False\n",
            "346 conv5_block5_2_conv False\n",
            "347 conv5_block5_concat False\n",
            "348 conv5_block6_0_bn False\n",
            "349 conv5_block6_0_relu False\n",
            "350 conv5_block6_1_conv False\n",
            "351 conv5_block6_1_bn False\n",
            "352 conv5_block6_1_relu False\n",
            "353 conv5_block6_2_conv False\n",
            "354 conv5_block6_concat False\n",
            "355 conv5_block7_0_bn False\n",
            "356 conv5_block7_0_relu False\n",
            "357 conv5_block7_1_conv False\n",
            "358 conv5_block7_1_bn False\n",
            "359 conv5_block7_1_relu False\n",
            "360 conv5_block7_2_conv False\n",
            "361 conv5_block7_concat False\n",
            "362 conv5_block8_0_bn False\n",
            "363 conv5_block8_0_relu False\n",
            "364 conv5_block8_1_conv False\n",
            "365 conv5_block8_1_bn False\n",
            "366 conv5_block8_1_relu False\n",
            "367 conv5_block8_2_conv False\n",
            "368 conv5_block8_concat False\n",
            "369 conv5_block9_0_bn False\n",
            "370 conv5_block9_0_relu False\n",
            "371 conv5_block9_1_conv False\n",
            "372 conv5_block9_1_bn False\n",
            "373 conv5_block9_1_relu False\n",
            "374 conv5_block9_2_conv False\n",
            "375 conv5_block9_concat False\n",
            "376 conv5_block10_0_bn False\n",
            "377 conv5_block10_0_relu False\n",
            "378 conv5_block10_1_conv False\n",
            "379 conv5_block10_1_bn False\n",
            "380 conv5_block10_1_relu False\n",
            "381 conv5_block10_2_conv False\n",
            "382 conv5_block10_concat False\n",
            "383 conv5_block11_0_bn False\n",
            "384 conv5_block11_0_relu False\n",
            "385 conv5_block11_1_conv False\n",
            "386 conv5_block11_1_bn False\n",
            "387 conv5_block11_1_relu False\n",
            "388 conv5_block11_2_conv False\n",
            "389 conv5_block11_concat False\n",
            "390 conv5_block12_0_bn False\n",
            "391 conv5_block12_0_relu False\n",
            "392 conv5_block12_1_conv False\n",
            "393 conv5_block12_1_bn False\n",
            "394 conv5_block12_1_relu False\n",
            "395 conv5_block12_2_conv True\n",
            "396 conv5_block12_concat True\n",
            "397 conv5_block13_0_bn True\n",
            "398 conv5_block13_0_relu True\n",
            "399 conv5_block13_1_conv True\n",
            "400 conv5_block13_1_bn True\n",
            "401 conv5_block13_1_relu True\n",
            "402 conv5_block13_2_conv True\n",
            "403 conv5_block13_concat True\n",
            "404 conv5_block14_0_bn True\n",
            "405 conv5_block14_0_relu True\n",
            "406 conv5_block14_1_conv True\n",
            "407 conv5_block14_1_bn True\n",
            "408 conv5_block14_1_relu True\n",
            "409 conv5_block14_2_conv True\n",
            "410 conv5_block14_concat True\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KcDo2VlW-6Jt"
      },
      "outputs": [],
      "source": [
        "#conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6prLuQV--6Jt",
        "outputId": "21272876-2976-4870-ca8a-f63126fc18c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 33\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 3,038,593\n",
            "Non-trainable params: 6,359,744\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "adagrad = optimizers.Adagrad(learning_rate=TrainingConfig.LEARNING_RATE, initial_accumulator_value=0.1, epsilon=TrainingConfig.EPSILON, decay =TrainingConfig.WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "P4qDSomz-6Jt"
      },
      "outputs": [],
      "source": [
        "modelPreTMob.compile(optimizer= adagrad, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])# Adagrad, adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add checkpoint to store the model on the best epoch for Val acc.\n",
        "checkpoint_filepath = r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-{epoch:02d}-{val_accuracy:.4f}.keras'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "print(TrainingConfig.EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.3808 - accuracy: 0.8012\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86671, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-01-0.8667.keras\n",
            "329/329 [==============================] - 242s 705ms/step - loss: 5.3808 - accuracy: 0.8012 - val_loss: 5.1435 - val_accuracy: 0.8667\n",
            "Epoch 2/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.1348 - accuracy: 0.8382\n",
            "Epoch 2: val_accuracy improved from 0.86671 to 0.87171, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-02-0.8717.keras\n",
            "329/329 [==============================] - 210s 637ms/step - loss: 5.1348 - accuracy: 0.8382 - val_loss: 4.9810 - val_accuracy: 0.8717\n",
            "Epoch 3/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.9729 - accuracy: 0.8456\n",
            "Epoch 3: val_accuracy improved from 0.87171 to 0.87961, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-03-0.8796.keras\n",
            "329/329 [==============================] - 212s 643ms/step - loss: 4.9729 - accuracy: 0.8456 - val_loss: 4.8407 - val_accuracy: 0.8796\n",
            "Epoch 4/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.8344 - accuracy: 0.8550\n",
            "Epoch 4: val_accuracy improved from 0.87961 to 0.88447, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-04-0.8845.keras\n",
            "329/329 [==============================] - 207s 630ms/step - loss: 4.8344 - accuracy: 0.8550 - val_loss: 4.7234 - val_accuracy: 0.8845\n",
            "Epoch 5/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.7297 - accuracy: 0.8563\n",
            "Epoch 5: val_accuracy improved from 0.88447 to 0.88539, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-05-0.8854.keras\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 4.7297 - accuracy: 0.8563 - val_loss: 4.6235 - val_accuracy: 0.8854\n",
            "Epoch 6/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.6290 - accuracy: 0.8593\n",
            "Epoch 6: val_accuracy improved from 0.88539 to 0.88553, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-06-0.8855.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 4.6290 - accuracy: 0.8593 - val_loss: 4.5370 - val_accuracy: 0.8855\n",
            "Epoch 7/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.5545 - accuracy: 0.8597\n",
            "Epoch 7: val_accuracy improved from 0.88553 to 0.88724, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-07-0.8872.keras\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 4.5545 - accuracy: 0.8597 - val_loss: 4.4583 - val_accuracy: 0.8872\n",
            "Epoch 8/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4755 - accuracy: 0.8606\n",
            "Epoch 8: val_accuracy did not improve from 0.88724\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.4755 - accuracy: 0.8606 - val_loss: 4.3892 - val_accuracy: 0.8862\n",
            "Epoch 9/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4130 - accuracy: 0.8638\n",
            "Epoch 9: val_accuracy improved from 0.88724 to 0.88816, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-09-0.8882.keras\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 4.4130 - accuracy: 0.8638 - val_loss: 4.3249 - val_accuracy: 0.8882\n",
            "Epoch 10/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.3470 - accuracy: 0.8621\n",
            "Epoch 10: val_accuracy improved from 0.88816 to 0.88934, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-10-0.8893.keras\n",
            "329/329 [==============================] - 201s 611ms/step - loss: 4.3470 - accuracy: 0.8621 - val_loss: 4.2655 - val_accuracy: 0.8893\n",
            "Epoch 11/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2941 - accuracy: 0.8646\n",
            "Epoch 11: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 201s 611ms/step - loss: 4.2941 - accuracy: 0.8646 - val_loss: 4.2131 - val_accuracy: 0.8887\n",
            "Epoch 12/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2429 - accuracy: 0.8647\n",
            "Epoch 12: val_accuracy improved from 0.88934 to 0.88961, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-12-0.8896.keras\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 4.2429 - accuracy: 0.8647 - val_loss: 4.1638 - val_accuracy: 0.8896\n",
            "Epoch 13/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1870 - accuracy: 0.8653\n",
            "Epoch 13: val_accuracy improved from 0.88961 to 0.89039, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-13-0.8904.keras\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 4.1870 - accuracy: 0.8653 - val_loss: 4.1182 - val_accuracy: 0.8904\n",
            "Epoch 14/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1474 - accuracy: 0.8656\n",
            "Epoch 14: val_accuracy improved from 0.89039 to 0.89053, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-14-0.8905.keras\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 4.1474 - accuracy: 0.8656 - val_loss: 4.0758 - val_accuracy: 0.8905\n",
            "Epoch 15/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0997 - accuracy: 0.8681\n",
            "Epoch 15: val_accuracy improved from 0.89053 to 0.89092, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-15-0.8909.keras\n",
            "329/329 [==============================] - 203s 616ms/step - loss: 4.0997 - accuracy: 0.8681 - val_loss: 4.0371 - val_accuracy: 0.8909\n",
            "Epoch 16/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0699 - accuracy: 0.8669\n",
            "Epoch 16: val_accuracy did not improve from 0.89092\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 4.0699 - accuracy: 0.8669 - val_loss: 4.0000 - val_accuracy: 0.8909\n",
            "Epoch 17/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0315 - accuracy: 0.8668\n",
            "Epoch 17: val_accuracy did not improve from 0.89092\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 4.0315 - accuracy: 0.8668 - val_loss: 3.9642 - val_accuracy: 0.8909\n",
            "Epoch 18/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9933 - accuracy: 0.8675\n",
            "Epoch 18: val_accuracy did not improve from 0.89092\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.9933 - accuracy: 0.8675 - val_loss: 3.9308 - val_accuracy: 0.8908\n",
            "Epoch 19/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9631 - accuracy: 0.8681\n",
            "Epoch 19: val_accuracy improved from 0.89092 to 0.89197, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-19-0.8920.keras\n",
            "329/329 [==============================] - 203s 616ms/step - loss: 3.9631 - accuracy: 0.8681 - val_loss: 3.8999 - val_accuracy: 0.8920\n",
            "Epoch 20/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9305 - accuracy: 0.8706\n",
            "Epoch 20: val_accuracy improved from 0.89197 to 0.89237, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-20-0.8924.keras\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.9305 - accuracy: 0.8706 - val_loss: 3.8692 - val_accuracy: 0.8924\n",
            "Epoch 21/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8973 - accuracy: 0.8708\n",
            "Epoch 21: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.8973 - accuracy: 0.8708 - val_loss: 3.8410 - val_accuracy: 0.8922\n",
            "Epoch 22/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8712 - accuracy: 0.8722\n",
            "Epoch 22: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.8712 - accuracy: 0.8722 - val_loss: 3.8144 - val_accuracy: 0.8912\n",
            "Epoch 23/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8438 - accuracy: 0.8708\n",
            "Epoch 23: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.8438 - accuracy: 0.8708 - val_loss: 3.7888 - val_accuracy: 0.8922\n",
            "Epoch 24/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8189 - accuracy: 0.8730\n",
            "Epoch 24: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.8189 - accuracy: 0.8730 - val_loss: 3.7655 - val_accuracy: 0.8917\n",
            "Epoch 25/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8008 - accuracy: 0.8700\n",
            "Epoch 25: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.8008 - accuracy: 0.8700 - val_loss: 3.7428 - val_accuracy: 0.8909\n",
            "Epoch 26/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7780 - accuracy: 0.8700\n",
            "Epoch 26: val_accuracy improved from 0.89237 to 0.89329, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-26-0.8933.keras\n",
            "329/329 [==============================] - 201s 612ms/step - loss: 3.7780 - accuracy: 0.8700 - val_loss: 3.7191 - val_accuracy: 0.8933\n",
            "Epoch 27/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7515 - accuracy: 0.8711\n",
            "Epoch 27: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.7515 - accuracy: 0.8711 - val_loss: 3.6987 - val_accuracy: 0.8926\n",
            "Epoch 28/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7292 - accuracy: 0.8753\n",
            "Epoch 28: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.7292 - accuracy: 0.8753 - val_loss: 3.6774 - val_accuracy: 0.8924\n",
            "Epoch 29/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7094 - accuracy: 0.8712\n",
            "Epoch 29: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.7094 - accuracy: 0.8712 - val_loss: 3.6580 - val_accuracy: 0.8921\n",
            "Epoch 30/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6926 - accuracy: 0.8720\n",
            "Epoch 30: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.6926 - accuracy: 0.8720 - val_loss: 3.6385 - val_accuracy: 0.8926\n",
            "Epoch 31/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6681 - accuracy: 0.8728\n",
            "Epoch 31: val_accuracy improved from 0.89329 to 0.89342, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-31-0.8934.keras\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.6681 - accuracy: 0.8728 - val_loss: 3.6202 - val_accuracy: 0.8934\n",
            "Epoch 32/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6482 - accuracy: 0.8762\n",
            "Epoch 32: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.6482 - accuracy: 0.8762 - val_loss: 3.6020 - val_accuracy: 0.8929\n",
            "Epoch 33/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6340 - accuracy: 0.8737\n",
            "Epoch 33: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 202s 612ms/step - loss: 3.6340 - accuracy: 0.8737 - val_loss: 3.5848 - val_accuracy: 0.8926\n",
            "Epoch 34/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6190 - accuracy: 0.8734\n",
            "Epoch 34: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.6190 - accuracy: 0.8734 - val_loss: 3.5685 - val_accuracy: 0.8933\n",
            "Epoch 35/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5996 - accuracy: 0.8749\n",
            "Epoch 35: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.5996 - accuracy: 0.8749 - val_loss: 3.5528 - val_accuracy: 0.8929\n",
            "Epoch 36/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5836 - accuracy: 0.8741\n",
            "Epoch 36: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.5836 - accuracy: 0.8741 - val_loss: 3.5384 - val_accuracy: 0.8925\n",
            "Epoch 37/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5674 - accuracy: 0.8756\n",
            "Epoch 37: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 202s 613ms/step - loss: 3.5674 - accuracy: 0.8756 - val_loss: 3.5224 - val_accuracy: 0.8930\n",
            "Epoch 38/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5543 - accuracy: 0.8735\n",
            "Epoch 38: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.5543 - accuracy: 0.8735 - val_loss: 3.5082 - val_accuracy: 0.8928\n",
            "Epoch 39/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5447 - accuracy: 0.8741\n",
            "Epoch 39: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.5447 - accuracy: 0.8741 - val_loss: 3.4940 - val_accuracy: 0.8930\n",
            "Epoch 40/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5281 - accuracy: 0.8739\n",
            "Epoch 40: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.5281 - accuracy: 0.8739 - val_loss: 3.4800 - val_accuracy: 0.8926\n",
            "Epoch 41/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5118 - accuracy: 0.8741\n",
            "Epoch 41: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.5118 - accuracy: 0.8741 - val_loss: 3.4671 - val_accuracy: 0.8933\n",
            "Epoch 42/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5034 - accuracy: 0.8739\n",
            "Epoch 42: val_accuracy did not improve from 0.89342\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.5034 - accuracy: 0.8739 - val_loss: 3.4542 - val_accuracy: 0.8925\n",
            "Epoch 43/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4855 - accuracy: 0.8775\n",
            "Epoch 43: val_accuracy improved from 0.89342 to 0.89382, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-43-0.8938.keras\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.4855 - accuracy: 0.8775 - val_loss: 3.4417 - val_accuracy: 0.8938\n",
            "Epoch 44/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4728 - accuracy: 0.8747\n",
            "Epoch 44: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.4728 - accuracy: 0.8747 - val_loss: 3.4295 - val_accuracy: 0.8934\n",
            "Epoch 45/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4584 - accuracy: 0.8770\n",
            "Epoch 45: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.4584 - accuracy: 0.8770 - val_loss: 3.4179 - val_accuracy: 0.8930\n",
            "Epoch 46/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4473 - accuracy: 0.8778\n",
            "Epoch 46: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 203s 615ms/step - loss: 3.4473 - accuracy: 0.8778 - val_loss: 3.4059 - val_accuracy: 0.8936\n",
            "Epoch 47/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4369 - accuracy: 0.8740\n",
            "Epoch 47: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.4369 - accuracy: 0.8740 - val_loss: 3.3951 - val_accuracy: 0.8934\n",
            "Epoch 48/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4260 - accuracy: 0.8750\n",
            "Epoch 48: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4260 - accuracy: 0.8750 - val_loss: 3.3835 - val_accuracy: 0.8938\n",
            "Epoch 49/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4137 - accuracy: 0.8756\n",
            "Epoch 49: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.4137 - accuracy: 0.8756 - val_loss: 3.3728 - val_accuracy: 0.8937\n",
            "Epoch 50/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4066 - accuracy: 0.8753\n",
            "Epoch 50: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 202s 613ms/step - loss: 3.4066 - accuracy: 0.8753 - val_loss: 3.3623 - val_accuracy: 0.8934\n",
            "Epoch 51/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3875 - accuracy: 0.8818\n",
            "Epoch 51: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 203s 615ms/step - loss: 3.3875 - accuracy: 0.8818 - val_loss: 3.3525 - val_accuracy: 0.8929\n",
            "Epoch 52/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3788 - accuracy: 0.8779\n",
            "Epoch 52: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.3788 - accuracy: 0.8779 - val_loss: 3.3429 - val_accuracy: 0.8934\n",
            "Epoch 53/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3719 - accuracy: 0.8780\n",
            "Epoch 53: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.3719 - accuracy: 0.8780 - val_loss: 3.3321 - val_accuracy: 0.8938\n",
            "Epoch 54/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3653 - accuracy: 0.8770\n",
            "Epoch 54: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.3653 - accuracy: 0.8770 - val_loss: 3.3234 - val_accuracy: 0.8930\n",
            "Epoch 55/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3501 - accuracy: 0.8787\n",
            "Epoch 55: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.3501 - accuracy: 0.8787 - val_loss: 3.3138 - val_accuracy: 0.8930\n",
            "Epoch 56/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3464 - accuracy: 0.8771\n",
            "Epoch 56: val_accuracy did not improve from 0.89382\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.3464 - accuracy: 0.8771 - val_loss: 3.3044 - val_accuracy: 0.8930\n",
            "Epoch 57/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3377 - accuracy: 0.8787\n",
            "Epoch 57: val_accuracy improved from 0.89382 to 0.89408, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-57-0.8941.keras\n",
            "329/329 [==============================] - 205s 621ms/step - loss: 3.3377 - accuracy: 0.8787 - val_loss: 3.2950 - val_accuracy: 0.8941\n",
            "Epoch 58/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3264 - accuracy: 0.8787\n",
            "Epoch 58: val_accuracy did not improve from 0.89408\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.3264 - accuracy: 0.8787 - val_loss: 3.2863 - val_accuracy: 0.8941\n",
            "Epoch 59/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3214 - accuracy: 0.8749\n",
            "Epoch 59: val_accuracy did not improve from 0.89408\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.3214 - accuracy: 0.8749 - val_loss: 3.2784 - val_accuracy: 0.8936\n",
            "Epoch 60/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3064 - accuracy: 0.8785\n",
            "Epoch 60: val_accuracy did not improve from 0.89408\n",
            "329/329 [==============================] - 202s 613ms/step - loss: 3.3064 - accuracy: 0.8785 - val_loss: 3.2694 - val_accuracy: 0.8933\n",
            "Epoch 61/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2968 - accuracy: 0.8805\n",
            "Epoch 61: val_accuracy did not improve from 0.89408\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.2968 - accuracy: 0.8805 - val_loss: 3.2615 - val_accuracy: 0.8939\n",
            "Epoch 62/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2954 - accuracy: 0.8771\n",
            "Epoch 62: val_accuracy improved from 0.89408 to 0.89434, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-62-0.8943.keras\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.2954 - accuracy: 0.8771 - val_loss: 3.2527 - val_accuracy: 0.8943\n",
            "Epoch 63/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2854 - accuracy: 0.8780\n",
            "Epoch 63: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.2854 - accuracy: 0.8780 - val_loss: 3.2454 - val_accuracy: 0.8937\n",
            "Epoch 64/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2722 - accuracy: 0.8793\n",
            "Epoch 64: val_accuracy improved from 0.89434 to 0.89566, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-64-0.8957.keras\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.2722 - accuracy: 0.8793 - val_loss: 3.2373 - val_accuracy: 0.8957\n",
            "Epoch 65/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2648 - accuracy: 0.8825\n",
            "Epoch 65: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.2648 - accuracy: 0.8825 - val_loss: 3.2297 - val_accuracy: 0.8945\n",
            "Epoch 66/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2582 - accuracy: 0.8802\n",
            "Epoch 66: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.2582 - accuracy: 0.8802 - val_loss: 3.2222 - val_accuracy: 0.8942\n",
            "Epoch 67/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2560 - accuracy: 0.8775\n",
            "Epoch 67: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.2560 - accuracy: 0.8775 - val_loss: 3.2149 - val_accuracy: 0.8946\n",
            "Epoch 68/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2433 - accuracy: 0.8787\n",
            "Epoch 68: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.2433 - accuracy: 0.8787 - val_loss: 3.2078 - val_accuracy: 0.8951\n",
            "Epoch 69/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2382 - accuracy: 0.8776\n",
            "Epoch 69: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 202s 615ms/step - loss: 3.2382 - accuracy: 0.8776 - val_loss: 3.2016 - val_accuracy: 0.8936\n",
            "Epoch 70/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2344 - accuracy: 0.8779\n",
            "Epoch 70: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.2344 - accuracy: 0.8779 - val_loss: 3.1941 - val_accuracy: 0.8945\n",
            "Epoch 71/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2251 - accuracy: 0.8783\n",
            "Epoch 71: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.2251 - accuracy: 0.8783 - val_loss: 3.1867 - val_accuracy: 0.8951\n",
            "Epoch 72/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2147 - accuracy: 0.8798\n",
            "Epoch 72: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.2147 - accuracy: 0.8798 - val_loss: 3.1809 - val_accuracy: 0.8938\n",
            "Epoch 73/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2124 - accuracy: 0.8809\n",
            "Epoch 73: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.2124 - accuracy: 0.8809 - val_loss: 3.1729 - val_accuracy: 0.8950\n",
            "Epoch 74/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1974 - accuracy: 0.8809\n",
            "Epoch 74: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.1974 - accuracy: 0.8809 - val_loss: 3.1666 - val_accuracy: 0.8947\n",
            "Epoch 75/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1956 - accuracy: 0.8800\n",
            "Epoch 75: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.1956 - accuracy: 0.8800 - val_loss: 3.1608 - val_accuracy: 0.8941\n",
            "Epoch 76/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1889 - accuracy: 0.8802\n",
            "Epoch 76: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.1889 - accuracy: 0.8802 - val_loss: 3.1539 - val_accuracy: 0.8951\n",
            "Epoch 77/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1922 - accuracy: 0.8769\n",
            "Epoch 77: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.1922 - accuracy: 0.8769 - val_loss: 3.1478 - val_accuracy: 0.8945\n",
            "Epoch 78/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1773 - accuracy: 0.8793\n",
            "Epoch 78: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.1773 - accuracy: 0.8793 - val_loss: 3.1423 - val_accuracy: 0.8942\n",
            "Epoch 79/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1713 - accuracy: 0.8785\n",
            "Epoch 79: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.1713 - accuracy: 0.8785 - val_loss: 3.1361 - val_accuracy: 0.8942\n",
            "Epoch 80/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1673 - accuracy: 0.8784\n",
            "Epoch 80: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.1673 - accuracy: 0.8784 - val_loss: 3.1303 - val_accuracy: 0.8946\n",
            "Epoch 81/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1647 - accuracy: 0.8788\n",
            "Epoch 81: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.1647 - accuracy: 0.8788 - val_loss: 3.1245 - val_accuracy: 0.8943\n",
            "Epoch 82/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1516 - accuracy: 0.8796\n",
            "Epoch 82: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.1516 - accuracy: 0.8796 - val_loss: 3.1184 - val_accuracy: 0.8950\n",
            "Epoch 83/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1521 - accuracy: 0.8761\n",
            "Epoch 83: val_accuracy did not improve from 0.89566\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.1521 - accuracy: 0.8761 - val_loss: 3.1134 - val_accuracy: 0.8932\n",
            "Epoch 84/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1422 - accuracy: 0.8802\n",
            "Epoch 84: val_accuracy improved from 0.89566 to 0.89605, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-84-0.8961.keras\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.1422 - accuracy: 0.8802 - val_loss: 3.1075 - val_accuracy: 0.8961\n",
            "Epoch 85/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1361 - accuracy: 0.8817\n",
            "Epoch 85: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.1361 - accuracy: 0.8817 - val_loss: 3.1020 - val_accuracy: 0.8945\n",
            "Epoch 86/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1317 - accuracy: 0.8795\n",
            "Epoch 86: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.1317 - accuracy: 0.8795 - val_loss: 3.0961 - val_accuracy: 0.8954\n",
            "Epoch 87/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1309 - accuracy: 0.8773\n",
            "Epoch 87: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 202s 614ms/step - loss: 3.1309 - accuracy: 0.8773 - val_loss: 3.0913 - val_accuracy: 0.8957\n",
            "Epoch 88/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1215 - accuracy: 0.8800\n",
            "Epoch 88: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.1215 - accuracy: 0.8800 - val_loss: 3.0863 - val_accuracy: 0.8950\n",
            "Epoch 89/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1178 - accuracy: 0.8772\n",
            "Epoch 89: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.1178 - accuracy: 0.8772 - val_loss: 3.0812 - val_accuracy: 0.8949\n",
            "Epoch 90/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1140 - accuracy: 0.8789\n",
            "Epoch 90: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 203s 616ms/step - loss: 3.1140 - accuracy: 0.8789 - val_loss: 3.0761 - val_accuracy: 0.8949\n",
            "Epoch 91/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1040 - accuracy: 0.8786\n",
            "Epoch 91: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 203s 617ms/step - loss: 3.1040 - accuracy: 0.8786 - val_loss: 3.0706 - val_accuracy: 0.8949\n",
            "Epoch 92/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0986 - accuracy: 0.8793\n",
            "Epoch 92: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 204s 618ms/step - loss: 3.0986 - accuracy: 0.8793 - val_loss: 3.0670 - val_accuracy: 0.8937\n",
            "Epoch 93/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0939 - accuracy: 0.8806\n",
            "Epoch 93: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 203s 616ms/step - loss: 3.0939 - accuracy: 0.8806 - val_loss: 3.0614 - val_accuracy: 0.8954\n",
            "Epoch 94/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0899 - accuracy: 0.8809\n",
            "Epoch 94: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.0899 - accuracy: 0.8809 - val_loss: 3.0562 - val_accuracy: 0.8953\n",
            "Epoch 95/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0901 - accuracy: 0.8772\n",
            "Epoch 95: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 202s 613ms/step - loss: 3.0901 - accuracy: 0.8772 - val_loss: 3.0526 - val_accuracy: 0.8950\n",
            "Epoch 96/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0846 - accuracy: 0.8775\n",
            "Epoch 96: val_accuracy did not improve from 0.89605\n",
            "329/329 [==============================] - 203s 618ms/step - loss: 3.0846 - accuracy: 0.8775 - val_loss: 3.0470 - val_accuracy: 0.8947\n",
            "Epoch 97/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0723 - accuracy: 0.8796\n",
            "Epoch 97: val_accuracy improved from 0.89605 to 0.89711, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT30-97-0.8971.keras\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.0723 - accuracy: 0.8796 - val_loss: 3.0421 - val_accuracy: 0.8971\n",
            "Epoch 98/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0765 - accuracy: 0.8791\n",
            "Epoch 98: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 202s 613ms/step - loss: 3.0765 - accuracy: 0.8791 - val_loss: 3.0377 - val_accuracy: 0.8950\n",
            "Epoch 99/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0633 - accuracy: 0.8830\n",
            "Epoch 99: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 202s 613ms/step - loss: 3.0633 - accuracy: 0.8830 - val_loss: 3.0338 - val_accuracy: 0.8946\n",
            "Epoch 100/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0682 - accuracy: 0.8779\n",
            "Epoch 100: val_accuracy did not improve from 0.89711\n",
            "329/329 [==============================] - 203s 615ms/step - loss: 3.0682 - accuracy: 0.8779 - val_loss: 3.0293 - val_accuracy: 0.8958\n"
          ]
        }
      ],
      "source": [
        "histPreT = modelPreTMob.fit(train_generator, epochs = TrainingConfig.EPOCHS, validation_data=validation_generator, callbacks=[model_checkpoint_callback]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 20374.608947753906 seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(Current_dir, 'History')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(r'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History\\\\HistoryDict_DenseNEt_FT30', 'wb') as file_pi:\n",
        "    pickle.dump(histPreT.history, file_pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 97\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "START_PLOT_FROM_EPOCH= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "e3wZrd90-6Jt",
        "outputId": "0630124c-9747-4688-f755-aaf80997102f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc = histPreT.history['accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "val_acc = histPreT.history['val_accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "loss = histPreT.history['loss'][START_PLOT_FROM_EPOCH:]\n",
        "val_loss = histPreT.history['val_loss'][START_PLOT_FROM_EPOCH:]\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, color='teal', label='Training acc')\n",
        "plt.plot(epochs, val_acc, color='orange', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, color='teal', label='Training loss')\n",
        "plt.plot(epochs, val_loss, color='orange', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 97\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading best epoch in our model using the checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dir= r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints' # C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model file: model-97-0.8971.keras\n"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = max(val_acc_per_epoch)\n",
        "best_model_file = f'model-{best_epoch:02d}-{best_val_accuracy:.4f}.keras'\n",
        "\n",
        "print(f'Best model file: {best_model_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\checkpoints'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(model_dir)\n",
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['checkpoints.lnk',\n",
              " 'ConvNextTiny_FT20-01-0.8195.keras',\n",
              " 'ConvNextTiny_FT20-04-0.8350.keras',\n",
              " 'ConvNextTiny_FT20-06-0.8462.keras',\n",
              " 'ConvNextTiny_FT20-07-0.8566.keras',\n",
              " 'ConvNextTiny_FT20-09-0.8584.keras',\n",
              " 'ConvNextTiny_FT20-27-0.8608.keras',\n",
              " 'ConvNextTiny_FT20-70-0.8611.keras',\n",
              " 'model-01-0.8824.keras',\n",
              " 'model-02-0.8867.keras',\n",
              " 'model-03-0.8893.keras',\n",
              " 'model-05-0.8895.keras',\n",
              " 'model-06-0.8934.keras',\n",
              " 'model-09-0.8961.keras',\n",
              " 'model-11-0.8966.keras',\n",
              " 'modelAlexNetFT10-01-0.8759.keras',\n",
              " 'modelAlexNetFT10-02-0.8841.keras',\n",
              " 'modelAlexNetFT10-06-0.8904.keras',\n",
              " 'modelAlexNetFT10-08-0.8968.keras',\n",
              " 'modelAlexNetFT10-13-0.8987.keras',\n",
              " 'modelAlexNetFT10-14-0.9022.keras',\n",
              " 'modelAlexNetFT10-24-0.9043.keras',\n",
              " 'modelDenseNet-01-0.8676.keras',\n",
              " 'modelDenseNet-02-0.8737.keras',\n",
              " 'modelDenseNet-03-0.8803.keras',\n",
              " 'modelDenseNet-04-0.8824.keras',\n",
              " 'modelDenseNet-05-0.8826.keras',\n",
              " 'modelDenseNet-08-0.8837.keras',\n",
              " 'modelDenseNet-12-0.8843.keras',\n",
              " 'modelDenseNet-14-0.8854.keras',\n",
              " 'modelDenseNet-15-0.8857.keras',\n",
              " 'modelDenseNet-16-0.8862.keras',\n",
              " 'modelDenseNet-22-0.8863.keras',\n",
              " 'modelDenseNet-23-0.8875.keras',\n",
              " 'modelDenseNet-39-0.8878.keras',\n",
              " 'modelDenseNet-40-0.8884.keras',\n",
              " 'modelDenseNet-43-0.8886.keras',\n",
              " 'modelDenseNet-49-0.8888.keras',\n",
              " 'modelDenseNet-59-0.8893.keras',\n",
              " 'modelDenseNet-75-0.8897.keras',\n",
              " 'modelDenseNet-81-0.8901.keras',\n",
              " 'modelDenseNet-87-0.8903.keras',\n",
              " 'modelDenseNetFT15-01-0.8609.keras',\n",
              " 'modelDenseNetFT15-02-0.8750.keras',\n",
              " 'modelDenseNetFT15-03-0.8783.keras',\n",
              " 'modelDenseNetFT15-04-0.8796.keras',\n",
              " 'modelDenseNetFT15-05-0.8816.keras',\n",
              " 'modelDenseNetFT15-06-0.8826.keras',\n",
              " 'modelDenseNetFT15-07-0.8833.keras',\n",
              " 'modelDenseNetFT15-08-0.8858.keras',\n",
              " 'modelDenseNetFT15-09-0.8864.keras',\n",
              " 'modelDenseNetFT15-11-0.8887.keras',\n",
              " 'modelDenseNetFT15-14-0.8888.keras',\n",
              " 'modelDenseNetFT15-16-0.8900.keras',\n",
              " 'modelDenseNetFT15-19-0.8917.keras',\n",
              " 'modelDenseNetFT15-42-0.8922.keras',\n",
              " 'modelDenseNetFT15-47-0.8924.keras',\n",
              " 'modelDenseNetFT15-50-0.8926.keras',\n",
              " 'modelDenseNetFT15-53-0.8928.keras',\n",
              " 'modelDenseNetFT15-55-0.8930.keras',\n",
              " 'modelDenseNetFT15-61-0.8933.keras',\n",
              " 'modelDenseNetFT15-66-0.8936.keras',\n",
              " 'modelDenseNetFT15-67-0.8939.keras',\n",
              " 'modelDenseNetFT15-74-0.8942.keras',\n",
              " 'modelDenseNetFT15-86-0.8943.keras',\n",
              " 'modelDenseNetFT30-01-0.8667.keras',\n",
              " 'modelDenseNetFT30-02-0.8717.keras',\n",
              " 'modelDenseNetFT30-03-0.8796.keras',\n",
              " 'modelDenseNetFT30-04-0.8845.keras',\n",
              " 'modelDenseNetFT30-05-0.8854.keras',\n",
              " 'modelDenseNetFT30-06-0.8855.keras',\n",
              " 'modelDenseNetFT30-07-0.8872.keras',\n",
              " 'modelDenseNetFT30-09-0.8882.keras',\n",
              " 'modelDenseNetFT30-10-0.8893.keras',\n",
              " 'modelDenseNetFT30-12-0.8896.keras',\n",
              " 'modelDenseNetFT30-13-0.8904.keras',\n",
              " 'modelDenseNetFT30-14-0.8905.keras',\n",
              " 'modelDenseNetFT30-15-0.8909.keras',\n",
              " 'modelDenseNetFT30-19-0.8920.keras',\n",
              " 'modelDenseNetFT30-20-0.8924.keras',\n",
              " 'modelDenseNetFT30-26-0.8933.keras',\n",
              " 'modelDenseNetFT30-31-0.8934.keras',\n",
              " 'modelDenseNetFT30-43-0.8938.keras',\n",
              " 'modelDenseNetFT30-57-0.8941.keras',\n",
              " 'modelDenseNetFT30-62-0.8943.keras',\n",
              " 'modelDenseNetFT30-64-0.8957.keras',\n",
              " 'modelDenseNetFT30-84-0.8961.keras',\n",
              " 'modelDenseNetFT30-97-0.8971.keras',\n",
              " 'modelMobileNetV2FT20-01-0.7942.keras',\n",
              " 'modelMobileNetV2FT20-02-0.8239.keras',\n",
              " 'modelMobileNetV2FT20-03-0.8364.keras',\n",
              " 'modelMobileNetV2FT20-04-0.8528.keras',\n",
              " 'modelMobileNetV2FT20-05-0.8658.keras',\n",
              " 'modelMobileNetV2FT20-06-0.8661.keras',\n",
              " 'modelMobileNetV2FT20-07-0.8704.keras',\n",
              " 'modelMobileNetV2FT20-08-0.8721.keras',\n",
              " 'modelMobileNetV2FT20-09-0.8774.keras',\n",
              " 'modelMobileNetV2FT20-10-0.8797.keras',\n",
              " 'modelMobileNetV2FT20-11-0.8807.keras',\n",
              " 'modelMobileNetV2FT20-12-0.8820.keras',\n",
              " 'modelMobileNetV2FT20-13-0.8822.keras',\n",
              " 'modelMobileNetV2FT20-14-0.8833.keras',\n",
              " 'modelMobileNetV2FT20-15-0.8838.keras',\n",
              " 'modelMobileNetV2FT20-16-0.8851.keras',\n",
              " 'modelMobileNetV2FT20-18-0.8858.keras',\n",
              " 'modelMobileNetV2FT20-19-0.8859.keras',\n",
              " 'modelMobileNetV2FT20-21-0.8876.keras',\n",
              " 'modelMobileNetV2FT20-23-0.8879.keras',\n",
              " 'modelMobileNetV2FT20-24-0.8880.keras',\n",
              " 'modelMobileNetV2FT20-26-0.8882.keras',\n",
              " 'modelMobileNetV2FT20-27-0.8887.keras',\n",
              " 'modelMobileNetV2FT20-31-0.8888.keras',\n",
              " 'modelMobileNetV2FT20-32-0.8891.keras',\n",
              " 'modelMobileNetV2FT20-33-0.8892.keras',\n",
              " 'modelMobileNetV2FT20-36-0.8901.keras',\n",
              " 'modelMobileNetV2FT20-47-0.8905.keras',\n",
              " 'modelMobileNetV2FT20-54-0.8907.keras',\n",
              " 'modelMobileNetV2FT20-57-0.8908.keras',\n",
              " 'modelMobileNetV2FT20-58-0.8911.keras',\n",
              " 'modelMobileNetV2FT20-62-0.8914.keras',\n",
              " 'modelMobileNetV2FT20-64-0.8916.keras',\n",
              " 'modelMobileNetV2FT20-66-0.8918.keras',\n",
              " 'modelMobileNetV2FT20-68-0.8924.keras',\n",
              " 'modelResNet50_FT20-01-0.8026.keras',\n",
              " 'modelResNet50_FT20-03-0.8136.keras',\n",
              " 'modelResNet50_FT20-08-0.8170.keras',\n",
              " 'modelResNet50_FT20-20-0.8295.keras',\n",
              " 'modelResNet50_FT20-24-0.8329.keras',\n",
              " 'modelResNet50_FT20-44-0.8339.keras',\n",
              " 'model_AlexNet-86-0.8629.keras']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(model_dir) if isfile(join(model_dir, f))]\n",
        "onlyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 3,038,593\n",
            "Non-trainable params: 6,359,744\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "#loaded_model = load_model(os.path.join('checkpoints',best_model_file))\n",
        "loaded_model = load_model('modelDenseNetFT30-97-0.8971.keras') \n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "r_Nq7Xip7rrJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "tgHLiCoC-6Jt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "60/60 [==============================] - 20s 294ms/step - loss: 3.0384 - accuracy: 0.8985\n",
            "test acc: 0.8985000252723694\n",
            "test loss: 3.0383565425872803\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.EPOCHS,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = loaded_model.evaluate(test_generator, steps=len(test_generator))  # steps_per_epoch * epochs\n",
        "print('test acc:', test_acc)\n",
        "print('test loss:', test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 20.070415258407593 Training set > seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s Training set > seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize lists to collect true labels and predictions\n",
        "true_labels = []\n",
        "predicted_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 93ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 99ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 94ms/step\n",
            "4/4 [==============================] - 0s 93ms/step\n",
            "4/4 [==============================] - 0s 98ms/step\n",
            "4/4 [==============================] - 0s 99ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 99ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 94ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 92ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 91ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 96ms/step\n",
            "4/4 [==============================] - 0s 97ms/step\n",
            "4/4 [==============================] - 0s 98ms/step\n",
            "4/4 [==============================] - 0s 95ms/step\n",
            "4/4 [==============================] - 0s 97ms/step\n",
            "4/4 [==============================] - 0s 98ms/step\n",
            "4/4 [==============================] - 0s 97ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 88ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n",
            "4/4 [==============================] - 0s 89ms/step\n",
            "4/4 [==============================] - 0s 93ms/step\n",
            "4/4 [==============================] - 0s 90ms/step\n"
          ]
        }
      ],
      "source": [
        "for _ in range(len(test_generator)):\n",
        "    X, y = next(test_generator)\n",
        "\n",
        "    yhat = modelPreTMob.predict(X)\n",
        "    \n",
        "    y_true_batch = y # Labels\n",
        "    \n",
        "    # Convert probabilities to class labels using a threshold of 0.5\n",
        "    y_pred_batch = (yhat > 0.5).astype(int)\n",
        "\n",
        "    # Append the true labels and predictions for this batch to the lists\n",
        "    true_labels.extend(y_true_batch)\n",
        "    predicted_labels.extend(y_pred_batch)\n",
        "\n",
        "    if len(true_labels) >= test_generator.n:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2640,  360],\n",
              "       [ 252, 2748]], dtype=int64)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the confusion matrix\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm/cm_sum.astype(float), display_labels=['Ads', 'non-Ads'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.899803536345776"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "f1_score(true_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8841698841698842"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.916"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.898000\n"
          ]
        }
      ],
      "source": [
        "# ROC AUC\n",
        "auc = roc_auc_score(true_labels, predicted_labels)\n",
        "print('ROC AUC: %f' % auc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
