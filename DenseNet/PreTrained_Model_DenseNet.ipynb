{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DenseNet no fine tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this run for the MobileNet, we froze all layers and added two dense layers after the conv_base.\n",
        "\n",
        "Results>\n",
        "\n",
        "Best Epoch: 87\n",
        "\n",
        "test acc: 0.88533\n",
        "\n",
        "test loss: 3.4204\n",
        "\n",
        "f1_score: 0.887814\n",
        "\n",
        "Precision: 0.887962\n",
        "\n",
        "Recall: 0.88766\n",
        "\n",
        "ROC AUC: 0.8878\n",
        "\n",
        "---Training:  seconds --- 20690 s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9F-3tLoS-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install \"tensorflow<2.11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Q0sXDdr-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ze2HI0C1-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eHaZm8sS-6Jk"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip list\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VTJsjK8k-6Jl"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pc4Ak-MX-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9qmltHoh-6Jl"
      },
      "outputs": [],
      "source": [
        "# add headings with ##(space) on the markdowns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oefqb7pK-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflor keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9_5zqcvh-6Jl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp9-KNO_XLJk",
        "outputId": "6744d109-58a8-4e55-860f-55eb54942aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jul 31 07:32:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1660 ...  WDDM  | 00000000:2D:00.0  On |                  N/A |\n",
            "|  0%   39C    P8              16W / 125W |    448MiB /  6144MiB |      6%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1644    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A      4640    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A      6600    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      8028    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A      8172    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     10264    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A     13432    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     16152    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     18028    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     18460    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     19896    C+G   ...e Stream\\94.0.1.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A     20052    C+G   ...n\\126.0.2592.113\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     21760    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     22492    C+G   ...am Files\\CyberGhost 8\\Dashboard.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkjlmr5C-6Jl",
        "outputId": "ee4947bd-e593-4a95-d056-cd5c5a96edb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig6dym2M-6Jm",
        "outputId": "9fc23f8a-8818-4670-8a29-5ad344823bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3sJDXlu-6Jm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-2RGi19W-6Jm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NqDqKYkQ-6Jm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingConfig:\n",
        "    BATCH_SIZE:       int   = 64\n",
        "    EPOCHS:           int   = 100\n",
        "    LEARNING_RATE:    float = 0.001\n",
        "    DROPOUT:          float = 0.5\n",
        "    LAYERS_FINE_TUNE: int   = 0\n",
        "    EPSILON:          float = 1e-07\n",
        "    MOMENTUM:         float = 0.9   \n",
        "    WEIGHT_DECAY:     float = 0.0005 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ0UVyCQ-6Jq"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = r\"C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\READY_BALANCED_SAME_SIZE_Random_Split\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knV1jDUD-6Jq",
        "outputId": "50f1446d-6355-4acd-f509-c5440328e53e"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hf-N_1PI-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\train\\\\Ads'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Ads_dir = os.path.join(train_dir, 'Ads')\n",
        "train_sample_dir = os.path.join(train_dir, 'Sample')\n",
        "train_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4lk-PK-6Jq",
        "outputId": "d9fbbdec-e425-4bd2-af75-32f3fbb86936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\validation\\\\Ads'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_Ads_dir = os.path.join(validation_dir, 'Ads')\n",
        "validation_sample_dir = os.path.join(validation_dir, 'Sample')\n",
        "validation_Ads_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JwHehlf4-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\test\\\\Ads'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Ads_dir = os.path.join(test_dir, 'Ads')\n",
        "test_sample_dir = os.path.join(test_dir, 'Sample')\n",
        "test_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fbi_AoAO-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training Ads images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training Ads images:', len(os.listdir(train_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h4bgQrIL-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training sample images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training sample images:', len(os.listdir(train_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YHrO9Y-6Jq",
        "outputId": "15bf628d-bf34-4ce7-ad11-fe568bf61432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation Ads images: 3650\n"
          ]
        }
      ],
      "source": [
        "print('total validation Ads images:', len(os.listdir(validation_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation sample images: 3950\n"
          ]
        }
      ],
      "source": [
        "print('total validation sample images:', len(os.listdir(validation_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test Ads images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test Ads images:', len(os.listdir(test_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test sample images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test sample images:', len(os.listdir(test_sample_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using data augmentation/ datagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "from tensorflow.keras.utils import img_to_array, array_to_img,  load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for color augmentation\n",
        "def color_jitter(image):\n",
        "    image = ImageEnhance.Brightness(image).enhance(np.random.uniform(0.4, 1.6)) # from -60% to +60%\n",
        "    image = ImageEnhance.Contrast(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    image = ImageEnhance.Color(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for ImageDataGenerator\n",
        "def custom_preprocessing_function(image):\n",
        "    # Convert array to PIL image\n",
        "    image = array_to_img(image)\n",
        "    # Apply color jitter\n",
        "    image = color_jitter(image)\n",
        "    # Convert PIL image back to array\n",
        "    image = img_to_array(image)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 images belonging to 2 classes.\n",
            "Found 7600 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "## with Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=custom_preprocessing_function)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretrained Model Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l38QgkUe-6Js"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4AL2-e8-6Js"
      },
      "source": [
        "# Appling a Pre-trained CNN on our Dataset for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcDjEV1-6Jt"
      },
      "source": [
        "The MobileNet model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OcyKdKno-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras.applications import DenseNet121\n",
        "\n",
        "conv_base = DenseNet121(weights='imagenet',\n",
        "                 include_top=False,\n",
        "                 input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRiAZIlI-6Jt",
        "outputId": "9254a8c6-9f28-4ea9-9b11-6553544bb4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVx8qd9U-6Jt"
      },
      "source": [
        "We will add a dense layer after our conv_base NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NwbCTdFB-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, AveragePooling2D\n",
        "\n",
        "modelPreTMob = models.Sequential()\n",
        "modelPreTMob.add(conv_base)\n",
        "\n",
        "modelPreTMob.add(layers.AveragePooling2D())\n",
        "modelPreTMob.add(layers.Flatten())\n",
        "modelPreTMob.add(layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "modelPreTMob.add(BatchNormalization())\n",
        "modelPreTMob.add(layers.Dropout(TrainingConfig.DROPOUT))\n",
        "modelPreTMob.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULwwwLKQ-6Jt",
        "outputId": "bca81ce0-c589-438d-d7f7-ddc78c5df1fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 9,314,177\n",
            "Non-trainable params: 84,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 True\n",
            "1 zero_padding2d True\n",
            "2 conv1/conv True\n",
            "3 conv1/bn True\n",
            "4 conv1/relu True\n",
            "5 zero_padding2d_1 True\n",
            "6 pool1 True\n",
            "7 conv2_block1_0_bn True\n",
            "8 conv2_block1_0_relu True\n",
            "9 conv2_block1_1_conv True\n",
            "10 conv2_block1_1_bn True\n",
            "11 conv2_block1_1_relu True\n",
            "12 conv2_block1_2_conv True\n",
            "13 conv2_block1_concat True\n",
            "14 conv2_block2_0_bn True\n",
            "15 conv2_block2_0_relu True\n",
            "16 conv2_block2_1_conv True\n",
            "17 conv2_block2_1_bn True\n",
            "18 conv2_block2_1_relu True\n",
            "19 conv2_block2_2_conv True\n",
            "20 conv2_block2_concat True\n",
            "21 conv2_block3_0_bn True\n",
            "22 conv2_block3_0_relu True\n",
            "23 conv2_block3_1_conv True\n",
            "24 conv2_block3_1_bn True\n",
            "25 conv2_block3_1_relu True\n",
            "26 conv2_block3_2_conv True\n",
            "27 conv2_block3_concat True\n",
            "28 conv2_block4_0_bn True\n",
            "29 conv2_block4_0_relu True\n",
            "30 conv2_block4_1_conv True\n",
            "31 conv2_block4_1_bn True\n",
            "32 conv2_block4_1_relu True\n",
            "33 conv2_block4_2_conv True\n",
            "34 conv2_block4_concat True\n",
            "35 conv2_block5_0_bn True\n",
            "36 conv2_block5_0_relu True\n",
            "37 conv2_block5_1_conv True\n",
            "38 conv2_block5_1_bn True\n",
            "39 conv2_block5_1_relu True\n",
            "40 conv2_block5_2_conv True\n",
            "41 conv2_block5_concat True\n",
            "42 conv2_block6_0_bn True\n",
            "43 conv2_block6_0_relu True\n",
            "44 conv2_block6_1_conv True\n",
            "45 conv2_block6_1_bn True\n",
            "46 conv2_block6_1_relu True\n",
            "47 conv2_block6_2_conv True\n",
            "48 conv2_block6_concat True\n",
            "49 pool2_bn True\n",
            "50 pool2_relu True\n",
            "51 pool2_conv True\n",
            "52 pool2_pool True\n",
            "53 conv3_block1_0_bn True\n",
            "54 conv3_block1_0_relu True\n",
            "55 conv3_block1_1_conv True\n",
            "56 conv3_block1_1_bn True\n",
            "57 conv3_block1_1_relu True\n",
            "58 conv3_block1_2_conv True\n",
            "59 conv3_block1_concat True\n",
            "60 conv3_block2_0_bn True\n",
            "61 conv3_block2_0_relu True\n",
            "62 conv3_block2_1_conv True\n",
            "63 conv3_block2_1_bn True\n",
            "64 conv3_block2_1_relu True\n",
            "65 conv3_block2_2_conv True\n",
            "66 conv3_block2_concat True\n",
            "67 conv3_block3_0_bn True\n",
            "68 conv3_block3_0_relu True\n",
            "69 conv3_block3_1_conv True\n",
            "70 conv3_block3_1_bn True\n",
            "71 conv3_block3_1_relu True\n",
            "72 conv3_block3_2_conv True\n",
            "73 conv3_block3_concat True\n",
            "74 conv3_block4_0_bn True\n",
            "75 conv3_block4_0_relu True\n",
            "76 conv3_block4_1_conv True\n",
            "77 conv3_block4_1_bn True\n",
            "78 conv3_block4_1_relu True\n",
            "79 conv3_block4_2_conv True\n",
            "80 conv3_block4_concat True\n",
            "81 conv3_block5_0_bn True\n",
            "82 conv3_block5_0_relu True\n",
            "83 conv3_block5_1_conv True\n",
            "84 conv3_block5_1_bn True\n",
            "85 conv3_block5_1_relu True\n",
            "86 conv3_block5_2_conv True\n",
            "87 conv3_block5_concat True\n",
            "88 conv3_block6_0_bn True\n",
            "89 conv3_block6_0_relu True\n",
            "90 conv3_block6_1_conv True\n",
            "91 conv3_block6_1_bn True\n",
            "92 conv3_block6_1_relu True\n",
            "93 conv3_block6_2_conv True\n",
            "94 conv3_block6_concat True\n",
            "95 conv3_block7_0_bn True\n",
            "96 conv3_block7_0_relu True\n",
            "97 conv3_block7_1_conv True\n",
            "98 conv3_block7_1_bn True\n",
            "99 conv3_block7_1_relu True\n",
            "100 conv3_block7_2_conv True\n",
            "101 conv3_block7_concat True\n",
            "102 conv3_block8_0_bn True\n",
            "103 conv3_block8_0_relu True\n",
            "104 conv3_block8_1_conv True\n",
            "105 conv3_block8_1_bn True\n",
            "106 conv3_block8_1_relu True\n",
            "107 conv3_block8_2_conv True\n",
            "108 conv3_block8_concat True\n",
            "109 conv3_block9_0_bn True\n",
            "110 conv3_block9_0_relu True\n",
            "111 conv3_block9_1_conv True\n",
            "112 conv3_block9_1_bn True\n",
            "113 conv3_block9_1_relu True\n",
            "114 conv3_block9_2_conv True\n",
            "115 conv3_block9_concat True\n",
            "116 conv3_block10_0_bn True\n",
            "117 conv3_block10_0_relu True\n",
            "118 conv3_block10_1_conv True\n",
            "119 conv3_block10_1_bn True\n",
            "120 conv3_block10_1_relu True\n",
            "121 conv3_block10_2_conv True\n",
            "122 conv3_block10_concat True\n",
            "123 conv3_block11_0_bn True\n",
            "124 conv3_block11_0_relu True\n",
            "125 conv3_block11_1_conv True\n",
            "126 conv3_block11_1_bn True\n",
            "127 conv3_block11_1_relu True\n",
            "128 conv3_block11_2_conv True\n",
            "129 conv3_block11_concat True\n",
            "130 conv3_block12_0_bn True\n",
            "131 conv3_block12_0_relu True\n",
            "132 conv3_block12_1_conv True\n",
            "133 conv3_block12_1_bn True\n",
            "134 conv3_block12_1_relu True\n",
            "135 conv3_block12_2_conv True\n",
            "136 conv3_block12_concat True\n",
            "137 pool3_bn True\n",
            "138 pool3_relu True\n",
            "139 pool3_conv True\n",
            "140 pool3_pool True\n",
            "141 conv4_block1_0_bn True\n",
            "142 conv4_block1_0_relu True\n",
            "143 conv4_block1_1_conv True\n",
            "144 conv4_block1_1_bn True\n",
            "145 conv4_block1_1_relu True\n",
            "146 conv4_block1_2_conv True\n",
            "147 conv4_block1_concat True\n",
            "148 conv4_block2_0_bn True\n",
            "149 conv4_block2_0_relu True\n",
            "150 conv4_block2_1_conv True\n",
            "151 conv4_block2_1_bn True\n",
            "152 conv4_block2_1_relu True\n",
            "153 conv4_block2_2_conv True\n",
            "154 conv4_block2_concat True\n",
            "155 conv4_block3_0_bn True\n",
            "156 conv4_block3_0_relu True\n",
            "157 conv4_block3_1_conv True\n",
            "158 conv4_block3_1_bn True\n",
            "159 conv4_block3_1_relu True\n",
            "160 conv4_block3_2_conv True\n",
            "161 conv4_block3_concat True\n",
            "162 conv4_block4_0_bn True\n",
            "163 conv4_block4_0_relu True\n",
            "164 conv4_block4_1_conv True\n",
            "165 conv4_block4_1_bn True\n",
            "166 conv4_block4_1_relu True\n",
            "167 conv4_block4_2_conv True\n",
            "168 conv4_block4_concat True\n",
            "169 conv4_block5_0_bn True\n",
            "170 conv4_block5_0_relu True\n",
            "171 conv4_block5_1_conv True\n",
            "172 conv4_block5_1_bn True\n",
            "173 conv4_block5_1_relu True\n",
            "174 conv4_block5_2_conv True\n",
            "175 conv4_block5_concat True\n",
            "176 conv4_block6_0_bn True\n",
            "177 conv4_block6_0_relu True\n",
            "178 conv4_block6_1_conv True\n",
            "179 conv4_block6_1_bn True\n",
            "180 conv4_block6_1_relu True\n",
            "181 conv4_block6_2_conv True\n",
            "182 conv4_block6_concat True\n",
            "183 conv4_block7_0_bn True\n",
            "184 conv4_block7_0_relu True\n",
            "185 conv4_block7_1_conv True\n",
            "186 conv4_block7_1_bn True\n",
            "187 conv4_block7_1_relu True\n",
            "188 conv4_block7_2_conv True\n",
            "189 conv4_block7_concat True\n",
            "190 conv4_block8_0_bn True\n",
            "191 conv4_block8_0_relu True\n",
            "192 conv4_block8_1_conv True\n",
            "193 conv4_block8_1_bn True\n",
            "194 conv4_block8_1_relu True\n",
            "195 conv4_block8_2_conv True\n",
            "196 conv4_block8_concat True\n",
            "197 conv4_block9_0_bn True\n",
            "198 conv4_block9_0_relu True\n",
            "199 conv4_block9_1_conv True\n",
            "200 conv4_block9_1_bn True\n",
            "201 conv4_block9_1_relu True\n",
            "202 conv4_block9_2_conv True\n",
            "203 conv4_block9_concat True\n",
            "204 conv4_block10_0_bn True\n",
            "205 conv4_block10_0_relu True\n",
            "206 conv4_block10_1_conv True\n",
            "207 conv4_block10_1_bn True\n",
            "208 conv4_block10_1_relu True\n",
            "209 conv4_block10_2_conv True\n",
            "210 conv4_block10_concat True\n",
            "211 conv4_block11_0_bn True\n",
            "212 conv4_block11_0_relu True\n",
            "213 conv4_block11_1_conv True\n",
            "214 conv4_block11_1_bn True\n",
            "215 conv4_block11_1_relu True\n",
            "216 conv4_block11_2_conv True\n",
            "217 conv4_block11_concat True\n",
            "218 conv4_block12_0_bn True\n",
            "219 conv4_block12_0_relu True\n",
            "220 conv4_block12_1_conv True\n",
            "221 conv4_block12_1_bn True\n",
            "222 conv4_block12_1_relu True\n",
            "223 conv4_block12_2_conv True\n",
            "224 conv4_block12_concat True\n",
            "225 conv4_block13_0_bn True\n",
            "226 conv4_block13_0_relu True\n",
            "227 conv4_block13_1_conv True\n",
            "228 conv4_block13_1_bn True\n",
            "229 conv4_block13_1_relu True\n",
            "230 conv4_block13_2_conv True\n",
            "231 conv4_block13_concat True\n",
            "232 conv4_block14_0_bn True\n",
            "233 conv4_block14_0_relu True\n",
            "234 conv4_block14_1_conv True\n",
            "235 conv4_block14_1_bn True\n",
            "236 conv4_block14_1_relu True\n",
            "237 conv4_block14_2_conv True\n",
            "238 conv4_block14_concat True\n",
            "239 conv4_block15_0_bn True\n",
            "240 conv4_block15_0_relu True\n",
            "241 conv4_block15_1_conv True\n",
            "242 conv4_block15_1_bn True\n",
            "243 conv4_block15_1_relu True\n",
            "244 conv4_block15_2_conv True\n",
            "245 conv4_block15_concat True\n",
            "246 conv4_block16_0_bn True\n",
            "247 conv4_block16_0_relu True\n",
            "248 conv4_block16_1_conv True\n",
            "249 conv4_block16_1_bn True\n",
            "250 conv4_block16_1_relu True\n",
            "251 conv4_block16_2_conv True\n",
            "252 conv4_block16_concat True\n",
            "253 conv4_block17_0_bn True\n",
            "254 conv4_block17_0_relu True\n",
            "255 conv4_block17_1_conv True\n",
            "256 conv4_block17_1_bn True\n",
            "257 conv4_block17_1_relu True\n",
            "258 conv4_block17_2_conv True\n",
            "259 conv4_block17_concat True\n",
            "260 conv4_block18_0_bn True\n",
            "261 conv4_block18_0_relu True\n",
            "262 conv4_block18_1_conv True\n",
            "263 conv4_block18_1_bn True\n",
            "264 conv4_block18_1_relu True\n",
            "265 conv4_block18_2_conv True\n",
            "266 conv4_block18_concat True\n",
            "267 conv4_block19_0_bn True\n",
            "268 conv4_block19_0_relu True\n",
            "269 conv4_block19_1_conv True\n",
            "270 conv4_block19_1_bn True\n",
            "271 conv4_block19_1_relu True\n",
            "272 conv4_block19_2_conv True\n",
            "273 conv4_block19_concat True\n",
            "274 conv4_block20_0_bn True\n",
            "275 conv4_block20_0_relu True\n",
            "276 conv4_block20_1_conv True\n",
            "277 conv4_block20_1_bn True\n",
            "278 conv4_block20_1_relu True\n",
            "279 conv4_block20_2_conv True\n",
            "280 conv4_block20_concat True\n",
            "281 conv4_block21_0_bn True\n",
            "282 conv4_block21_0_relu True\n",
            "283 conv4_block21_1_conv True\n",
            "284 conv4_block21_1_bn True\n",
            "285 conv4_block21_1_relu True\n",
            "286 conv4_block21_2_conv True\n",
            "287 conv4_block21_concat True\n",
            "288 conv4_block22_0_bn True\n",
            "289 conv4_block22_0_relu True\n",
            "290 conv4_block22_1_conv True\n",
            "291 conv4_block22_1_bn True\n",
            "292 conv4_block22_1_relu True\n",
            "293 conv4_block22_2_conv True\n",
            "294 conv4_block22_concat True\n",
            "295 conv4_block23_0_bn True\n",
            "296 conv4_block23_0_relu True\n",
            "297 conv4_block23_1_conv True\n",
            "298 conv4_block23_1_bn True\n",
            "299 conv4_block23_1_relu True\n",
            "300 conv4_block23_2_conv True\n",
            "301 conv4_block23_concat True\n",
            "302 conv4_block24_0_bn True\n",
            "303 conv4_block24_0_relu True\n",
            "304 conv4_block24_1_conv True\n",
            "305 conv4_block24_1_bn True\n",
            "306 conv4_block24_1_relu True\n",
            "307 conv4_block24_2_conv True\n",
            "308 conv4_block24_concat True\n",
            "309 pool4_bn True\n",
            "310 pool4_relu True\n",
            "311 pool4_conv True\n",
            "312 pool4_pool True\n",
            "313 conv5_block1_0_bn True\n",
            "314 conv5_block1_0_relu True\n",
            "315 conv5_block1_1_conv True\n",
            "316 conv5_block1_1_bn True\n",
            "317 conv5_block1_1_relu True\n",
            "318 conv5_block1_2_conv True\n",
            "319 conv5_block1_concat True\n",
            "320 conv5_block2_0_bn True\n",
            "321 conv5_block2_0_relu True\n",
            "322 conv5_block2_1_conv True\n",
            "323 conv5_block2_1_bn True\n",
            "324 conv5_block2_1_relu True\n",
            "325 conv5_block2_2_conv True\n",
            "326 conv5_block2_concat True\n",
            "327 conv5_block3_0_bn True\n",
            "328 conv5_block3_0_relu True\n",
            "329 conv5_block3_1_conv True\n",
            "330 conv5_block3_1_bn True\n",
            "331 conv5_block3_1_relu True\n",
            "332 conv5_block3_2_conv True\n",
            "333 conv5_block3_concat True\n",
            "334 conv5_block4_0_bn True\n",
            "335 conv5_block4_0_relu True\n",
            "336 conv5_block4_1_conv True\n",
            "337 conv5_block4_1_bn True\n",
            "338 conv5_block4_1_relu True\n",
            "339 conv5_block4_2_conv True\n",
            "340 conv5_block4_concat True\n",
            "341 conv5_block5_0_bn True\n",
            "342 conv5_block5_0_relu True\n",
            "343 conv5_block5_1_conv True\n",
            "344 conv5_block5_1_bn True\n",
            "345 conv5_block5_1_relu True\n",
            "346 conv5_block5_2_conv True\n",
            "347 conv5_block5_concat True\n",
            "348 conv5_block6_0_bn True\n",
            "349 conv5_block6_0_relu True\n",
            "350 conv5_block6_1_conv True\n",
            "351 conv5_block6_1_bn True\n",
            "352 conv5_block6_1_relu True\n",
            "353 conv5_block6_2_conv True\n",
            "354 conv5_block6_concat True\n",
            "355 conv5_block7_0_bn True\n",
            "356 conv5_block7_0_relu True\n",
            "357 conv5_block7_1_conv True\n",
            "358 conv5_block7_1_bn True\n",
            "359 conv5_block7_1_relu True\n",
            "360 conv5_block7_2_conv True\n",
            "361 conv5_block7_concat True\n",
            "362 conv5_block8_0_bn True\n",
            "363 conv5_block8_0_relu True\n",
            "364 conv5_block8_1_conv True\n",
            "365 conv5_block8_1_bn True\n",
            "366 conv5_block8_1_relu True\n",
            "367 conv5_block8_2_conv True\n",
            "368 conv5_block8_concat True\n",
            "369 conv5_block9_0_bn True\n",
            "370 conv5_block9_0_relu True\n",
            "371 conv5_block9_1_conv True\n",
            "372 conv5_block9_1_bn True\n",
            "373 conv5_block9_1_relu True\n",
            "374 conv5_block9_2_conv True\n",
            "375 conv5_block9_concat True\n",
            "376 conv5_block10_0_bn True\n",
            "377 conv5_block10_0_relu True\n",
            "378 conv5_block10_1_conv True\n",
            "379 conv5_block10_1_bn True\n",
            "380 conv5_block10_1_relu True\n",
            "381 conv5_block10_2_conv True\n",
            "382 conv5_block10_concat True\n",
            "383 conv5_block11_0_bn True\n",
            "384 conv5_block11_0_relu True\n",
            "385 conv5_block11_1_conv True\n",
            "386 conv5_block11_1_bn True\n",
            "387 conv5_block11_1_relu True\n",
            "388 conv5_block11_2_conv True\n",
            "389 conv5_block11_concat True\n",
            "390 conv5_block12_0_bn True\n",
            "391 conv5_block12_0_relu True\n",
            "392 conv5_block12_1_conv True\n",
            "393 conv5_block12_1_bn True\n",
            "394 conv5_block12_1_relu True\n",
            "395 conv5_block12_2_conv True\n",
            "396 conv5_block12_concat True\n",
            "397 conv5_block13_0_bn True\n",
            "398 conv5_block13_0_relu True\n",
            "399 conv5_block13_1_conv True\n",
            "400 conv5_block13_1_bn True\n",
            "401 conv5_block13_1_relu True\n",
            "402 conv5_block13_2_conv True\n",
            "403 conv5_block13_concat True\n",
            "404 conv5_block14_0_bn True\n",
            "405 conv5_block14_0_relu True\n",
            "406 conv5_block14_1_conv True\n",
            "407 conv5_block14_1_bn True\n",
            "408 conv5_block14_1_relu True\n",
            "409 conv5_block14_2_conv True\n",
            "410 conv5_block14_concat True\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the number of layers to fine tune at the end of the convolutional base.\n",
        "num_layers_fine_tune = TrainingConfig.LAYERS_FINE_TUNE\n",
        "num_layers = len(conv_base.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg5O_dq-6Jt",
        "outputId": "0b8e8703-9f13-4415-d6a7-fc5af46bc1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 368\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'before freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FREEZING LAYER: <keras.engine.input_layer.InputLayer object at 0x000002A828DBA6A0>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000002A828DF9220>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A828DDA2E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A828DE12E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A828DDAC10>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x000002A828DE8100>\n",
            "FREEZING LAYER: <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002A828DEF6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A828DEF2E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A828DEF160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A828DF7D00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C0B790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A828DF70D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C10C70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C1D760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C1DD30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C179A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C25580>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C25F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C25370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C2B8B0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C2E610>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C2ED60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C29D60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C3C760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C42460>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C3C730>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C29880>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C2B130>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C4DF10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C4AEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C56940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C5ACA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C56160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C4D400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C4AC10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C5F4F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C65EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C6E9D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C71E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C71190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C5F550>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C56280>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C7E1F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C7BFD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C85BB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C8BE50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C8B370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C7E7F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C423D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C2E940>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C56250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C1D160>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000002A837C91E50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C1D5E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A828DEFB80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C08B50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C8DE50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C2E5E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A828DF7C70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C9BE20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C9BAC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C9B400>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CA0E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CA5820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CA0280>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CAAEB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C9B4C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CA9670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CAAA60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CB7D60>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CBD880>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CBDD00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CC1340>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837CCAA60>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CCAFD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CC1370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CD5340>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CCDE20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CCDD00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CD2610>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837CE67C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CE6D90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CDDA30>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CEF520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CF4130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CEF040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CE60D0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863001640>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863001D90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863001C10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CE66A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CCACD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CAA730>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837CA0190>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A828DF7DC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C082E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C4A160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863009220>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863009E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C2E760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A86300C460>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A86300E340>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A86300E9A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C2E820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863017490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A86301CF70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863017FA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863010F40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863028910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863028E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863025BE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630306D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630333A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630172E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863028250>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863040760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863040EB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A86303CEB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863049850>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A86304ECA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863049190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863040310>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A86303C070>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863059490>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863056FD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863061940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630683A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863061250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630591F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863073B20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630733A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863070340>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863040AC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C08520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630496A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863059B80>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837CF4400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A86307CAF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A86307CA90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863075850>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000002A8630820D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863075670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863082070>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863084A00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863086CA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630842B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630755B0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863075730>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863091820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630918B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863099CA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A86309D4F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630990A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863091550>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630A96D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630A95B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630A9490>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630B0E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630B56D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A820957820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630A9550>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A820970670>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630C3F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A7D376EE80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630CA310>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630BCE20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630C3F40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630C3D00>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630DC190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630DC2B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630BCF70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630E2370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630EBEE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630EBEB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630E26A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630BC7C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630B0040>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630A34F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863086E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863033EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630B0F10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863059A90>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863091F10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630DCEB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863091D00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863084040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A86308D430>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630E2790>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630F8AC0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630F89D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B704DF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630F8D60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630FAA90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B712C10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630FADC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B712E50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630D3A60>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B71AEB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B70AE80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B721040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630F5910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B704940>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B729F70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B71A400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B733A00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B721FD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B73A160>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B712550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B733FA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B73A700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B729EE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B74B220>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B73A340>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B73A6A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B75AF40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B74BA60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B751220>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B721CD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B712A30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B75A0D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B73A580>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863082820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7213D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630A9FD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630B5BB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B761D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7433D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B761490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B751F40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B70AC40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B761850>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B766AC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630F59D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B766E50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7790A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B780CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B780CA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B780F10>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B773C40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630F81F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B779F70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7900D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630F8A30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B788F10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B790700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7803D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B779310>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7881F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7A73A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7B0EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7A0040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B790100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B790F70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B797760>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7A0370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B790FA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7C8160>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7BABB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7BAFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B790EB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B780D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7C8310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7B0D30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7BAAC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B790460>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B71AC40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B773DC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7D2D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7BF6D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7D6040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7665E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B780430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7D9EB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7D2490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7DFF10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7D6EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7E9070>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B761FA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7DFEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7EFFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7DF520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7D9550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7E9250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE00190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7D9520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7FA430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7EF670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7EFF40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7E9DC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7FA310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B7EF340>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE1F130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE10B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE096A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BE2B400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE2B610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE1F100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE007F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE399D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE39190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE2FC70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BE00F10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7FAF70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE39430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE1F0A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7793D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE005B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B780970>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7DFC10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B797790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7D9BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE47040>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x000002A91BE4AD00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630611F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE2F9A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE476D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91B7D2CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7D2DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE50A00>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7D2820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE5FA60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B797B50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE5FB50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE688E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B7D6E50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE68BE0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BE687F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE78250>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE68B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE78B20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE7F2E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE6BDC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE78C40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BE7F910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE90100>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE7FCA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE6B6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE98B50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE7FD00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE98370>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BEA8910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BEA8130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE98DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE981F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE5F910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE5F760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE50040>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BE85940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630F5340>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE90C40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE56280>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE909D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91B743700>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE10FD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BE90A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BEB99D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BEA8BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BE56190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BE4AF70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BE4AC40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BEB6520>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BEB99A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BECD790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BEBFAF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BECD610>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BEBFB50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BEBF850>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BED5CD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BED5880>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BEE5370>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BED5C70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BEB6820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BECDE20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BECD400>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BEEFCA0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BEEFA00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BEE80D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BEEFD90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BEF4A90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BF0EC10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BEF4E20>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BF0EE50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91BF169D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BF161F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BF0E0A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BEE89D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BEC63A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A91BEC6520>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C4ACD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C7B2E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C4A970>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C29B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C25460>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C56430>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C250A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C2E910>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837CA9490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C2EB50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CBDCA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C9B1F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C9BDF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837C107F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A837C3C3D0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A837C6E220>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CDD4C0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CDDDF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863030340>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A8630302E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A86301C850>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863010DF0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A863010BB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CEF0A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A837CEF460>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A863028A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837CC1D00>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630593D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A8630845E0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A8630847C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A837C7E610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A863075D30>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91BEEF490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A863099670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630B58E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002A91B751100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x000002A91B7C8EB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000002A91BF167F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x000002A8630EB040>\n"
          ]
        }
      ],
      "source": [
        "# Freeze the initial layers in the convolutional base.\n",
        "for model_layer in conv_base.layers[:num_layers - num_layers_fine_tune]:\n",
        "    print(f\"FREEZING LAYER: {model_layer}\")\n",
        "    model_layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 zero_padding2d False\n",
            "2 conv1/conv False\n",
            "3 conv1/bn False\n",
            "4 conv1/relu False\n",
            "5 zero_padding2d_1 False\n",
            "6 pool1 False\n",
            "7 conv2_block1_0_bn False\n",
            "8 conv2_block1_0_relu False\n",
            "9 conv2_block1_1_conv False\n",
            "10 conv2_block1_1_bn False\n",
            "11 conv2_block1_1_relu False\n",
            "12 conv2_block1_2_conv False\n",
            "13 conv2_block1_concat False\n",
            "14 conv2_block2_0_bn False\n",
            "15 conv2_block2_0_relu False\n",
            "16 conv2_block2_1_conv False\n",
            "17 conv2_block2_1_bn False\n",
            "18 conv2_block2_1_relu False\n",
            "19 conv2_block2_2_conv False\n",
            "20 conv2_block2_concat False\n",
            "21 conv2_block3_0_bn False\n",
            "22 conv2_block3_0_relu False\n",
            "23 conv2_block3_1_conv False\n",
            "24 conv2_block3_1_bn False\n",
            "25 conv2_block3_1_relu False\n",
            "26 conv2_block3_2_conv False\n",
            "27 conv2_block3_concat False\n",
            "28 conv2_block4_0_bn False\n",
            "29 conv2_block4_0_relu False\n",
            "30 conv2_block4_1_conv False\n",
            "31 conv2_block4_1_bn False\n",
            "32 conv2_block4_1_relu False\n",
            "33 conv2_block4_2_conv False\n",
            "34 conv2_block4_concat False\n",
            "35 conv2_block5_0_bn False\n",
            "36 conv2_block5_0_relu False\n",
            "37 conv2_block5_1_conv False\n",
            "38 conv2_block5_1_bn False\n",
            "39 conv2_block5_1_relu False\n",
            "40 conv2_block5_2_conv False\n",
            "41 conv2_block5_concat False\n",
            "42 conv2_block6_0_bn False\n",
            "43 conv2_block6_0_relu False\n",
            "44 conv2_block6_1_conv False\n",
            "45 conv2_block6_1_bn False\n",
            "46 conv2_block6_1_relu False\n",
            "47 conv2_block6_2_conv False\n",
            "48 conv2_block6_concat False\n",
            "49 pool2_bn False\n",
            "50 pool2_relu False\n",
            "51 pool2_conv False\n",
            "52 pool2_pool False\n",
            "53 conv3_block1_0_bn False\n",
            "54 conv3_block1_0_relu False\n",
            "55 conv3_block1_1_conv False\n",
            "56 conv3_block1_1_bn False\n",
            "57 conv3_block1_1_relu False\n",
            "58 conv3_block1_2_conv False\n",
            "59 conv3_block1_concat False\n",
            "60 conv3_block2_0_bn False\n",
            "61 conv3_block2_0_relu False\n",
            "62 conv3_block2_1_conv False\n",
            "63 conv3_block2_1_bn False\n",
            "64 conv3_block2_1_relu False\n",
            "65 conv3_block2_2_conv False\n",
            "66 conv3_block2_concat False\n",
            "67 conv3_block3_0_bn False\n",
            "68 conv3_block3_0_relu False\n",
            "69 conv3_block3_1_conv False\n",
            "70 conv3_block3_1_bn False\n",
            "71 conv3_block3_1_relu False\n",
            "72 conv3_block3_2_conv False\n",
            "73 conv3_block3_concat False\n",
            "74 conv3_block4_0_bn False\n",
            "75 conv3_block4_0_relu False\n",
            "76 conv3_block4_1_conv False\n",
            "77 conv3_block4_1_bn False\n",
            "78 conv3_block4_1_relu False\n",
            "79 conv3_block4_2_conv False\n",
            "80 conv3_block4_concat False\n",
            "81 conv3_block5_0_bn False\n",
            "82 conv3_block5_0_relu False\n",
            "83 conv3_block5_1_conv False\n",
            "84 conv3_block5_1_bn False\n",
            "85 conv3_block5_1_relu False\n",
            "86 conv3_block5_2_conv False\n",
            "87 conv3_block5_concat False\n",
            "88 conv3_block6_0_bn False\n",
            "89 conv3_block6_0_relu False\n",
            "90 conv3_block6_1_conv False\n",
            "91 conv3_block6_1_bn False\n",
            "92 conv3_block6_1_relu False\n",
            "93 conv3_block6_2_conv False\n",
            "94 conv3_block6_concat False\n",
            "95 conv3_block7_0_bn False\n",
            "96 conv3_block7_0_relu False\n",
            "97 conv3_block7_1_conv False\n",
            "98 conv3_block7_1_bn False\n",
            "99 conv3_block7_1_relu False\n",
            "100 conv3_block7_2_conv False\n",
            "101 conv3_block7_concat False\n",
            "102 conv3_block8_0_bn False\n",
            "103 conv3_block8_0_relu False\n",
            "104 conv3_block8_1_conv False\n",
            "105 conv3_block8_1_bn False\n",
            "106 conv3_block8_1_relu False\n",
            "107 conv3_block8_2_conv False\n",
            "108 conv3_block8_concat False\n",
            "109 conv3_block9_0_bn False\n",
            "110 conv3_block9_0_relu False\n",
            "111 conv3_block9_1_conv False\n",
            "112 conv3_block9_1_bn False\n",
            "113 conv3_block9_1_relu False\n",
            "114 conv3_block9_2_conv False\n",
            "115 conv3_block9_concat False\n",
            "116 conv3_block10_0_bn False\n",
            "117 conv3_block10_0_relu False\n",
            "118 conv3_block10_1_conv False\n",
            "119 conv3_block10_1_bn False\n",
            "120 conv3_block10_1_relu False\n",
            "121 conv3_block10_2_conv False\n",
            "122 conv3_block10_concat False\n",
            "123 conv3_block11_0_bn False\n",
            "124 conv3_block11_0_relu False\n",
            "125 conv3_block11_1_conv False\n",
            "126 conv3_block11_1_bn False\n",
            "127 conv3_block11_1_relu False\n",
            "128 conv3_block11_2_conv False\n",
            "129 conv3_block11_concat False\n",
            "130 conv3_block12_0_bn False\n",
            "131 conv3_block12_0_relu False\n",
            "132 conv3_block12_1_conv False\n",
            "133 conv3_block12_1_bn False\n",
            "134 conv3_block12_1_relu False\n",
            "135 conv3_block12_2_conv False\n",
            "136 conv3_block12_concat False\n",
            "137 pool3_bn False\n",
            "138 pool3_relu False\n",
            "139 pool3_conv False\n",
            "140 pool3_pool False\n",
            "141 conv4_block1_0_bn False\n",
            "142 conv4_block1_0_relu False\n",
            "143 conv4_block1_1_conv False\n",
            "144 conv4_block1_1_bn False\n",
            "145 conv4_block1_1_relu False\n",
            "146 conv4_block1_2_conv False\n",
            "147 conv4_block1_concat False\n",
            "148 conv4_block2_0_bn False\n",
            "149 conv4_block2_0_relu False\n",
            "150 conv4_block2_1_conv False\n",
            "151 conv4_block2_1_bn False\n",
            "152 conv4_block2_1_relu False\n",
            "153 conv4_block2_2_conv False\n",
            "154 conv4_block2_concat False\n",
            "155 conv4_block3_0_bn False\n",
            "156 conv4_block3_0_relu False\n",
            "157 conv4_block3_1_conv False\n",
            "158 conv4_block3_1_bn False\n",
            "159 conv4_block3_1_relu False\n",
            "160 conv4_block3_2_conv False\n",
            "161 conv4_block3_concat False\n",
            "162 conv4_block4_0_bn False\n",
            "163 conv4_block4_0_relu False\n",
            "164 conv4_block4_1_conv False\n",
            "165 conv4_block4_1_bn False\n",
            "166 conv4_block4_1_relu False\n",
            "167 conv4_block4_2_conv False\n",
            "168 conv4_block4_concat False\n",
            "169 conv4_block5_0_bn False\n",
            "170 conv4_block5_0_relu False\n",
            "171 conv4_block5_1_conv False\n",
            "172 conv4_block5_1_bn False\n",
            "173 conv4_block5_1_relu False\n",
            "174 conv4_block5_2_conv False\n",
            "175 conv4_block5_concat False\n",
            "176 conv4_block6_0_bn False\n",
            "177 conv4_block6_0_relu False\n",
            "178 conv4_block6_1_conv False\n",
            "179 conv4_block6_1_bn False\n",
            "180 conv4_block6_1_relu False\n",
            "181 conv4_block6_2_conv False\n",
            "182 conv4_block6_concat False\n",
            "183 conv4_block7_0_bn False\n",
            "184 conv4_block7_0_relu False\n",
            "185 conv4_block7_1_conv False\n",
            "186 conv4_block7_1_bn False\n",
            "187 conv4_block7_1_relu False\n",
            "188 conv4_block7_2_conv False\n",
            "189 conv4_block7_concat False\n",
            "190 conv4_block8_0_bn False\n",
            "191 conv4_block8_0_relu False\n",
            "192 conv4_block8_1_conv False\n",
            "193 conv4_block8_1_bn False\n",
            "194 conv4_block8_1_relu False\n",
            "195 conv4_block8_2_conv False\n",
            "196 conv4_block8_concat False\n",
            "197 conv4_block9_0_bn False\n",
            "198 conv4_block9_0_relu False\n",
            "199 conv4_block9_1_conv False\n",
            "200 conv4_block9_1_bn False\n",
            "201 conv4_block9_1_relu False\n",
            "202 conv4_block9_2_conv False\n",
            "203 conv4_block9_concat False\n",
            "204 conv4_block10_0_bn False\n",
            "205 conv4_block10_0_relu False\n",
            "206 conv4_block10_1_conv False\n",
            "207 conv4_block10_1_bn False\n",
            "208 conv4_block10_1_relu False\n",
            "209 conv4_block10_2_conv False\n",
            "210 conv4_block10_concat False\n",
            "211 conv4_block11_0_bn False\n",
            "212 conv4_block11_0_relu False\n",
            "213 conv4_block11_1_conv False\n",
            "214 conv4_block11_1_bn False\n",
            "215 conv4_block11_1_relu False\n",
            "216 conv4_block11_2_conv False\n",
            "217 conv4_block11_concat False\n",
            "218 conv4_block12_0_bn False\n",
            "219 conv4_block12_0_relu False\n",
            "220 conv4_block12_1_conv False\n",
            "221 conv4_block12_1_bn False\n",
            "222 conv4_block12_1_relu False\n",
            "223 conv4_block12_2_conv False\n",
            "224 conv4_block12_concat False\n",
            "225 conv4_block13_0_bn False\n",
            "226 conv4_block13_0_relu False\n",
            "227 conv4_block13_1_conv False\n",
            "228 conv4_block13_1_bn False\n",
            "229 conv4_block13_1_relu False\n",
            "230 conv4_block13_2_conv False\n",
            "231 conv4_block13_concat False\n",
            "232 conv4_block14_0_bn False\n",
            "233 conv4_block14_0_relu False\n",
            "234 conv4_block14_1_conv False\n",
            "235 conv4_block14_1_bn False\n",
            "236 conv4_block14_1_relu False\n",
            "237 conv4_block14_2_conv False\n",
            "238 conv4_block14_concat False\n",
            "239 conv4_block15_0_bn False\n",
            "240 conv4_block15_0_relu False\n",
            "241 conv4_block15_1_conv False\n",
            "242 conv4_block15_1_bn False\n",
            "243 conv4_block15_1_relu False\n",
            "244 conv4_block15_2_conv False\n",
            "245 conv4_block15_concat False\n",
            "246 conv4_block16_0_bn False\n",
            "247 conv4_block16_0_relu False\n",
            "248 conv4_block16_1_conv False\n",
            "249 conv4_block16_1_bn False\n",
            "250 conv4_block16_1_relu False\n",
            "251 conv4_block16_2_conv False\n",
            "252 conv4_block16_concat False\n",
            "253 conv4_block17_0_bn False\n",
            "254 conv4_block17_0_relu False\n",
            "255 conv4_block17_1_conv False\n",
            "256 conv4_block17_1_bn False\n",
            "257 conv4_block17_1_relu False\n",
            "258 conv4_block17_2_conv False\n",
            "259 conv4_block17_concat False\n",
            "260 conv4_block18_0_bn False\n",
            "261 conv4_block18_0_relu False\n",
            "262 conv4_block18_1_conv False\n",
            "263 conv4_block18_1_bn False\n",
            "264 conv4_block18_1_relu False\n",
            "265 conv4_block18_2_conv False\n",
            "266 conv4_block18_concat False\n",
            "267 conv4_block19_0_bn False\n",
            "268 conv4_block19_0_relu False\n",
            "269 conv4_block19_1_conv False\n",
            "270 conv4_block19_1_bn False\n",
            "271 conv4_block19_1_relu False\n",
            "272 conv4_block19_2_conv False\n",
            "273 conv4_block19_concat False\n",
            "274 conv4_block20_0_bn False\n",
            "275 conv4_block20_0_relu False\n",
            "276 conv4_block20_1_conv False\n",
            "277 conv4_block20_1_bn False\n",
            "278 conv4_block20_1_relu False\n",
            "279 conv4_block20_2_conv False\n",
            "280 conv4_block20_concat False\n",
            "281 conv4_block21_0_bn False\n",
            "282 conv4_block21_0_relu False\n",
            "283 conv4_block21_1_conv False\n",
            "284 conv4_block21_1_bn False\n",
            "285 conv4_block21_1_relu False\n",
            "286 conv4_block21_2_conv False\n",
            "287 conv4_block21_concat False\n",
            "288 conv4_block22_0_bn False\n",
            "289 conv4_block22_0_relu False\n",
            "290 conv4_block22_1_conv False\n",
            "291 conv4_block22_1_bn False\n",
            "292 conv4_block22_1_relu False\n",
            "293 conv4_block22_2_conv False\n",
            "294 conv4_block22_concat False\n",
            "295 conv4_block23_0_bn False\n",
            "296 conv4_block23_0_relu False\n",
            "297 conv4_block23_1_conv False\n",
            "298 conv4_block23_1_bn False\n",
            "299 conv4_block23_1_relu False\n",
            "300 conv4_block23_2_conv False\n",
            "301 conv4_block23_concat False\n",
            "302 conv4_block24_0_bn False\n",
            "303 conv4_block24_0_relu False\n",
            "304 conv4_block24_1_conv False\n",
            "305 conv4_block24_1_bn False\n",
            "306 conv4_block24_1_relu False\n",
            "307 conv4_block24_2_conv False\n",
            "308 conv4_block24_concat False\n",
            "309 pool4_bn False\n",
            "310 pool4_relu False\n",
            "311 pool4_conv False\n",
            "312 pool4_pool False\n",
            "313 conv5_block1_0_bn False\n",
            "314 conv5_block1_0_relu False\n",
            "315 conv5_block1_1_conv False\n",
            "316 conv5_block1_1_bn False\n",
            "317 conv5_block1_1_relu False\n",
            "318 conv5_block1_2_conv False\n",
            "319 conv5_block1_concat False\n",
            "320 conv5_block2_0_bn False\n",
            "321 conv5_block2_0_relu False\n",
            "322 conv5_block2_1_conv False\n",
            "323 conv5_block2_1_bn False\n",
            "324 conv5_block2_1_relu False\n",
            "325 conv5_block2_2_conv False\n",
            "326 conv5_block2_concat False\n",
            "327 conv5_block3_0_bn False\n",
            "328 conv5_block3_0_relu False\n",
            "329 conv5_block3_1_conv False\n",
            "330 conv5_block3_1_bn False\n",
            "331 conv5_block3_1_relu False\n",
            "332 conv5_block3_2_conv False\n",
            "333 conv5_block3_concat False\n",
            "334 conv5_block4_0_bn False\n",
            "335 conv5_block4_0_relu False\n",
            "336 conv5_block4_1_conv False\n",
            "337 conv5_block4_1_bn False\n",
            "338 conv5_block4_1_relu False\n",
            "339 conv5_block4_2_conv False\n",
            "340 conv5_block4_concat False\n",
            "341 conv5_block5_0_bn False\n",
            "342 conv5_block5_0_relu False\n",
            "343 conv5_block5_1_conv False\n",
            "344 conv5_block5_1_bn False\n",
            "345 conv5_block5_1_relu False\n",
            "346 conv5_block5_2_conv False\n",
            "347 conv5_block5_concat False\n",
            "348 conv5_block6_0_bn False\n",
            "349 conv5_block6_0_relu False\n",
            "350 conv5_block6_1_conv False\n",
            "351 conv5_block6_1_bn False\n",
            "352 conv5_block6_1_relu False\n",
            "353 conv5_block6_2_conv False\n",
            "354 conv5_block6_concat False\n",
            "355 conv5_block7_0_bn False\n",
            "356 conv5_block7_0_relu False\n",
            "357 conv5_block7_1_conv False\n",
            "358 conv5_block7_1_bn False\n",
            "359 conv5_block7_1_relu False\n",
            "360 conv5_block7_2_conv False\n",
            "361 conv5_block7_concat False\n",
            "362 conv5_block8_0_bn False\n",
            "363 conv5_block8_0_relu False\n",
            "364 conv5_block8_1_conv False\n",
            "365 conv5_block8_1_bn False\n",
            "366 conv5_block8_1_relu False\n",
            "367 conv5_block8_2_conv False\n",
            "368 conv5_block8_concat False\n",
            "369 conv5_block9_0_bn False\n",
            "370 conv5_block9_0_relu False\n",
            "371 conv5_block9_1_conv False\n",
            "372 conv5_block9_1_bn False\n",
            "373 conv5_block9_1_relu False\n",
            "374 conv5_block9_2_conv False\n",
            "375 conv5_block9_concat False\n",
            "376 conv5_block10_0_bn False\n",
            "377 conv5_block10_0_relu False\n",
            "378 conv5_block10_1_conv False\n",
            "379 conv5_block10_1_bn False\n",
            "380 conv5_block10_1_relu False\n",
            "381 conv5_block10_2_conv False\n",
            "382 conv5_block10_concat False\n",
            "383 conv5_block11_0_bn False\n",
            "384 conv5_block11_0_relu False\n",
            "385 conv5_block11_1_conv False\n",
            "386 conv5_block11_1_bn False\n",
            "387 conv5_block11_1_relu False\n",
            "388 conv5_block11_2_conv False\n",
            "389 conv5_block11_concat False\n",
            "390 conv5_block12_0_bn False\n",
            "391 conv5_block12_0_relu False\n",
            "392 conv5_block12_1_conv False\n",
            "393 conv5_block12_1_bn False\n",
            "394 conv5_block12_1_relu False\n",
            "395 conv5_block12_2_conv False\n",
            "396 conv5_block12_concat False\n",
            "397 conv5_block13_0_bn False\n",
            "398 conv5_block13_0_relu False\n",
            "399 conv5_block13_1_conv False\n",
            "400 conv5_block13_1_bn False\n",
            "401 conv5_block13_1_relu False\n",
            "402 conv5_block13_2_conv False\n",
            "403 conv5_block13_concat False\n",
            "404 conv5_block14_0_bn False\n",
            "405 conv5_block14_0_relu False\n",
            "406 conv5_block14_1_conv False\n",
            "407 conv5_block14_1_bn False\n",
            "408 conv5_block14_1_relu False\n",
            "409 conv5_block14_2_conv False\n",
            "410 conv5_block14_concat False\n",
            "411 conv5_block15_0_bn False\n",
            "412 conv5_block15_0_relu False\n",
            "413 conv5_block15_1_conv False\n",
            "414 conv5_block15_1_bn False\n",
            "415 conv5_block15_1_relu False\n",
            "416 conv5_block15_2_conv False\n",
            "417 conv5_block15_concat False\n",
            "418 conv5_block16_0_bn False\n",
            "419 conv5_block16_0_relu False\n",
            "420 conv5_block16_1_conv False\n",
            "421 conv5_block16_1_bn False\n",
            "422 conv5_block16_1_relu False\n",
            "423 conv5_block16_2_conv False\n",
            "424 conv5_block16_concat False\n",
            "425 bn False\n",
            "426 relu False\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KcDo2VlW-6Jt"
      },
      "outputs": [],
      "source": [
        "#conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6prLuQV--6Jt",
        "outputId": "21272876-2976-4870-ca8a-f63126fc18c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 6\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 2,360,321\n",
            "Non-trainable params: 7,038,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "adagrad = optimizers.Adagrad(learning_rate=TrainingConfig.LEARNING_RATE, initial_accumulator_value=0.1, epsilon=TrainingConfig.EPSILON, decay =TrainingConfig.WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "P4qDSomz-6Jt"
      },
      "outputs": [],
      "source": [
        "modelPreTMob.compile(optimizer= adagrad, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])# Adagrad, adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add checkpoint to store the model on the best epoch for Val acc.\n",
        "checkpoint_filepath = r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-{epoch:02d}-{val_accuracy:.4f}.keras'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "print(TrainingConfig.EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.3564 - accuracy: 0.8078\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86763, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-01-0.8676.keras\n",
            "329/329 [==============================] - 247s 720ms/step - loss: 5.3564 - accuracy: 0.8078 - val_loss: 5.1282 - val_accuracy: 0.8676\n",
            "Epoch 2/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.1285 - accuracy: 0.8357\n",
            "Epoch 2: val_accuracy improved from 0.86763 to 0.87368, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-02-0.8737.keras\n",
            "329/329 [==============================] - 223s 679ms/step - loss: 5.1285 - accuracy: 0.8357 - val_loss: 4.9670 - val_accuracy: 0.8737\n",
            "Epoch 3/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.9747 - accuracy: 0.8439\n",
            "Epoch 3: val_accuracy improved from 0.87368 to 0.88026, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-03-0.8803.keras\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 4.9747 - accuracy: 0.8439 - val_loss: 4.8317 - val_accuracy: 0.8803\n",
            "Epoch 4/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.8364 - accuracy: 0.8537\n",
            "Epoch 4: val_accuracy improved from 0.88026 to 0.88237, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-04-0.8824.keras\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 4.8364 - accuracy: 0.8537 - val_loss: 4.7184 - val_accuracy: 0.8824\n",
            "Epoch 5/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.7364 - accuracy: 0.8498\n",
            "Epoch 5: val_accuracy improved from 0.88237 to 0.88263, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-05-0.8826.keras\n",
            "329/329 [==============================] - 208s 633ms/step - loss: 4.7364 - accuracy: 0.8498 - val_loss: 4.6210 - val_accuracy: 0.8826\n",
            "Epoch 6/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.6346 - accuracy: 0.8557\n",
            "Epoch 6: val_accuracy did not improve from 0.88263\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 4.6346 - accuracy: 0.8557 - val_loss: 4.5340 - val_accuracy: 0.8813\n",
            "Epoch 7/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.5544 - accuracy: 0.8554\n",
            "Epoch 7: val_accuracy did not improve from 0.88263\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 4.5544 - accuracy: 0.8554 - val_loss: 4.4555 - val_accuracy: 0.8814\n",
            "Epoch 8/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4795 - accuracy: 0.8550\n",
            "Epoch 8: val_accuracy improved from 0.88263 to 0.88368, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-08-0.8837.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 4.4795 - accuracy: 0.8550 - val_loss: 4.3860 - val_accuracy: 0.8837\n",
            "Epoch 9/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4107 - accuracy: 0.8577\n",
            "Epoch 9: val_accuracy did not improve from 0.88368\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 4.4107 - accuracy: 0.8577 - val_loss: 4.3205 - val_accuracy: 0.8820\n",
            "Epoch 10/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.3478 - accuracy: 0.8580\n",
            "Epoch 10: val_accuracy did not improve from 0.88368\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 4.3478 - accuracy: 0.8580 - val_loss: 4.2629 - val_accuracy: 0.8825\n",
            "Epoch 11/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2950 - accuracy: 0.8571\n",
            "Epoch 11: val_accuracy did not improve from 0.88368\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 4.2950 - accuracy: 0.8571 - val_loss: 4.2100 - val_accuracy: 0.8834\n",
            "Epoch 12/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2321 - accuracy: 0.8643\n",
            "Epoch 12: val_accuracy improved from 0.88368 to 0.88434, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-12-0.8843.keras\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 4.2321 - accuracy: 0.8643 - val_loss: 4.1615 - val_accuracy: 0.8843\n",
            "Epoch 13/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1920 - accuracy: 0.8591\n",
            "Epoch 13: val_accuracy did not improve from 0.88434\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 4.1920 - accuracy: 0.8591 - val_loss: 4.1150 - val_accuracy: 0.8843\n",
            "Epoch 14/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1494 - accuracy: 0.8598\n",
            "Epoch 14: val_accuracy improved from 0.88434 to 0.88539, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-14-0.8854.keras\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 4.1494 - accuracy: 0.8598 - val_loss: 4.0722 - val_accuracy: 0.8854\n",
            "Epoch 15/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1086 - accuracy: 0.8605\n",
            "Epoch 15: val_accuracy improved from 0.88539 to 0.88566, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-15-0.8857.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 4.1086 - accuracy: 0.8605 - val_loss: 4.0311 - val_accuracy: 0.8857\n",
            "Epoch 16/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0671 - accuracy: 0.8606\n",
            "Epoch 16: val_accuracy improved from 0.88566 to 0.88618, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-16-0.8862.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 4.0671 - accuracy: 0.8606 - val_loss: 3.9948 - val_accuracy: 0.8862\n",
            "Epoch 17/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0299 - accuracy: 0.8612\n",
            "Epoch 17: val_accuracy did not improve from 0.88618\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 4.0299 - accuracy: 0.8612 - val_loss: 3.9594 - val_accuracy: 0.8858\n",
            "Epoch 18/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9944 - accuracy: 0.8645\n",
            "Epoch 18: val_accuracy did not improve from 0.88618\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.9944 - accuracy: 0.8645 - val_loss: 3.9272 - val_accuracy: 0.8858\n",
            "Epoch 19/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9618 - accuracy: 0.8594\n",
            "Epoch 19: val_accuracy did not improve from 0.88618\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.9618 - accuracy: 0.8594 - val_loss: 3.8954 - val_accuracy: 0.8851\n",
            "Epoch 20/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9270 - accuracy: 0.8650\n",
            "Epoch 20: val_accuracy did not improve from 0.88618\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.9270 - accuracy: 0.8650 - val_loss: 3.8670 - val_accuracy: 0.8841\n",
            "Epoch 21/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9110 - accuracy: 0.8598\n",
            "Epoch 21: val_accuracy did not improve from 0.88618\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.9110 - accuracy: 0.8598 - val_loss: 3.8377 - val_accuracy: 0.8853\n",
            "Epoch 22/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8765 - accuracy: 0.8641\n",
            "Epoch 22: val_accuracy improved from 0.88618 to 0.88632, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-22-0.8863.keras\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.8765 - accuracy: 0.8641 - val_loss: 3.8116 - val_accuracy: 0.8863\n",
            "Epoch 23/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8520 - accuracy: 0.8635\n",
            "Epoch 23: val_accuracy improved from 0.88632 to 0.88750, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-23-0.8875.keras\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.8520 - accuracy: 0.8635 - val_loss: 3.7852 - val_accuracy: 0.8875\n",
            "Epoch 24/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8165 - accuracy: 0.8661\n",
            "Epoch 24: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.8165 - accuracy: 0.8661 - val_loss: 3.7608 - val_accuracy: 0.8872\n",
            "Epoch 25/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8039 - accuracy: 0.8649\n",
            "Epoch 25: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.8039 - accuracy: 0.8649 - val_loss: 3.7375 - val_accuracy: 0.8868\n",
            "Epoch 26/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7733 - accuracy: 0.8642\n",
            "Epoch 26: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.7733 - accuracy: 0.8642 - val_loss: 3.7155 - val_accuracy: 0.8862\n",
            "Epoch 27/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7523 - accuracy: 0.8660\n",
            "Epoch 27: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.7523 - accuracy: 0.8660 - val_loss: 3.6935 - val_accuracy: 0.8862\n",
            "Epoch 28/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7361 - accuracy: 0.8653\n",
            "Epoch 28: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.7361 - accuracy: 0.8653 - val_loss: 3.6723 - val_accuracy: 0.8859\n",
            "Epoch 29/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7162 - accuracy: 0.8615\n",
            "Epoch 29: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.7162 - accuracy: 0.8615 - val_loss: 3.6525 - val_accuracy: 0.8863\n",
            "Epoch 30/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6937 - accuracy: 0.8641\n",
            "Epoch 30: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.6937 - accuracy: 0.8641 - val_loss: 3.6329 - val_accuracy: 0.8872\n",
            "Epoch 31/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6763 - accuracy: 0.8644\n",
            "Epoch 31: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.6763 - accuracy: 0.8644 - val_loss: 3.6150 - val_accuracy: 0.8861\n",
            "Epoch 32/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6564 - accuracy: 0.8649\n",
            "Epoch 32: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.6564 - accuracy: 0.8649 - val_loss: 3.5970 - val_accuracy: 0.8864\n",
            "Epoch 33/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6445 - accuracy: 0.8618\n",
            "Epoch 33: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.6445 - accuracy: 0.8618 - val_loss: 3.5803 - val_accuracy: 0.8861\n",
            "Epoch 34/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6230 - accuracy: 0.8638\n",
            "Epoch 34: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 621ms/step - loss: 3.6230 - accuracy: 0.8638 - val_loss: 3.5639 - val_accuracy: 0.8867\n",
            "Epoch 35/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6095 - accuracy: 0.8640\n",
            "Epoch 35: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.6095 - accuracy: 0.8640 - val_loss: 3.5483 - val_accuracy: 0.8861\n",
            "Epoch 36/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5917 - accuracy: 0.8644\n",
            "Epoch 36: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.5917 - accuracy: 0.8644 - val_loss: 3.5327 - val_accuracy: 0.8866\n",
            "Epoch 37/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5704 - accuracy: 0.8686\n",
            "Epoch 37: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.5704 - accuracy: 0.8686 - val_loss: 3.5179 - val_accuracy: 0.8864\n",
            "Epoch 38/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5540 - accuracy: 0.8683\n",
            "Epoch 38: val_accuracy did not improve from 0.88750\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.5540 - accuracy: 0.8683 - val_loss: 3.5031 - val_accuracy: 0.8874\n",
            "Epoch 39/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5476 - accuracy: 0.8645\n",
            "Epoch 39: val_accuracy improved from 0.88750 to 0.88776, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-39-0.8878.keras\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.5476 - accuracy: 0.8645 - val_loss: 3.4886 - val_accuracy: 0.8878\n",
            "Epoch 40/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5304 - accuracy: 0.8673\n",
            "Epoch 40: val_accuracy improved from 0.88776 to 0.88842, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-40-0.8884.keras\n",
            "329/329 [==============================] - 207s 627ms/step - loss: 3.5304 - accuracy: 0.8673 - val_loss: 3.4746 - val_accuracy: 0.8884\n",
            "Epoch 41/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5162 - accuracy: 0.8674\n",
            "Epoch 41: val_accuracy did not improve from 0.88842\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.5162 - accuracy: 0.8674 - val_loss: 3.4612 - val_accuracy: 0.8883\n",
            "Epoch 42/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5075 - accuracy: 0.8618\n",
            "Epoch 42: val_accuracy did not improve from 0.88842\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.5075 - accuracy: 0.8618 - val_loss: 3.4488 - val_accuracy: 0.8876\n",
            "Epoch 43/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4978 - accuracy: 0.8634\n",
            "Epoch 43: val_accuracy improved from 0.88842 to 0.88855, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-43-0.8886.keras\n",
            "329/329 [==============================] - 207s 627ms/step - loss: 3.4978 - accuracy: 0.8634 - val_loss: 3.4356 - val_accuracy: 0.8886\n",
            "Epoch 44/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4722 - accuracy: 0.8685\n",
            "Epoch 44: val_accuracy did not improve from 0.88855\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.4722 - accuracy: 0.8685 - val_loss: 3.4238 - val_accuracy: 0.8880\n",
            "Epoch 45/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4715 - accuracy: 0.8636\n",
            "Epoch 45: val_accuracy did not improve from 0.88855\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4715 - accuracy: 0.8636 - val_loss: 3.4116 - val_accuracy: 0.8883\n",
            "Epoch 46/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4491 - accuracy: 0.8682\n",
            "Epoch 46: val_accuracy did not improve from 0.88855\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.4491 - accuracy: 0.8682 - val_loss: 3.4000 - val_accuracy: 0.8884\n",
            "Epoch 47/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4435 - accuracy: 0.8658\n",
            "Epoch 47: val_accuracy did not improve from 0.88855\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.4435 - accuracy: 0.8658 - val_loss: 3.3887 - val_accuracy: 0.8882\n",
            "Epoch 48/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4243 - accuracy: 0.8688\n",
            "Epoch 48: val_accuracy did not improve from 0.88855\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.4243 - accuracy: 0.8688 - val_loss: 3.3775 - val_accuracy: 0.8875\n",
            "Epoch 49/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4195 - accuracy: 0.8668\n",
            "Epoch 49: val_accuracy improved from 0.88855 to 0.88882, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-49-0.8888.keras\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.4195 - accuracy: 0.8668 - val_loss: 3.3669 - val_accuracy: 0.8888\n",
            "Epoch 50/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4119 - accuracy: 0.8667\n",
            "Epoch 50: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.4119 - accuracy: 0.8667 - val_loss: 3.3566 - val_accuracy: 0.8879\n",
            "Epoch 51/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3927 - accuracy: 0.8681\n",
            "Epoch 51: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.3927 - accuracy: 0.8681 - val_loss: 3.3460 - val_accuracy: 0.8883\n",
            "Epoch 52/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3881 - accuracy: 0.8678\n",
            "Epoch 52: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.3881 - accuracy: 0.8678 - val_loss: 3.3362 - val_accuracy: 0.8880\n",
            "Epoch 53/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3743 - accuracy: 0.8668\n",
            "Epoch 53: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.3743 - accuracy: 0.8668 - val_loss: 3.3261 - val_accuracy: 0.8884\n",
            "Epoch 54/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3703 - accuracy: 0.8651\n",
            "Epoch 54: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.3703 - accuracy: 0.8651 - val_loss: 3.3169 - val_accuracy: 0.8887\n",
            "Epoch 55/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3571 - accuracy: 0.8689\n",
            "Epoch 55: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.3571 - accuracy: 0.8689 - val_loss: 3.3076 - val_accuracy: 0.8888\n",
            "Epoch 56/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3452 - accuracy: 0.8687\n",
            "Epoch 56: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.3452 - accuracy: 0.8687 - val_loss: 3.2991 - val_accuracy: 0.8879\n",
            "Epoch 57/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3401 - accuracy: 0.8684\n",
            "Epoch 57: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.3401 - accuracy: 0.8684 - val_loss: 3.2898 - val_accuracy: 0.8883\n",
            "Epoch 58/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3331 - accuracy: 0.8702\n",
            "Epoch 58: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 205s 621ms/step - loss: 3.3331 - accuracy: 0.8702 - val_loss: 3.2810 - val_accuracy: 0.8886\n",
            "Epoch 59/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3206 - accuracy: 0.8688\n",
            "Epoch 59: val_accuracy improved from 0.88882 to 0.88934, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-59-0.8893.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.3206 - accuracy: 0.8688 - val_loss: 3.2719 - val_accuracy: 0.8893\n",
            "Epoch 60/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3124 - accuracy: 0.8693\n",
            "Epoch 60: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.3124 - accuracy: 0.8693 - val_loss: 3.2641 - val_accuracy: 0.8887\n",
            "Epoch 61/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3091 - accuracy: 0.8653\n",
            "Epoch 61: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 204s 619ms/step - loss: 3.3091 - accuracy: 0.8653 - val_loss: 3.2556 - val_accuracy: 0.8887\n",
            "Epoch 62/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2953 - accuracy: 0.8699\n",
            "Epoch 62: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.2953 - accuracy: 0.8699 - val_loss: 3.2474 - val_accuracy: 0.8891\n",
            "Epoch 63/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2886 - accuracy: 0.8672\n",
            "Epoch 63: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.2886 - accuracy: 0.8672 - val_loss: 3.2392 - val_accuracy: 0.8891\n",
            "Epoch 64/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2853 - accuracy: 0.8673\n",
            "Epoch 64: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2853 - accuracy: 0.8673 - val_loss: 3.2315 - val_accuracy: 0.8883\n",
            "Epoch 65/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2733 - accuracy: 0.8679\n",
            "Epoch 65: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.2733 - accuracy: 0.8679 - val_loss: 3.2240 - val_accuracy: 0.8886\n",
            "Epoch 66/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2694 - accuracy: 0.8669\n",
            "Epoch 66: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.2694 - accuracy: 0.8669 - val_loss: 3.2163 - val_accuracy: 0.8888\n",
            "Epoch 67/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2589 - accuracy: 0.8672\n",
            "Epoch 67: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2589 - accuracy: 0.8672 - val_loss: 3.2093 - val_accuracy: 0.8891\n",
            "Epoch 68/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2498 - accuracy: 0.8678\n",
            "Epoch 68: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.2498 - accuracy: 0.8678 - val_loss: 3.2022 - val_accuracy: 0.8892\n",
            "Epoch 69/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2442 - accuracy: 0.8705\n",
            "Epoch 69: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.2442 - accuracy: 0.8705 - val_loss: 3.1947 - val_accuracy: 0.8891\n",
            "Epoch 70/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2355 - accuracy: 0.8685\n",
            "Epoch 70: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.2355 - accuracy: 0.8685 - val_loss: 3.1877 - val_accuracy: 0.8889\n",
            "Epoch 71/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2321 - accuracy: 0.8681\n",
            "Epoch 71: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.2321 - accuracy: 0.8681 - val_loss: 3.1811 - val_accuracy: 0.8889\n",
            "Epoch 72/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2225 - accuracy: 0.8654\n",
            "Epoch 72: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2225 - accuracy: 0.8654 - val_loss: 3.1742 - val_accuracy: 0.8887\n",
            "Epoch 73/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2114 - accuracy: 0.8714\n",
            "Epoch 73: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2114 - accuracy: 0.8714 - val_loss: 3.1678 - val_accuracy: 0.8889\n",
            "Epoch 74/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2049 - accuracy: 0.8706\n",
            "Epoch 74: val_accuracy did not improve from 0.88934\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.2049 - accuracy: 0.8706 - val_loss: 3.1612 - val_accuracy: 0.8892\n",
            "Epoch 75/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1975 - accuracy: 0.8700\n",
            "Epoch 75: val_accuracy improved from 0.88934 to 0.88974, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-75-0.8897.keras\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.1975 - accuracy: 0.8700 - val_loss: 3.1547 - val_accuracy: 0.8897\n",
            "Epoch 76/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1971 - accuracy: 0.8699\n",
            "Epoch 76: val_accuracy did not improve from 0.88974\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.1971 - accuracy: 0.8699 - val_loss: 3.1488 - val_accuracy: 0.8897\n",
            "Epoch 77/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1905 - accuracy: 0.8667\n",
            "Epoch 77: val_accuracy did not improve from 0.88974\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1905 - accuracy: 0.8667 - val_loss: 3.1424 - val_accuracy: 0.8895\n",
            "Epoch 78/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1873 - accuracy: 0.8658\n",
            "Epoch 78: val_accuracy did not improve from 0.88974\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.1873 - accuracy: 0.8658 - val_loss: 3.1364 - val_accuracy: 0.8893\n",
            "Epoch 79/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1813 - accuracy: 0.8663\n",
            "Epoch 79: val_accuracy did not improve from 0.88974\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.1813 - accuracy: 0.8663 - val_loss: 3.1302 - val_accuracy: 0.8896\n",
            "Epoch 80/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1727 - accuracy: 0.8680\n",
            "Epoch 80: val_accuracy did not improve from 0.88974\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1727 - accuracy: 0.8680 - val_loss: 3.1247 - val_accuracy: 0.8896\n",
            "Epoch 81/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1615 - accuracy: 0.8705\n",
            "Epoch 81: val_accuracy improved from 0.88974 to 0.89013, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-81-0.8901.keras\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.1615 - accuracy: 0.8705 - val_loss: 3.1187 - val_accuracy: 0.8901\n",
            "Epoch 82/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1596 - accuracy: 0.8696\n",
            "Epoch 82: val_accuracy did not improve from 0.89013\n",
            "329/329 [==============================] - 204s 621ms/step - loss: 3.1596 - accuracy: 0.8696 - val_loss: 3.1134 - val_accuracy: 0.8895\n",
            "Epoch 83/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1577 - accuracy: 0.8678\n",
            "Epoch 83: val_accuracy did not improve from 0.89013\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1577 - accuracy: 0.8678 - val_loss: 3.1077 - val_accuracy: 0.8896\n",
            "Epoch 84/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1511 - accuracy: 0.8681\n",
            "Epoch 84: val_accuracy did not improve from 0.89013\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.1511 - accuracy: 0.8681 - val_loss: 3.1024 - val_accuracy: 0.8892\n",
            "Epoch 85/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1419 - accuracy: 0.8680\n",
            "Epoch 85: val_accuracy did not improve from 0.89013\n",
            "329/329 [==============================] - 204s 620ms/step - loss: 3.1419 - accuracy: 0.8680 - val_loss: 3.0966 - val_accuracy: 0.8896\n",
            "Epoch 86/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1398 - accuracy: 0.8700\n",
            "Epoch 86: val_accuracy did not improve from 0.89013\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.1398 - accuracy: 0.8700 - val_loss: 3.0917 - val_accuracy: 0.8889\n",
            "Epoch 87/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1311 - accuracy: 0.8696\n",
            "Epoch 87: val_accuracy improved from 0.89013 to 0.89026, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNet-87-0.8903.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.1311 - accuracy: 0.8696 - val_loss: 3.0857 - val_accuracy: 0.8903\n",
            "Epoch 88/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1288 - accuracy: 0.8698\n",
            "Epoch 88: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1288 - accuracy: 0.8698 - val_loss: 3.0804 - val_accuracy: 0.8896\n",
            "Epoch 89/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1247 - accuracy: 0.8681\n",
            "Epoch 89: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.1247 - accuracy: 0.8681 - val_loss: 3.0752 - val_accuracy: 0.8892\n",
            "Epoch 90/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1227 - accuracy: 0.8673\n",
            "Epoch 90: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.1227 - accuracy: 0.8673 - val_loss: 3.0704 - val_accuracy: 0.8897\n",
            "Epoch 91/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1185 - accuracy: 0.8674\n",
            "Epoch 91: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 3.1185 - accuracy: 0.8674 - val_loss: 3.0651 - val_accuracy: 0.8896\n",
            "Epoch 92/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1041 - accuracy: 0.8720\n",
            "Epoch 92: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 207s 627ms/step - loss: 3.1041 - accuracy: 0.8720 - val_loss: 3.0602 - val_accuracy: 0.8899\n",
            "Epoch 93/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1055 - accuracy: 0.8672\n",
            "Epoch 93: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.1055 - accuracy: 0.8672 - val_loss: 3.0553 - val_accuracy: 0.8895\n",
            "Epoch 94/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0968 - accuracy: 0.8695\n",
            "Epoch 94: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 206s 628ms/step - loss: 3.0968 - accuracy: 0.8695 - val_loss: 3.0504 - val_accuracy: 0.8892\n",
            "Epoch 95/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0904 - accuracy: 0.8706\n",
            "Epoch 95: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.0904 - accuracy: 0.8706 - val_loss: 3.0454 - val_accuracy: 0.8892\n",
            "Epoch 96/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0915 - accuracy: 0.8671\n",
            "Epoch 96: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.0915 - accuracy: 0.8671 - val_loss: 3.0408 - val_accuracy: 0.8901\n",
            "Epoch 97/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0879 - accuracy: 0.8682\n",
            "Epoch 97: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.0879 - accuracy: 0.8682 - val_loss: 3.0358 - val_accuracy: 0.8896\n",
            "Epoch 98/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0822 - accuracy: 0.8689\n",
            "Epoch 98: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.0822 - accuracy: 0.8689 - val_loss: 3.0318 - val_accuracy: 0.8892\n",
            "Epoch 99/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0692 - accuracy: 0.8712\n",
            "Epoch 99: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.0692 - accuracy: 0.8712 - val_loss: 3.0273 - val_accuracy: 0.8897\n",
            "Epoch 100/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0661 - accuracy: 0.8698\n",
            "Epoch 100: val_accuracy did not improve from 0.89026\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.0661 - accuracy: 0.8698 - val_loss: 3.0227 - val_accuracy: 0.8901\n"
          ]
        }
      ],
      "source": [
        "histPreT = modelPreTMob.fit(train_generator, epochs = TrainingConfig.EPOCHS, validation_data=validation_generator, callbacks=[model_checkpoint_callback]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 20609.674021720886 seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(Current_dir, 'History')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(r'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History\\\\HistoryDict_DenseNEt_FT0', 'wb') as file_pi:\n",
        "    pickle.dump(histPreT.history, file_pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 87\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "START_PLOT_FROM_EPOCH= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "e3wZrd90-6Jt",
        "outputId": "0630124c-9747-4688-f755-aaf80997102f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACO4klEQVR4nO3dd3hU1dbA4d/MpBPSQxIgEAi9d6TjFalGUUEEpCrYUBQbKGDhA7zq5aKioF4RCyCoWEERIoj03juEToAE0vvM+f44M4eZZJLMpBPW+zx5TM6csuckctasvfbeOkVRFIQQQgghKjB9eTdACCGEEKIwErAIIYQQosKTgEUIIYQQFZ4ELEIIIYSo8CRgEUIIIUSFJwGLEEIIISo8CViEEEIIUeFJwCKEEEKICk8CFiGEEEJUeBKwiNvS6NGjiYiIKNKxb7zxBjqdrmQbVMGcOXMGnU7HokWLyvS669evR6fTsX79em2bo7+r0mpzREQEo0ePLtFzCiGcJwGLqFB0Op1DX9YPNCGKa/PmzbzxxhskJCSUd1OEEPlwKe8GCGHt66+/tvn5q6++Ys2aNXm2N27cuFjX+eyzzzCZTEU6durUqUyePLlY1xeOK87vylGbN2/mzTffZPTo0fj5+dm8duzYMfR6+WwnRHmTgEVUKI888ojNz1u3bmXNmjV5tueWlpaGl5eXw9dxdXUtUvsAXFxccHGR/3XKSnF+VyXB3d29XK9/q0hNTaVKlSrl3QxRicnHBnHL6dmzJ82aNWPXrl10794dLy8vXn31VQB+/vlnBgwYQPXq1XF3dycyMpIZM2ZgNBptzpG7LsJS//Dee+/x6aefEhkZibu7O+3bt2fHjh02x9qrYdHpdEyYMIGffvqJZs2a4e7uTtOmTfnjjz/ytH/9+vW0a9cODw8PIiMj+eSTTxyui/nnn38YPHgwtWrVwt3dnfDwcJ5//nnS09PzvD9vb28uXrzIwIED8fb2Jjg4mBdffDHPvUhISGD06NH4+vri5+fHqFGjHOoa2blzJzqdji+//DLPa6tXr0an0/Hbb78BcPbsWZ566ikaNmyIp6cngYGBDB48mDNnzhR6HXs1LI62ef/+/YwePZq6devi4eFBaGgoY8eOJT4+XtvnjTfe4KWXXgKgTp06WrejpW32alhOnz7N4MGDCQgIwMvLizvuuIOVK1fa7GOpx1m+fDkzZ86kZs2aeHh4cNddd3Hy5MlC37cz9ywhIYHnn3+eiIgI3N3dqVmzJiNHjiQuLk7bJyMjgzfeeIMGDRrg4eFBWFgYDzzwAKdOnbJpb+7uVnu1QZa/r1OnTtG/f3+qVq3K8OHDAcf/RgGOHj3KQw89RHBwMJ6enjRs2JDXXnsNgHXr1qHT6fjxxx/zHLdkyRJ0Oh1btmwp9D6KykM+JopbUnx8PP369ePhhx/mkUceISQkBIBFixbh7e3NpEmT8Pb25q+//mL69OkkJSXx7rvvFnreJUuWkJyczOOPP45Op+Odd97hgQce4PTp04V+0t+4cSMrVqzgqaeeomrVqnzwwQc8+OCDnDt3jsDAQAD27NlD3759CQsL480338RoNPLWW28RHBzs0Pv+7rvvSEtL48knnyQwMJDt27fz4YcfcuHCBb777jubfY1GI3369KFjx4689957rF27lv/85z9ERkby5JNPAqAoCvfddx8bN27kiSeeoHHjxvz444+MGjWq0La0a9eOunXrsnz58jz7L1u2DH9/f/r06QPAjh072Lx5Mw8//DA1a9bkzJkzzJ8/n549e3L48GGnsmPOtHnNmjWcPn2aMWPGEBoayqFDh/j00085dOgQW7duRafT8cADD3D8+HGWLl3Kf//7X4KCggDy/Z1cuXKFzp07k5aWxrPPPktgYCBffvkl9957L99//z3333+/zf5vv/02er2eF198kcTERN555x2GDx/Otm3bCnyfjt6zlJQUunXrxpEjRxg7dixt2rQhLi6OX375hQsXLhAUFITRaOSee+4hOjqahx9+mIkTJ5KcnMyaNWs4ePAgkZGRDt9/i5ycHPr06UPXrl157733tPY4+je6f/9+unXrhqurK+PHjyciIoJTp07x66+/MnPmTHr27El4eDiLFy/Oc08XL15MZGQknTp1crrd4hamCFGBPf3000ruP9MePXoogLJgwYI8+6elpeXZ9vjjjyteXl5KRkaGtm3UqFFK7dq1tZ9jYmIUQAkMDFSuX7+ubf/5558VQPn111+1ba+//nqeNgGKm5ubcvLkSW3bvn37FED58MMPtW1RUVGKl5eXcvHiRW3biRMnFBcXlzzntMfe+5s9e7ai0+mUs2fP2rw/QHnrrbds9m3durXStm1b7eeffvpJAZR33nlH25aTk6N069ZNAZQvvviiwPZMmTJFcXV1tblnmZmZip+fnzJ27NgC271lyxYFUL766itt27p16xRAWbdunc17sf5dOdNme9ddunSpAigbNmzQtr377rsKoMTExOTZv3bt2sqoUaO0n5977jkFUP755x9tW3JyslKnTh0lIiJCMRqNNu+lcePGSmZmprbv+++/rwDKgQMH8lzLmqP3bPr06QqgrFixIs/+JpNJURRFWbhwoQIoc+bMyXcfe/deUW7+v2F9Xy1/X5MnT3ao3fb+Rrt3765UrVrVZpt1exRF/ftyd3dXEhIStG1Xr15VXFxclNdffz3PdUTlJl1C4pbk7u7OmDFj8mz39PTUvk9OTiYuLo5u3bqRlpbG0aNHCz3vkCFD8Pf3137u1q0boHYBFKZXr142n1RbtGiBj4+PdqzRaGTt2rUMHDiQ6tWra/vVq1ePfv36FXp+sH1/qampxMXF0blzZxRFYc+ePXn2f+KJJ2x+7tatm817WbVqFS4uLlrGBcBgMPDMM8841J4hQ4aQnZ3NihUrtG1//vknCQkJDBkyxG67s7OziY+Pp169evj5+bF7926HrlWUNltfNyMjg7i4OO644w4Ap69rff0OHTrQtWtXbZu3tzfjx4/nzJkzHD582Gb/MWPG4Obmpv3s6N+Uo/fshx9+oGXLlnmyEIDWzfjDDz8QFBRk9x4VZ4i+9e/AXrvz+xu9du0aGzZsYOzYsdSqVSvf9owcOZLMzEy+//57bduyZcvIyckptK5NVD4SsIhbUo0aNWweAhaHDh3i/vvvx9fXFx8fH4KDg7V/2BITEws9b+5/PC3By40bN5w+1nK85dirV6+Snp5OvXr18uxnb5s9586dY/To0QQEBGh1KT169ADyvj8PD4883RrW7QG1TiIsLAxvb2+b/Ro2bOhQe1q2bEmjRo1YtmyZtm3ZsmUEBQXxr3/9S9uWnp7O9OnTCQ8Px93dnaCgIIKDg0lISHDo92LNmTZfv36diRMnEhISgqenJ8HBwdSpUwdw7O8hv+vbu5Zl5NrZs2dtthf1b8rRe3bq1CmaNWtW4LlOnTpFw4YNS7RY3MXFhZo1a+bZ7sjfqCVYK6zdjRo1on379ixevFjbtnjxYu644w6H/58RlYfUsIhbkvWnOIuEhAR69OiBj48Pb731FpGRkXh4eLB7925eeeUVh4bGGgwGu9sVRSnVYx1hNBq5++67uX79Oq+88gqNGjWiSpUqXLx4kdGjR+d5f/m1p6QNGTKEmTNnEhcXR9WqVfnll18YOnSozcPxmWee4YsvvuC5556jU6dO+Pr6otPpePjhh0t1yPJDDz3E5s2beemll2jVqhXe3t6YTCb69u1b6kOlLYr6d1HW9yy/TEvuIm0Ld3f3PMO9nf0bdcTIkSOZOHEiFy5cIDMzk61btzJv3jynzyNufRKwiEpj/fr1xMfHs2LFCrp3765tj4mJKcdW3VStWjU8PDzsjhBxZNTIgQMHOH78OF9++SUjR47Utq9Zs6bIbapduzbR0dGkpKTYZCyOHTvm8DmGDBnCm2++yQ8//EBISAhJSUk8/PDDNvt8//33jBo1iv/85z/atoyMjCJN1OZom2/cuEF0dDRvvvkm06dP17afOHEizzmd6RapXbu23ftj6XKsXbu2w+cqiKP3LDIykoMHDxZ4rsjISLZt20Z2dna+xeOWzE/u8+fOGBXE0b/RunXrAhTaboCHH36YSZMmsXTpUtLT03F1dbXpbhS3D+kSEpWG5ZOs9SfXrKwsPv744/Jqkg2DwUCvXr346aefuHTpkrb95MmT/P777w4dD7bvT1EU3n///SK3qX///uTk5DB//nxtm9Fo5MMPP3T4HI0bN6Z58+YsW7aMZcuWERYWZhMwWtqeO6Pw4Ycf5vvpvSTabO9+AcydOzfPOS3zhzgSQPXv35/t27fbDKlNTU3l008/JSIigiZNmjj6Vgrk6D178MEH2bdvn93hv5bjH3zwQeLi4uxmJiz71K5dG4PBwIYNG2xed+b/H0f/RoODg+nevTsLFy7k3LlzdttjERQURL9+/fjmm29YvHgxffv21UZyiduLZFhEpdG5c2f8/f0ZNWoUzz77LDqdjq+//rrEumRKwhtvvMGff/5Jly5dePLJJzEajcybN49mzZqxd+/eAo9t1KgRkZGRvPjii1y8eBEfHx9++OEHh+pr8hMVFUWXLl2YPHkyZ86coUmTJqxYscLp+o4hQ4Ywffp0PDw8ePTRR/N0Fdxzzz18/fXX+Pr60qRJE7Zs2cLatWu14d6l0WYfHx+6d+/OO++8Q3Z2NjVq1ODPP/+0m3Fr27YtAK+99hoPP/wwrq6uREVF2Z0IbfLkySxdupR+/frx7LPPEhAQwJdffklMTAw//PBDic2K6+g9e+mll/j+++8ZPHgwY8eOpW3btly/fp1ffvmFBQsW0LJlS0aOHMlXX33FpEmT2L59O926dSM1NZW1a9fy1FNPcd999+Hr68vgwYP58MMP0el0REZG8ttvv3H16lWH2+zM3+gHH3xA165dadOmDePHj6dOnTqcOXOGlStX5vl/YeTIkQwaNAiAGTNmOH8zReVQ5uOShHBCfsOamzZtanf/TZs2KXfccYfi6empVK9eXXn55ZeV1atXFzpU1jJ08913381zTsBmCGV+w5qffvrpPMfmHhKrKIoSHR2ttG7dWnFzc1MiIyOV//3vf8oLL7ygeHh45HMXbjp8+LDSq1cvxdvbWwkKClLGjRunDZ/OPey0SpUqeY631/b4+HhlxIgRio+Pj+Lr66uMGDFC2bNnj0PDmi1OnDihAAqgbNy4Mc/rN27cUMaMGaMEBQUp3t7eSp8+fZSjR4/muT+ODGt2ps0XLlxQ7r//fsXPz0/x9fVVBg8erFy6dCnP71RRFGXGjBlKjRo1FL1ebzPE2d7v8NSpU8qgQYMUPz8/xcPDQ+nQoYPy22+/2exjeS/fffedzXZ7w4TtcfSeWe7HhAkTlBo1aihubm5KzZo1lVGjRilxcXHaPmlpacprr72m1KlTR3F1dVVCQ0OVQYMGKadOndL2uXbtmvLggw8qXl5eir+/v/L4448rBw8edPjvS1Ec/xtVFEU5ePCg9vvx8PBQGjZsqEybNi3POTMzMxV/f3/F19dXSU9PL/C+icpLpygV6OOnELepgQMHcujQIbv1FULc7nJycqhevTpRUVF8/vnn5d0cUU6khkWIMpZ7ivITJ06watUqevbsWT4NEqKC++mnn7h27ZpNIa+4/UiGRYgyFhYWpq1vc/bsWebPn09mZiZ79uyhfv365d08ISqMbdu2sX//fmbMmEFQUFCRJ/sTlYMU3QpRxvr27cvSpUuJjY3F3d2dTp06MWvWLAlWhMhl/vz5fPPNN7Rq1cpm8UVxe5IMixBCCCEqPKlhEUIIIUSFJwGLEEIIISq8SlPDYjKZuHTpElWrVi3W6qNCCCGEKDuKopCcnEz16tULnHix0gQsly5dIjw8vLybIYQQQogiOH/+vN0VwC0qTcBStWpVQH3DPj4+5dwaIYQQQjgiKSmJ8PBw7Tmen0oTsFi6gXx8fCRgEUIIIW4xhZVzSNGtEEIIISo8CViEEEIIUeFJwCKEEEKICk8CFiGEEEJUeBKwCCGEEKLCk4BFCCGEEBWeBCxCCCGEqPAkYBFCCCFEhScBixBCCCEqPAlYhBBCCFHhScAihBBCiAqvSAHLRx99REREBB4eHnTs2JHt27cXuP/cuXNp2LAhnp6ehIeH8/zzz5ORkaG9npyczHPPPUft2rXx9PSkc+fO7NixoyhNE0IIIUQl5HTAsmzZMiZNmsTrr7/O7t27admyJX369OHq1at291+yZAmTJ0/m9ddf58iRI3z++ecsW7aMV199VdvnscceY82aNXz99dccOHCA3r1706tXLy5evFj0dyaEEEKUlhv74NiHkJNe3i0pO6bscr28TlEUxZkDOnbsSPv27Zk3bx4AJpOJ8PBwnnnmGSZPnpxn/wkTJnDkyBGio6O1bS+88ALbtm1j48aNpKenU7VqVX7++WcGDBig7dO2bVv69evH//3f/znUrqSkJHx9fUlMTJTVmoUQ4nYTtx2OvAsRwyD8/tK9VlYC/FofMuMguAt0/xncA0v3mkWRcgb2vQZhvaHOSChkNeR8pV2AA2/Cjb3QZxvoSraaxNHnt1NXzcrKYteuXfTq1evmCfR6evXqxZYtW+we07lzZ3bt2qV1G50+fZpVq1bRv39/AHJycjAajXh4eNgc5+npycaNG/NtS2ZmJklJSTZfQgghbjOmHDgwA9Z0hvPfwz8PwJH3wLnP4s45NFMNVgCubYI1XSAlpuTOb8oBY0bh+xUkOwX+joKzS2DraPjnQciIc+4cGXGw+0X4pR6c+h9c3wlX/y5eu4rBxZmd4+LiMBqNhISE2GwPCQnh6NGjdo8ZNmwYcXFxdO3aFUVRyMnJ4YknntC6hKpWrUqnTp2YMWMGjRs3JiQkhKVLl7Jlyxbq1auXb1tmz57Nm2++6UzzhRBClKWkE5B4wHabzgCBHcEztPjnTzkNm0dA3Gb1Z7+WkLAP9rwEqWehzVzQG4p/HWvJJ+HY++r3bebA0bmQdAz+vAN6rITAdoW0+QykngHfpuARfHO7YoK4LXBmMZxbrmZx6o6GZq9DlXDn2qiYYOsoSDwIbgGQkwwXfoT4rdDxC6jep+Djc1LhyBw1Y5WTrG4L7gatZqsZpXLiVMBSFOvXr2fWrFl8/PHHdOzYkZMnTzJx4kRmzJjBtGnTAPj6668ZO3YsNWrUwGAw0KZNG4YOHcquXbvyPe+UKVOYNGmS9nNSUhLh4U7+UoUQQpQ8Uw4cfhsOvAGKMe/rOj2E3KV239S8H9x88z+XYoKrG9RP9qacm9uN6XDyE8hJAVcfaPexer5jc2H3JDg+T+3K6LwYDJ6Qdg4SDkDSUfBtrnaT2OsiMRnh/A9qG8MfzLvPnpfVWo6wPtDwOag1BNb3VwOltT2g0yIIH5T3OJMRjrwD+6eDYn4fHiHg1xyq1IbYtWqQZe3U5xDzDTR4GppMAY+g/O+TtYMz4fwK0LtBj9/AxRM2DYOkI7C+LzR4Blq8BW5+eY+N3wmbh0PycfVn/1bQchaE9S16l1IJcaqGJSsrCy8vL77//nsGDhyobR81ahQJCQn8/PPPeY7p1q0bd9xxB++++6627ZtvvmH8+PGkpKSg19/slUpNTSUpKYmwsDCGDBlCSkoKK1eudKhtUsMihBAVQEoMbBmhdpWA+sBz8b75enYSJOy/+bPeXQ0eAtqqD2/f5uBdVw0AziyBs99CegEDMIK7QaevwDvi5rZz36mZF1MmeNVUr5mdq2wgqLOaMajWXf1ZUeDCz7D/NUg8rG5r8KyaRbFkaa6sh+g71SxRv33g1/Tme/pnEMSuuXnulrMgpIf5npyBLSPh2j/qz57VIf0ykOvx61IVwh9QAy+Dl9qWqxtuvlb/cYh4BPxa5B88XPgZNgxUv+/4OUSOVb/PSYe9r8DxD9Wf3fyhyWRoMAFcvNSASgsyc8CzBrR+D2o/VOI1K7k5+vx2KsPi5uZG27ZtiY6O1gIWk8lEdHQ0EyZMsHtMWlqaTVACYDCov/zcsVKVKlWoUqUKN27cYPXq1bzzzjvONE8IIcrGqYVwYj40fxNq9C/v1uQvJ139lF3S3SL2KArEfAU7n1G7EVx9oN1HEDE878M1+RScXap2fyQdhYu/ql8WelfbESmuflDjHvUha82vGdR9NO/7qzUYPEJhw31qlgVA5wK+jdVg6PJqtRtpbQ8I6wd1HoFjH0D8NvP1fNQg5PgHkHZezdLo3WD38+rr9cbfDFYs+/dcqRamHp2jnju6p5qFCeujBgHZSWrg1m6eWgBrTIOEQ2qXWfJJNWCrPkDNhljctV5t675X4cYetTbnyHvg2wRqD4Nag9QuH4uUGNj8iPp9g2duBiugnrfdB+p93P28GpTtfUXNSDV+Wc0qXdt48/61XwDuVueuAJweJbRs2TJGjRrFJ598QocOHZg7dy7Lly/n6NGjhISEMHLkSGrUqMHs2bMBeOONN5gzZw6ffvqp1iX05JNP0rZtW5YtWwbA6tWrURSFhg0bcvLkSV566SU8PDz4559/cHV1dahdkmERQpSJ01+qRYygftJuPx/qjXPs2Mx49cFj/c+uTgdBncClSvHalX5Z/TSecODmV2oMGDzAp4mavbD+8ggtmRR/6lk4s1Qt7kww16sEd4VOX9tmPexRFHXkyZV16oM74QAkHlILTg0eUCNKDXjC+oLB3fm2pcdC3FaoGglVG4LBTd2edgkOzlALSRWrbiaDFzR6Dhq/BJf/VDNFpiz191Pzftj7Mrj6QtQJ2/oTm2teVs998jPbcwd1hs5fqwGTsxSTGtDFfAUXf1PbVJCQO+HO1WrgZ4/JqAaLB6bbdkO5VDUHVCPKtPvH0ee30wELwLx583j33XeJjY2lVatWfPDBB3Ts2BGAnj17EhERwaJFiwB1FNDMmTP5+uuvuXjxIsHBwURFRTFz5kz8/PwAWL58OVOmTOHChQsEBATw4IMPMnPmTHx9C+jXLOIbFkKIIjv3A2x6SH2A+Da52XXQ9DVoMSP/f+SzEuHof+Dof9Wai9yq1IZe/zhfXJmVqNYqnFkMV9ep7XKUe6Da/eLXHLxqAFZt1xnUrpbA9vbfU0YcnP9O7bK5ZjWaU+8GzV+Hxq8UPatjMkLaWXAPBteqRTuHo5JPqjUll1aqWY+mr9kWA1/9R83SZN24ua31e9D4BQfOfUo99+XfoeHz0HQK6EugbDQrwfw7XwJX1+etEQrsqNatOFLvYsyEk5/C4X+DTwO1C8m7TvHb6KRSDVgqIglYhLgF3dgHp7+AJq+AZ1jpXCMrUR0tYfn07h0JDSc6/wny0h+w4V61q6LuWOj4GRx4Cw6aRytGjICO/7v5KR7ULpkTH8OhWZB1Xd1WpY7ahWCRflEdIlu1AfTaAJ62ozDzMGbApVVqkHJxpVqnYeHf5mYtiF9zdSRKdqJt1iXxACSfcCy48Y5U6ylqD1NrQS78rGZSLv9plT3QQUhPcxfFg3m7bW4FipL/30PiEVjfT81EeEfCgENFy/aUhvwe3+VcHOssCViEEEVT0D/eJcmYBauaq6MRAtqpD2vr/vuish4eemlV3pEXAG3fh4bPOn7OqxtgXV91ZEqtwdB56c0MwqnPYfvj6iddzxq2WYHMa2o3EIBPI2jxf2pRpfX9TT0Pa7qqo1j8WkCv9Xkf+iajmkE5s0StNbAuIPVtonab1H7Y8e6GnHR1xEjCAbUA1tJGi+wktXbCmHZzW+66koC2UHuoel2vGo5d91aVfhlOLFDfq2/j8m5NpSMBixC3u+wUyIhVP9E7mp6/sQ/+vgd8GqvZgiq1HLxWsjq3RNUGjn/6PPo+7H7u5s8RI6DTl0UPlhIOwZlv1GLO3EGKZw014+BaVR1BojPAnX9C6L/yP58pRx1qemaJOiGZMV0tiuy2wjaLAnDpd9g4WJ2/IjevcLU4t86I/LsEkk/Cmm7q7yuwI/xrjVqgGb9DzWicXaa+Zn3O2g+rgUpBI0aKIydVzaicWaIGL0qOOeMyXA1UfBuV/DXFbUkCFiFuZ5dWw8ZBar2EwVPtGvBrrk6sVecR+9OIZ8TB6nY3H/auvtDePLeFNWOWOnwzbsvNT+ipZ8zH+KndArWHQbUe+QdKmfHq7JnZCWr3SsyXaoaizRxo9LztvtnJEButfrL1aZj3XIlHYf9UNfNg4VJVbUetIRDY4eZoB0WBLaPgzNfq6Iq+O/P22SccgBOfqJN3ZV67uT30bnUK9vyyQBlxapeTNb2LmokweNg/xua6B9VRK1nXwb+1+r5TTt583S1Aze5EDFOLWkt5qKmNzHjIuKbe/1usu0FUfBKwCHG7OrUQto9XAwCdPm+tgndd6Pm7WmRnYcqGdX3U0RrekWrBY/xW9bXaQ9WRA4kH1U/b5767WY9hzeBl24XgGQZ1RqlFmLkf2DufVeeD8GsBfXfDiY9g10S1vT3/gLC71VqNEwtsp0H3b2OuqXhYfX8H3jAHOyZABzXvVeepyD081FpOOqztrk4z7tcC7t4Ert43CzDPfos2P4Z7kBr0RAyHoDtK/2EdvwOi/3WzMNfgBTXvU99zaO+8mR0hKgEJWIS43SiKOg+EVgT6CHT4VJ1HwlJwGfOVOtTVPRC6/wLBndV9LQGEizf03qp+kj40Cw6+ZQ58DLajETzDoHp/NWNjKfB081drPSxdKJaRFcFdzYvDmbMciUfU2hXFCP9aC6F3qW3f9qhagOvmD82mqSNq0s6br1cdMq7aFnrqXW7WVNS8T60P8Wvm2L1KuwB/tIOMK1BzoDrE13qIa/iDEPmY2rb8hoaWlrht6siNkH+p78vVu/BjhLiFScAixO3ElK0Wfp7+Qv256avqAzx3RiDjKqy/B67vULMenZeo2ZJtj6mvd/9JfUhaxG1VJ6JKOaV2EYU/qH7ar9az4LoYY6Za/7B9vDpKxaehmtXxrgPrB6jFsDXuhR4/2x6ztsfNybtArT1p/oa6pkrWDTUQsh5KW62nOltp0B3O37Nr5sm9rAtJw/qqM5QGtHb+fEKIIpGARYjbgTad+FS1fkKnV9dUqf94/sfkpMKmoeaZRa0yFc3fgubT7OyfBtd3qXNyOFKLYS3hkDokNO28um5KoxfUybd0LurwUOtuKVAn9FrbTZ1roumrUP8p+107qefUGg/fJsXrpjm9SA3WAjvaTtMuhCgzErCIysGUo6bH3fzV+oTizgZamVxZB3un3MxIuPnDHV9CzajCjzXlqFOon1yg/hz+AHT9rnQKOdMumheHs1o/puFz0Pa/9vc3ZqldUGUxnTyoNS0lMZxaCFEkpbKWkBBl7sh7sG+K+r3BS603iBimLpZW1rUFFUVWgrry6uXf1Z+tpxO3t/qqPXoXdQSQfyu1mLbl7NIbdeJVA+7+B/55UB0m7BYAzafnv39ZF5ZKsCLELUEyLKLiSj4Fq5qpo0U8w8yrm5q5B6kPaMtKo6UlO0UdHuxSBbosK5mptYvDZIS/o9RgRe8KkeOh2VTb6cQrKmOWWvQb2AH8W5R3a4QQFYSjz+8yHMgvhBMUBXY8oQYrIXfBwIvQe5s6pbpHiDrMde8r8Gs9deirdeFkibXBpC4Jf3m1unbHsQ9K/hrO2j9VDVYMHnD3Zmg/79YIVkDNnNR7TIIVIUSRSMAiKqYzi9XuA4MHdFhgXtG2A7SdCwMvQKevoEqEmnXZ8ST81hjO/1iybTj4f3DB6pz7p0HKmZK9hjPOLIXDb6vfd1wIge3Kry1CCFHGJGARFU9GHOw2z3babDpUrWf7ut5Fneb8nqPQ9gPwqKYOu/3nATgwI/8FwZxx4Wc48Lr6fcf/qaNHjGmw8+min//KetjxNKScdv7Y63vUeUoAGr8MEUOL1gYhhLhFScAiKp69L6ldPr7NoPGL+e9ncIeGz0DUKXX5doAD09W5P4rTRZRwSJ17BKDBMxD5KLT/BPRu6vwh577Le4yiqCNv8nPqC/irl7py75+dIH6n/f3OfAt/dIC/7oZdk9Tjrm6ADQPVtWws84QIIcRtRopuRcUS+xf8dRegg96bnZsQ7MR82DlBrT0J6wddlzs/S2jmdVjdQc3YhNwJd66+ORrpwJvqVPAeIXDPEXUYsaLAhZ/U7qLUc9BoEjSeBK7mv0FFUWeLPfCG+rObvzoBmsFLbV+NAer2rAS17WcW59+2qvWhz3bHRwIJIcQtQOZhESUjK1F9IIf8C6qEl+61spPh99ZqsFD/abWg1FkXfoFND6vZCP82ateRNfcgqHFP3oe+KVtdg+fgW5B+CarUhj47wSPo5j7GTPi9FSQdhXrj1TVm9k2B+O25rhEITV+DyHHq+jinF6rbm0yBppPhn8EQ+6c6jLj9fPBpBJtHQNo5dVuTKWp9TsIBSDQvLqh3g39Fy9L2QohKRwIWUXxX/4EtI9TVe/Xu0OBp9WFq/RAvSVvHqlPLe9WC/vvBzbdo54nbDn/fY7vSrjW9m7oOTsRw9b8XfjEX1JpXxq1SW11nx95olqsb1OnjrRm81BWGfZuqmZTk4+btHuoop9yzz+aeRh8doKiLEnb6BoI72Z7f8r+orJIrhKiEJGARRWfMUhfQO/y22r3i4n1z9ViXqtD4BfUB7ZKru6U4E4+d+x42DgZ00Gt98adITzmtTjqXlWi7PWG/OlGahfWifu7B6pwm9R5X62Pys208nPpM7Sqq97iaTbEMLTblqNO9H3xTXWDP4AVdl6lZHWu5FyqsO1YdAeVatTjvWgghbjkSsIiiSTwKWx5R144BqDsG2r6vLhS371W4sTufA3VQewh0/Nz5idzSLsCqFmptR9NXoeXMYr2FQiUcUBfQO7NE7YZx9YFGL6qzxToSMBgz1cLb4C7qYn5298lQg7CANup6N/mJjVYDvZA7i/RWhBDiVicBi3Bc5nU4/4Na8Hl1A6CoxaEdPoVag27up5jU/fZNvdntkVtgR+jxK3gEO3ZtxaSOnrmyDgLaqYW2ZTXlvmJS61E8q0shqxBClBNZS0gULuGQmjW5/LvtMODqA6DDJ+oaMNZ0eqg1GMIHQdb1XOfaD/8MUhfi+7MT9PwdfOoX3oYj/1GDFYMXdF5ctusD6fQFZz+EEEJUGBKw3K6ybsD6fpB2Xv3Zr6W6qGDth6FKrYKP1enUkTDWQu5UsyPr+qmjfNZ0VjMtBQ1LvrEX9r+mft/2ffBpUOS3I4QQonKTieNuR4oC259QgxXvetD/IPTfC01eLjxYKYhPQ+i9BQLaqhO/Rd8J1zbZ39eUA1sfVTM7NQeqk7MJIYQQ+ZCA5XYU8zWcWw46F+iyBPyalty5PUPgrvXqjKzGDNg8PO9IHYDjH6oFvK5+0H6BDNkVQghRIAlYbjcpp9UZVQGavwGB7Uv+Gq7e6lBe77rqHC47n7Z9PfWsWrgL0PpdNcgRQgghCiABy+3ElKOukZOTDMFdocnk0ruWq486CZrOoI4+OrNE3a4o6gKAxjQI7gaRY0uvDUIIISoNCVgqK0WB9CuQHnvz68CbELdFDSY6fwN6Q+m2IbgTNJumfr/jSUg5o85fcmmlOttsh0+KN9mcEEKI24aMEqqMctLVqemv/GX/9fbz1enny0LT1+DyajVQ2jxM7ZICdYp/WRdHCCGEg+TjbWWjKLB9vFWworv5pdND/SfV4ctlRe+iZnNcqqpBS8YVdTRR0yll1wYhhBC3PMmwVDZH58AZc+3Iv9ZUjCnfvetCu3mwdZT6c4dPC16rRwghhMhFApbK5NJq2Puy+n2b/1aMYMWizgi10NbFu/gLGwohhLjtSJdQRZISAyvCYNfzzh+bfBI2Payuj1N3LDSYUPLtKw6dDuo/AXUeKe+WCCGEuAVJwFKRnPofZMTC8Q/UuUoclZ0Ef98L2QkQeAe0/1gmYhNCCFGpSMBSUSiKOuQX1CzJ8Y8cPM4EW0ZC0hF11eHuK6Q+RAghRKUjAUtFkbAPkk/c/PnkZ5CTWvhxB96ECz+D3h26rQDPsNJroxBCCFFOJGCpKCzZlZr3gXek2r0T81XBx5xfAQffUr/v8AkEdSzVJgohhBDlRQKWikBR4Oxy9ftaD0PDier3x95Xu3zsSTigdgUBNHwO6o4q9WYKIYQQ5UUCltKQeg6Ovg8Xf3Ns/4R9kHISDB5Q4x6oO1qdPj/pmDpLbG6Z8fD3fWqXUchd6gKCQgghRCUm87CUlIw4OP+9usjftX/UbToD9NsHfk0LPtaSXaneX13pGCDyMXUSuKNzoXq/m/tmXod/BkFqDFSpo66KrJdfoxBCiMpNMiwl4fRX8GOYusDftX8AHXhUA8UIe14o+Fjr0UHhg29ubzBBnUo/9k9IPKxui42GVS3g6npwqQI9fgb3wNJ4R0IIIUSFIgFLcZmMsG8KKDng3wpavwcDz8Hdm0DvqnbpXPo9/+Nv7LXtDrLwrgM17lO/P/Iu7H4B/uoF6RehagO4az34NS+99yWEEEJUINKXUFxX/4b0S+DmD723gcHt5msNnoWj/4HdkyC0lxrA5GbJrlh3B1k0eg4u/AinF93cVu8JaPOemmERQgghbhOSYSmuM4vV/4YPsg1WAJpNBfcgSDoKJz7Je6yiwDnL6KCH8r4e3A38W6vfuwdD91+gw3wJVoQQQtx2JGApDmOGWmgLEDE87+tuftDCPE/Kgdch64bt6zf2QsoptTuo+oC8x+t00O17aPU29D8ANaNKsvVCCCHELUMCluK4uFJdx8crHKp1s79P5DjwbQpZ1+HAWze3m7Ih5kv1++oD8nYHWXjXhSavgGdIybZdCCGEuIVIDUtxWLqDag9VR/TYo3eBNnNgXR84Pg8yrkLiQXXtH1O2uk+twfaPFUIIIQQgGZaiy0qASyvV7+11B1kL660W1So5cHYJJOxXgxWXqlAjSp2OXwghhBD5kgxLUZ3/AUxZ4NsM/FsUvn+Hz+Dw2+ARog5H9msBVWqrdSpCCCGEKJAELEVl6Q6KGObY/l7Vod0HpdceIYQQohKTLqGiSLsIV9ar3zsasAghhBCiyCRgKYqzSwEFgruq3TpCCCGEKFVFClg++ugjIiIi8PDwoGPHjmzfvr3A/efOnUvDhg3x9PQkPDyc559/noyMDO11o9HItGnTqFOnDp6enkRGRjJjxgwURSlK80qf1h1USLGtEEIIIUqE0zUsy5YtY9KkSSxYsICOHTsyd+5c+vTpw7Fjx6hWrVqe/ZcsWcLkyZNZuHAhnTt35vjx44wePRqdTsecOXMA+Pe//838+fP58ssvadq0KTt37mTMmDH4+vry7LPPFv9dlqTEo+qEbzoXGY4shBBClBGnMyxz5sxh3LhxjBkzhiZNmrBgwQK8vLxYuHCh3f03b95Mly5dGDZsGBEREfTu3ZuhQ4faZGU2b97Mfffdx4ABA4iIiGDQoEH07t270MxNubi+U/1vUCdZKVkIIYQoI04FLFlZWezatYtevXrdPIFeT69evdiyZYvdYzp37syuXbu04OP06dOsWrWK/v372+wTHR3N8ePHAdi3bx8bN26kX79++bYlMzOTpKQkm68ykXZe/a93nbK5nhBCCCGc6xKKi4vDaDQSEmI7TXxISAhHjx61e8ywYcOIi4uja9euKIpCTk4OTzzxBK+++qq2z+TJk0lKSqJRo0YYDAaMRiMzZ85k+PD8a0Rmz57Nm2++6UzzS4YlYPEKL/trCyGEELepUh8ltH79embNmsXHH3/M7t27WbFiBStXrmTGjBnaPsuXL2fx4sUsWbKE3bt38+WXX/Lee+/x5Zdf5nveKVOmkJiYqH2dP3++tN+KKlUCFiGEEKKsOZVhCQoKwmAwcOXKFZvtV65cITQ01O4x06ZNY8SIETz22GMANG/enNTUVMaPH89rr72GXq/npZdeYvLkyTz88MPaPmfPnmX27NmMGjXK7nnd3d1xd3d3pvklQzIsQgghRJlzKsPi5uZG27ZtiY6O1raZTCaio6Pp1KmT3WPS0tLQ620vYzAYALRhy/ntYzKZnGle2bAELFUkYBFCCCHKitPDmidNmsSoUaNo164dHTp0YO7cuaSmpjJmzBgARo4cSY0aNZg9ezYAUVFRzJkzh9atW9OxY0dOnjzJtGnTiIqK0gKXqKgoZs6cSa1atWjatCl79uxhzpw5jB07tgTfagnISYOs6+r3kmERQgghyozTAcuQIUO4du0a06dPJzY2llatWvHHH39ohbjnzp2zyZZMnToVnU7H1KlTuXjxIsHBwVqAYvHhhx8ybdo0nnrqKa5evUr16tV5/PHHmT59egm8xRJkya64eIOrb/m2RQghhLiN6JQKO52sc5KSkvD19SUxMREfH5/SuUjsWvjrbvBpDPccLp1rCCGEELcRR5/fspaQM2SEkBBCCFEuJGBxhhTcCiGEEOVCAhZnyJBmIYQQolxIwOKM1HPqf71qlW87hBBCiNuMBCzOkC4hIYQQolxIwOIoRZEuISGEEKKcSMDiqOxEyElRv5eARQghhChTErA4ypJdcQsAF6/ybYsQQghxm5GAxVEyB4sQQghRbiRgcZTUrwghhBDlRgIWR8kIISGEEKLcSMDiKMmwCCGEEOVGAhZHScAihBBClBsJWBwlRbdCCCFEuZGAxRGKAukX1O+lhkUIIYQocxKwOCIzDowZ6veeNcq3LUIIIcRtSAIWR1jqVzxCweBevm0RQgghbkMSsDhCW6VZuoOEEEKI8iABiyNkDhYhhBCiXEnA4ggZ0iyEEEKUKwlYHCEBixBCCFGuJGBxhAQsQgghRLmSgMURMmmcEEIIUa4kYCmMyQjpF9XvpehWCCGEKBcSsBQmIxYUI+gM4BFW3q0RQgghbksSsBTGUr/iWR30hvJtixBCCHGbkoClMFJwK4QQQpQ7CVgKIwW3QgghRLmTgKUwMsutEEIIUe4kYCmM1iVUq3zbIYQQQtzGJGApjNSwCCGEEOVOApbCSJeQEEIIUe5cyrsBFZqiQPhgSDsLXrXLuzVCCCHEbUsCloLodNDu/fJuhRBCCHHbky4hIYQQQlR4ErAIIYQQosKTgEUIIYQQFZ4ELEIIIYSo8CRgEUIIIUSFJwGLEEIIISo8CViEEEKICibHZCrvJlQ4ErAIIYQQFcgzq1YR9M47nElIKO+mVCgSsAghhBAVyPdHjpCYmcm6mJjybkqFIgGLEEIIUUHcSE8nNiUFgKNxceXcmopFAhYhhBBOURSFT3ftYtO5c+XdlErniFWQciw+vhxbUvFIwCKEEMIpuy5f5vHffuPOL7/kz1Onyrs5lcrha9e078srw5KWnc3vJ05grGCFvxKwCCGEcMox84M022Ti/mXL2HrhQjm3qPKwDlhO3bhBttFY5m14NTqa/kuW8Npff5X5tQsiAYsQQginnE1MBECv05GWnc2AJUs4dPVqObeqcrAOWHJMJk7duFGm1zeaTHx78CAA72/bxqXk5DK9fkEkYBFCCOEUy3DbSXfcwR01a3I9PZ3e33wjw3BLgCVgcdWrj+djZdwttOXCBa6kpgKQkZPD/23YUKbXL4gELEIIIZxiybA0q1aNlcOG0TQ4mEvJydz99ddcrkCfyG81yZmZnE9KAqBX3bqAc3UsV1NTuWg+vqhWHDkCQNPgYAA+272b02Wc5clPkQKWjz76iIiICDw8POjYsSPbt28vcP+5c+fSsGFDPD09CQ8P5/nnnycjI0N7PSIiAp1Ol+fr6aefLkrzhBBC2HH42jWeXrmSq+ZP0EVlyaTU9vMjwNOT1Y88Qm1fX05ev06H//2P3Zcvl0BrnROflsYTv/12S49csgQnod7e3FGzprrNwZFC5xMTafrxxzSfP5+kzMwiXV9RFC1gmXHnnfSJjCTHZOLNv/8u0vlKmtMBy7Jly5g0aRKvv/46u3fvpmXLlvTp04er+fRfLlmyhMmTJ/P6669z5MgRPv/8c5YtW8arr76q7bNjxw4uX76sfa1ZswaAwYMHF/FtCSFEybmcnExadnZ5N6PYXl6zho937uTN9euLfA6TonDWHLBE+PkBUMPHh79GjaJRUBAXkpLounAh3x06VPwGO+GDbdv4ZNcu+i5ezN7Y2DK9dkmxdAc1CQ6mUVAQ4FiGxWgyMfKnn4hLS+NGRgbbilgEvSc2lrOJiXi6uNCnXj3+71//AuDrffsqRI2S0wHLnDlzGDduHGPGjKFJkyYsWLAALy8vFi5caHf/zZs306VLF4YNG0ZERAS9e/dm6NChNlmZ4OBgQkNDta/ffvuNyMhIevToUfR3JoQQJeDQ1avUef99en/9NSZFKe/mFFlmTg7rzpwBYOnBg2Tm5BTpPFdTU8k0GtHrdNSoWlXbXtffn62PPkrfevVIz8nhoe+/583168vsnv187BgAKVlZDFiyhPPmbqtbiRawBAVpAcuxuDiUQu7he5s3s978uwXYdvFika7/ozm70q9+fbxcXWlXvToPNG6MAkwvRpBbUpwKWLKysti1axe9evW6eQK9nl69erFlyxa7x3Tu3Jldu3ZpAcrp06dZtWoV/fv3z/ca33zzDWPHjkWn0+XblszMTJKSkmy+hBCipM3bvp1Mo5FN589r6fJb0ebz57Us0Y2MDH49frxI57F0B9X08cHVYLB5zdfDg9+GDmXSHXcA8Mbff9Ptiy94ZtUq5mzZwoojR9gXG1voA7gobdp35Qp6nY5GQUFcSk6m/5IlJFqVHhSHSVFYdvBgqc+Lcth8/ibBwdQPCECH+ru6lpaW7zE7L11i6rp1AHQydyMVNWBZcfQoAA80aqRtm3HnnehQa1t2XrpUpPOWFKcClri4OIxGIyEhITbbQ0JCiM0nBTds2DDeeustunbtiqurK5GRkfTs2dOmS8jaTz/9REJCAqNHjy6wLbNnz8bX11f7Cg8Pd+atCCFEoZIzM/nmwAHt52nr1hVrFd2Ptm8naunSItcYFMdq8wRvLubRJ4v27i3Sec7k6g7KzaDX858+ffj83ntx1evZfP4883bs4IU//+TB5ctp9cknvBodXaRr5+dXc3alW61arH7kEcK8vTl49SqDvvuuROYx+WDbNh7+4QeafvwxI378kZPXr+fZJ8toZOelS8QXEFwUxrpLyNPVVbvH+QVKKVlZDPvhB3JMJgY3acJ/evcGYNuFC04HhUfj4jh87Rquej0DGjTQtjcJDmZEy5YATC3neVlKfZTQ+vXrmTVrFh9//DG7d+9mxYoVrFy5khkzZtjd//PPP6dfv35Ur169wPNOmTKFxMRE7ev8+fOl0XwhxG1s6cGDpGRlEenvT6CnJ0fj4vhm//4in+///vmH344fL/P6DkCbkXZK164A/HHypLZmjTMs9Su1fX0L3G9s69bsf/JJFgwYwOQuXRjStCnNq1UDbnbflBTL+e5t2JBavr6sHDaMKq6urD19mvG//VasjI6iKHy2ezegZlq+2b+fRvPmMfbnn4k+fZq3N26kzzff4P/vf9P+s8/ovmhRkWaITc/OJsY8GqexeYROw0LqWJ7/4w9OXL9OTR8fPrnnHlqHheGq13MtLc3pIeaW7qC76tbFz8PD5rU3evTAVa9n9alTbCzHomanApagoCAMBgNXrlyx2X7lyhVCQ0PtHjNt2jRGjBjBY489RvPmzbn//vuZNWsWs2fPxpTrl3r27FnWrl3LY489Vmhb3N3d8fHxsfkSQoiS9MmuXQA82a6d9qB/Y/36ItV/XLda1O73kydLrpEOuJqayh5zFnxChw7cUbMmRkVhcRGCr8IyLNYaBQXxeLt2zO7Vi28HDeKvUaMAdb2c4mQirCVkZPD32bMA3NewIQCtw8L4bvBgDDodi/buZeWJE0U+//aLFzl87RqeLi78NXIkA+rXx6gofLF3L72+/pop0dH8eeqU1t12+No1fjR3rTjjWHw8ChDo6UmwlxcAjQID1dfsBCy/HDvG//bsQQd8c//9+Ht64uHiQkvzs9jZbiF73UEWdfz9ebVbN+YPGECHGjWcOm9JcipgcXNzo23btkRbpfNMJhPR0dF06tTJ7jFpaWno9baXMZj7PXNHvV988QXVqlVjwIABzjRLCCFK3M5Ll9h9+TJuBgOjWrXiqfbtqV61KmcTE7VP3NYOXr1a4EiKI1YzmK45fbpMp1xfY86utA4NpVqVKowyp/gX7dvndPbBMgdLYRkWe4K8vGhofghvLqGs+KoTJ8gxmWgaHExkQIC2vV/9+jxnrqX5aMeOIp9/4Z49AAxq0oQ769Tht2HD2GIuLq5etSoDGzXi/b59OfDkk0zt1g2AdzZtcvq+WncHWeo3tZFCdoY2v79tGwAvdOpEj4gIbXtHc0DhzEihc4mJ7Lx0CR1wn52ABeCNnj15ol073HLVLZUlp7uEJk2axGeffcaXX37JkSNHePLJJ0lNTWXMmDEAjBw5kilTpmj7R0VFMX/+fL799ltiYmJYs2YN06ZNIyoqSgtcQA18vvjiC0aNGoWLi0sJvDUhhCi6T3buBNQHVZCXF56urkzv3h2A/9uwgdSsLAASMzJ4auVKms+fT6fPP893+LP1lOtJmZlsKcP1d/48fRqA3pGRAAxp2hR3g4GDV69qmRdHOZNhsaeLud5wUwkFLL9YdQfl9mS7duhQu79O2ak7KUxadjZLzdPUj2nVStt+R82a/D58OBcnTeLHIUN4tmNHmlWrxjMdO+Lh4sKOS5e0rI+jrAMWi/yGNselpfG3eVTQk+3b27ymBSxOZFgs3UHdatemWpUqTrW7LDkdsAwZMoT33nuP6dOn06pVK/bu3csff/yhFeKeO3eOy1aTBk2dOpUXXniBqVOn0qRJEx599FH69OnDJ598YnPetWvXcu7cOcaOHVvMtySEEMWTlJmpPageb9tW2z62dWvq+vtzJTWVD7dv56ejR2ny8cfMNwc3yVlZHMjVZW5hHbAA/F6MbgpnKIqi1a/0MQcs/p6eDDR/knam+FZRlOIHLLVqASUTsGQZjVr32n12ApbIgAD61KsH3Ozec8YPhw+TnJVFHT8/myxGfqpVqaIFNu9s2uTUtQoKWM4kJJBh1Q3567FjGBWFVqGh1PX3tzlPR/NIod2XL5PlYBavoO6giqRIRbcTJkzg7NmzZGZmsm3bNjp27Ki9tn79ehYtWqT97OLiwuuvv87JkydJT0/n3LlzfPTRR/jl+mPv3bs3iqLQwKo6WQhRuWQbjeW6ZP1/t2xh1E8/MWfLFtbFxHAjPd3ufov37yc1O5tGQUF0Mz9gAVwNBt7s2RNQR0zcv2wZl5KTqRcQoD1o8pu07Ij5U3KP2rWBsqtjOXD1KrEpKXi5utLZajSlpVtoyYEDDj/Y4tLSSM/JQQeEF6FLCG5mWHZcvFjkuWAs1p85Q1JmJmHe3rTPp7biqXbtAPh8zx7SnZz87wtzMDemVSv0BUyzYW1Sp07odTp+P3mS/fkEr/bYC1iqVamCr7s7JkWxGZlUUIBRPyAAfw8PMo1Gh66/4+JFrZD2/saNHW5veZC1hISo4FKysm7JSbByO5uQQOA77zB8xYpyuf7l5GQm/fknX+3bxwt//sm/vvqKgHfeoc777/PKmjVcMM/lpCiK9ml8fJs2eeaDGtqsGU2DgzEqCi56PVO6dmX/E08QZf6wlV/AYnkgPX/HHeiAfVeulMlKuKvNgdGdERG4W3W33x0ZSZi3N/Hp6ax0cE4WS3aletWqRa5laBAYSJCXF5lGY7Gn8P/Z/OCOatAg34Cif/361PL15Xp6Ot8dPuzwuU/fuMG6M2fQAaOsuoMKUy8ggAfND/73Nm926Jgso1ELSBqbsyoAOvO8MnCzWyg5M1PLmD1gJ8DQ6XRaYWxhdSy/nzhBzy+/xKQo9ImMpFYRg9CyIgGLEBXcg8uXU2vuXHosWsTPR4+WeYZi/5UrPPfHH8Ue1fHzsWMkZ2Wx7NChItUTFJdl0qtQb28eaNyYOuYs75mEBN7ZvJk677/PIytWsHDPHvZduYK7udg2N4Nez/LBg3m2Qwd2jhvHrLvuwtPVlVbm0Rl77XyqTbJa1K577dq0M0/b8EcZZFly169YuOj1jGjRAriZSSiM9RpCRaXT6bRMT3G6hRRF4RdzoGWvfsXCoNdr3XqWrjtHWLrK7i7Cg/ylzp0BdVj8OQc+bJyIj8eoKPi4u1PdavZgyFvHsurECbKMRhoEBtpkY6w5UseyaO9eopYuJS07m96RkXx3CyyFIwGLEBVYltHIXzExAGw4e5aBy5bR6KOP+Gj79jJb2+atv//m/W3bijzRmIX11OHFPVdR7DJ/mu8dGckPDz3E6YkTufHKK6x46CF61K5NjsnE4gMHeOzXXwEY3LQpAZ6eds/VJDiY9/v104aQAlrAsv/KlTxBpfWidv6envQz11WUdrdQWnY2/5iLP/vkCljgZubg1+PHueurrwoduWMZIVTU+hWLriUQsOyJjeVCUhJVXF25y7yycX4ebd0aV72erRcuOJTVMZpM2t/oWCeyKxbta9TgzogIckwm5m7dWuj+9kYIWWhT9JtHCll3B+U3G3zHAma8VRSFmRs2MObnnzEqCiNatODXoUOp6u7u4LsrPxKwCFGBHY2LI8dkwsfdnclduuDn4cHJ69eZ8PvvPPTdd2XWBrhZg2FPSlYWb65fr00qlptJUdhgNWpi0b59DmeKFEVh24ULJBRzmnVLhqVdWJi2zc/Dg/sbN2b96NHsHDeOYc2b46LXo9fpmJBr9EVh6gcE4OniQlp2NqfME4BZ5K5P6Fe/PqAONy7OzLmF2XD2LJlGI7V8fWlgHk5srUlwMG/27ImrXs9fMTF0WbiQvt98w/Z8PplrBbfF7DrQCm/PnSvypG6W7qA+9erhUcjI0hBvbwY1aQLA/FxDnBMzMvgrJoaYGze0tkTHxHA+KQl/D498h/kW5uUuXQD4dNcurudTK2VhvYZQbtYZloycHK37zl53kIWlS+h4fHyeOq1Xo6O1qfyndO3KlwMHlutQZWdIwCJEBWYZcdIiJITZvXpx/vnneffuuwH4KyamVB92gE2x37EClrmfv2MHb/z9N8/8/rvd1w9dvUp8ejperq4EeHpyISmJteauisJ8sG0bd3z+OTXnzGHi779rs4E6Q1EULcPSNp9ZtNtWr87iBx7g7HPPcfDJJ7VPqY4y6PU0N4+WzF3HkvuB1L56dQI9PUnMzGRLKc7Sbalf6V23br6fxqf36MHJZ59lXJs2uJhnM+34v/+xwE73iTYHSzEzLG3DwnA3GLiWlmZ3mntHWGa3tTc6yJ4nzcW3Sw4eJCEjg7MJCbywejXh//0vd331FXU/+AD/f/+bnosW8cKffwIwvHnzQoOh/PSJjKRFSAip2dlMWr26wMDMeg2h3Czz1hyNi+PPU6dIzc6mpo+P1q1oT5CXF5Hm0UPWweeGs2d52zx66cN+/Zh1110FrtlX0UjAIkQFdsA8EZllSnNvNzcmdepEVTc30nNySn0xtvOJiWSaR5AcLyBg2WcOrNacPq3NT2LN0h3UtVYthjdvDsBCB7qFUrKy+L9//gEgNTubD7Zvp96HHzJo+fJ8swD2XEpOJjYlBb1Op3Xd5Kd61ara1OjOapVPwHIk1wPJoNdrNSWFdQuZFIVvDx7kBycKRi0s9SuWob35qeXry6dRURybMIHB5kzEh+YFa60Vd0izhbuLi/bALUq30L7YWPZduYKLXk9/c7aqMF1r1aJZtWqkZWfTc9EiIj/4gDlbt5KclUWotzeuej2JmZn8ffYsB83/341p3drptlnodDreu/tu9DodX+7bx4wNG/Ld194IIYvIgAAMOh0pWVnMM/9OCuoOssjdLZSenc1jv/wCwGOtWzOhQwfn31Q5k4BFiAosd8ACoNfpaG3u1thVyqunWgcpV1NT8+2WsTyQM3JytBEM1tabu4N61K7NWPND4KejRwst5J23fTtxaWnUCwjg9+HD6RMZiUlR+OHIEe743/8cHt1iya40CQ7Gy9XVoWOKQiu8zS/DYvVAcqSO5VJyMv0WL2boDz8w6LvvnApa/oqJ4fC1a+h1Ou6qU8ehY+r6+7PgnnvQ63QcvnZNGzkFtnOwFGWW29y0CeSKsDaN5cH9YOPGBJmnsS+MTqfThjjvu3IFo6LQq25dVg0bxsVJk0h59VX2PP44C++9l2c7dOCDvn1pY9V9WBR3R0byUf/+ALy+fj1f7duXZ58ck0mbet9eoOxmMGgz+K4xB6AFdQdZ5C68fX39ek5cv06NqlV5z7xI4q1GAhYhKjBLl1DzXCuktzE/GHcVc1hoYU7kStfbW9PEpCg2mZ5fcgUR1vUrPSMiaBUaSuvQULKMRpZYrYScW1JmJu+ah4VO796dvvXq8ccjj3DgySe5r2FDFGDUTz/ZPFTzo9WvFLKoanHZC1jS7CxqBzezHntjY7lsZ3jzD4cP03z+fJsA8NFffuF0IV1iJkXh3xs3cvfXXwMwoH59/PMpHrYnwNOT9ub7ZH3tGxkZpJizZyUx/LWoE8hdT09nsfnvxtkswahWrRjarBljW7Vi7+OPs2bECPrVr49ep8PNYKBVaChjWrfm/X79eMZqfrHieKJdO142jxp69JdftCJ6i1PXr5NtMuHl6prvfW1kVdsS7OVFV6u5gfJjPUX/9osX+c+WLQAsuOcefHMtbnirkIBFiAoqISNDGwrbzCrDAjfrMAoKWI7GxfH1vn18uG0bb/39N5NWr+aZVasK7NrJLfe+9o49l5hoM2Lpt+PHbQpqD1+7RlxaGl6urlrAYMmyFNQt9OG2bVxPT6dhYCBDzd1IoN6LZYMG0TYsjPj0dB7+/vtCa3m0+pVifmIuTPOQEHTA5ZQUrqamAmqQl3tRO1AnBbMe3qwoCrEpKWw5f54xP//MoO++43p6Om3Cwtj/xBN0Dg8nMTOTh7//Pt+J3m6kp3Pft98yOToak6IwsmVLvh00yOn3Yemusg5YLNmVUG9vPEsgS2UZ2nwkLq7QolRrC/fsIT0nh1ahoVqWxlFerq4sefBBPr/vPpsRXqVtdq9eDGnalByTiQeWLWPt6dN8d+gQr0ZHM9bcTdM4KCjfuWQaWRVM39ewIQZ94Y/uVqGhuBkMxKenM2j5ckyKwrDmzbnnFp6cVRbtEaKCsmRXwn188iz3bnnw7o2NxWgy5fkHLCkzk/affaZ9IrZ5LSuLLwcOdKgNlgDF08WF9Jwcu4W3lkX9GgYGcjU1lbi0NDafP08384yulvqVLuHh2miEYc2b88Kff7I3NpY9ly9rXVwWiRkZ2ifC6T164JLr/bm7uLBs0CDafPopm86fZ9pffzG7Vy+770FRlDLLsHi7uVE/MJDj8fHsi43l7sjIAoes9qtXj52XLvHc6tU8tWqVzfTrOmBy16680bMnbgYD3z74IK0++YQdly7xypo1/LdvX5v3+M+5c4z66SfOJCTgbjDwYb9+PGZn4jtH9ImMZMaGDaw5fVr7+zpbgt1BcHMhxGPx8Ww+f96hB6nRZNIWMpzQvv0tUzCq1+lYNHAgF5OT2XjunJb9svavArrtGlplWBzpDgL1/5FWoaFsv3iR80lJBHt58b7V38ytSDIsQlRQWv1Kru4gUGcLreLqSlp2tt0gYv2ZM6RkZeHv4cFDTZsyvk0b7R86ZzIsli6hu82fuO0da3kgtwgJYYD5oWMZwQFoi8BZpqQHtdvhfvNwUctquNbe37aNGxkZNA4KYkjTpnbbFhkQwOf33gvA25s25TsJ28XkZK6mpmLQ6Whp516WtJa5Cm9zF9xau79RI3SoAWaGZcp7Hx961a3L36NHM+uuu7QgL9zXVws0527bxk9Hj5JjMrH80CE6ff45PRYt4kxCAnX9/dny6KOMa9u2yA/0DjVq4OPuzvX0dG3ekpIquLXmbB3LyhMnOJOQQICnJ8Ossm63Ag8XF34aMoTm1arh4eJC++rVGd+mDfMHDGDbY4/x73wCbriZYfVxdy8wsMmto9VyBR/26+dwvU9FJRkWISoobUhzru4gUEeZtA4LY+O5c+y6dCnPw9AyZHhI06bMv+ceQH2ArjhypNAaCItso1Grvbinfn1+OXbMfobFUjAYFESzatX4Zv9+fj52TBt+bcmw9My1eNzY1q1ZdugQiw8c4N3evbXhowkZGcwxZ1fe6NmzwPT3oCZNeKpdOz7euZMRP/7I3scfp4aPj80+luxK02rVSqQrozCtQkP57vBhbcbbgkaAtA4LY+tjj5GUmUkdPz/CfX0LnBPjngYNeKFTJ/6zZQujf/oJPw8Pbaixu8HAyJYteefuu/Nk5JzlajBwV506/Hj0KH+eOkX7GjVKJ2CpVYuFe/ey0cE6Fkux7aOtW5fJ77KkBXp5se+JJzApikPdOhbtq1dnTu/eNK1WzWZ5hcJENWjAh9u381DTpjyUT+B/K5GARYgKqqAMC6jdQhvPnWPX5cuMMC9kZ2EJWO62mt3UMhX91dRUUrKy8HZzK/D6MQkJGBWFKq6u2kq1J+LjMSmKTV+7dQahb716uBkMnLx+naNxcZgUhbi0NDxdXPIsTndXnTqE+/hwPimJ2nPn0tpcjHshOZnEzEyaVaumTfZVkP/06cPmCxfYGxvLY7/+yu/Dh9u8bhlJVdr1Kxa5C28tAUtjO5OCwc1Jvhw1+6672HjuHNsuXiQxM5MgLy+ebt+eJ9u1I8Tbuxgtt9U7MpIfjx5l9alTvNa9+805WEpwvZncCyEW9DA+GhfHmtOn0QFPOTmpX0Wi0+kwOJn50ul0PN+pk9PXujsykpiJEwn38bllus8KIl1CQlRAiqJoc0E0t5NhAbQhl7kLby8mJXEkLg4d6oJ3Fr4eHgSaR4s4MvmapfunfmAgdf39cdXrSc/JyTPUVXsgBwdT1Spl/fOxY1p2pbNV/YqFQa/ntW7dcNHruZqayupTp3h70ya+2b8fgDd69HBohVwPcz2LQafjj5Mn2ZPrfuw0/1za9SsWloDlWFwciRkZ2sRo+a374ixXg4EfHnqI8W3a8Ok993Duued4o2fPEg1W4Gbh7ZYLF0jKzCyVDIv1QojLDx0qcN+PzNmVqIYNS7QNlV2En59T2ZyKrHK8CyEqmfNJSSRmZuKi19sU3FmzZAz2XL5sMyon2jxssl316nmGs9Y1z37pSLfQCUvAEhCAi16vzQVhPbT5inluFr1Op039bpl59Odjx7T6ldzdQRaPt2tH4uTJbH30UeYPGMD4Nm3oUKMGo1q2dGqp+waBgVrKe47V2i2KopR5hiXM25tgLy+MisKPR4/mu6hdcdTw8eGTqCjGtW1bal0jdf39qRcQQI7JxLqYmBJZ+DA3nU7HuDZtABj366/51rIkZWayyDyHyTO34IRnomRIwCJEBWSpX2kUFJRvTUOjoCC8XF1Jzc62mS/F0h3Uy86CcM4ELJYMiyUQsfzXuo7Fkl2p6++v1aBEmQtvt124oA2LzS9gAXWoaceaNXmiXTs+iYpi22OPsWjgQIeyK9YmmVPm3x48qGWBziclcS0tDRe9nhZlUHAL6kPYkmWxzDNjb4TQraC3+W9o+eHDJGZmAiXbJQQw4847ua9hQzKNRu799ts8hd1ZRiNT//qLlKwsGgUFOTwJnqh8JGARt5ztFy/y5G+/cSUlxanjTIpCehmtcFxc9ma4zc2g12sPRksWQVGUEgtYLEFQfXNmxbKmifUD5Yid+owa5nVOFCAxM1OtXymD7ph21avT3bzq8ofbtgE370vT4OAyLdK0jBSyZLvsLWp3K7BMbmeZYTfYy4sqhdQ+Ocug17PkwQdpX70619PT6bd4MdfMc9hsu3CBtp9+qi0T8FLnzrdk4CdKhgQs4pbzwp9/smDXLp5atcqp4/ovXkzIe+/ZnTq+onEkYIGb3RyWOpYjcXFcTknBw8VFm5jLmhaw5LOqsrXcGZaGdjIs+Q3ZtV6QrlN4uFMjG4rjBXOW5ZNdu0jOzCyz+VdyswSSJvOCdyVVv1LWekZE4KLXa+tJlWR3kDUvV1d+HTqUOn5+nL5xg3u//ZaJv/9Op88/5+DVqwR5efH1/fczplWrUrm+uDVIwCJuKQkZGdrqtiuOHMl37o3cdly8yOpTp0jOyiJq6VJ+sZonpCLab7VKc0FyByyW7Eq3WrXsrjLraIYlLTtbm2W3fu4uIasalvxGwNxrFbD0tJp/pbTd06ABDQIDSczM5Iu9e8tshtvcci+wWNTFFMubj7u7TeBbmsWuId7erBo+HH8PD7ZeuMAH27ejACNatODI00/zSIsWkl25zUnAIm4pa06dwmi1TPuEXLOD5meeeXbMqm5uZBmNPLBsGcsOHiy1dhZHltGorc2T35BmizZWhbemQrqD4GbAEnPjhvbp355T5u4gf6uRRZbi33OJiVrX2pF8Fm1rXq2alpEpbKXgkqTX6Xj+jjsAmLt1a7llWBoGBeFuVXt0q2ZY4GYdC5R8/UpujYKC+Onhh/F2c6OOnx+rH3mEr+6//5af8EyUDAlYxC3FsrLt+DZtCPP25tSNG7y7aVOBx1xNTeVbc3DyxyOP8EiLFhgVhWErVvCFnVlWy9uxuDhyTCZ83d0JzzUJWm6Ng4PxdHEhOSuLI9euacOI8wtYavr4aCl+ewvuWVgPabZ8qg328sLPwwMFOHn9OjfS04k11xHlzrDodDpWDR/OmhEjnJ5npLhGtmxJoKcnMQkJxKen46LXFxr4lTTraxa0qN2toLfVXD5lMZy4e+3aXJo0iRPPPGNzbSEkYBG3DEVRtC6gh5o2ZU6fPgDM2rixwHlF/rd7N1lGIx1q1KBzeDhfDhzIuDZtMCkKY3/5hUUFLMBXHiz1K82qVSs0Be6i12uLuC3YuZPkrCwCPD3zdElY72/5lHyqgHtmKbhtYLXoms5q6PKx+Hgtu1LTx4eq7u55zlHX3z/fwKk0ebm68mS7dtrPlqnQy1orc8BS0KJ2t4I2YWFalq2s5j+p6u5eaeYOESVH/iJEmYlNSSE+La3Ix++7coXLKSlUcXWla61aDGnalDsjIsjIyWHiH3/YPSbHZGL+zp2AulgaqN0Gn9xzD8+a53N46++/i9ym0mAZ0lxYwa2FpT7jc3O26K46dQp8QDpSx3Lcag4Wa9YjheyNEKoonu7QQRsOXtb1KxaWodzOrihc0Rj0eub178/YVq0k4yHKlQQsokykZWfT5KOPaP3JJwXWThTk9xMnAHVVU3cXF3Q6HR/174+LXs+vx4/zq51C2p+OHuWCeaVS67U0dDodb/TsCahT0DuzvL09iqKQbR5JUVyFTcmfm+WBnG6u5Sksq+FIwGIvw2L987H4+ALXyClvod7ePN62LQD969cvlzYMa96c9aNGMfOuu8rl+iXp4WbN+Py++wpc50iI0iYBiygTJ+LjuZGRwfmkJC5aTe3uDEv9Sj+rIs7GwcFMMhdZPrlypTadvYVlsbTxbdvmGVrr7+mpPbx355rO3RnbLlygzaefEvaf/zg9N4w9jg5ptmiTK4NwdwkELA5lWKwWPayI/tunD8cmTGCgeVXosqbT6egREVHomk1CCMdIwCLKhPXD8aTVrKyOSsjIYLN5OHO/XJ+Yp/XoQcPAQC4mJ9Pp88/57fhxQB0a/PfZsxh0Op6wqmmwpg0LNo8mcUZyZqY2V8Te2Fji09MdHmadn8SMDM6ZF5lzNMPSJDhYG5FS19+fOuaAJD+FBSyJGRlcNU/cVT9XhsUyUuhYXFyFzrCA2pXRwKpoWAhxa5OARRTbpeRk6n/4IdPXrct3H+uH44kiBCxrT5/GqCg0CgrKU/jn7ebGprFj6RkRQUpWFvcuXcq7mzZp2ZX7GzemZj6jbSzZid3mlXUdoSgKK48fp+nHH2tzRVhG82wwr51TVJYMUbiPD34eHg4d42owaIW3vRyYtrywgMXy+wmpUgWfXMW09cwZlxsZGdrqvbfqHCNCiFuLBCyV1DubNnHft9+SVUJ1FQX58cgRTl6/XuBom+JmWCz1K/3ymdMj0MuLPx95hMfbtkUBXl67ls927wYKXizN0QyLSVHYduECr6xZQ8N587hn6VLOJyURYZ4rYsE99wCwIZ/F2xxx6vp13jQXADs7DHdUy5ZUdXNjbOvWhe5rCViupKaSmpWV5/UTuWa4tZZ7iG6Ql5fMkSGEKBNlP9ZPlIl/b9rE9fR0Np8/X+DCcyVh84ULgLrQXFp2Nl521myxngq+oAzL2YQEziYm0t1qdlRFUezWr+TmajAwf8AAmlerxsQ//sCoKLQICaFbrVr5HmPJsJy6cYOEjAy7WY3/27CB+Tt3cslq3hJ3g4EJHTrwZs+eVHFzIzEjAx1qMHYpOdmplXmTMjOZuWEDc7dtI8toxKDTMd68gq2jnmrfnqfMo6AK4+fhgb+HBzcyMohJSKBZrlqZ/OpXLBoGBmrdVhW1O0gIUflIhqUSSs/O1ka9FCWb4SxLbQncnCE1N5suoVyrsVqLWrqUHosW8dTKldqoG8twZi9XV5tAxh6dTsfTHTrwxyOPMKB+feYPGFBgDUOgl5fWxWSv8PZ4fDzT1q3jUnIy3m5uDGnalGWDBnHtpZd4r3dvbSE4Xw8Pbe6TfxzoFlIUhSPXrvHfLVuo/+GHvLN5M1lGI30iI9n/5JPcV8qFogV1Cx3PZ4SQhfX2ilpwK4SofCTDUglZZwJKO2C5lJzMGavsyfH4+DzdGUaTyWafU+Zp4XPPFZKSlaWNkJm/cyfH4uP5bvDgPMOZHdGrbl2HJy1rGxbGmYQEdl26xL9y1YCsMl+7a61arBkxosAJyLrXrs2e2Fj+OXeOIc2a5Xk9OTOTZYcO8VdMDOvOnNFmiQU1CJjTuzf969cvkyLRuv7+7Lp82W7AcsJqllt7GkrAIoQoBxKwVEIXrQKWohS4OsM6u5Lf9S4lJ5NlNOJinrkyIyeHi0lJhOearvyQOVixDAP9KyaGDp99hqe5i6mg7qDiaBsWxg9HjmgL5VmzdEUNbNiw0NlSu9WqxfvbtuVbePvUqlV8s3+/9rNlReUHGjViXNu2ZTrHRX4ZFkVR8qzSnFtDqyBFuoSEEGVFApZKqCwzLJaAxaDTYbR62FmzPBQj/PzQoQY1J69fzxOwWEbIdKpZk//07s29335rM318qQUs5oXxcncJpWVn87d5bZ7cQ6nt6Wburjpw9SrX09MJME9nDuqw7O8OHQLgpc6d6V+/PnfUrFkuU8ZD/gFLXFoaiZmZAETmMzzapktIAhYhRBmRGpZKyHpitpPXr6MUcWZZR1gClr7mYMJehsXyUKzr7691M9jbz3rCtOYhIWx/7DGtYLZJcHCh84sUlaXw9sT16yRmZGjb18XEkGk0UsvX16Guj2pVqtDIvN/GXKOFlh08SKbRSLNq1fh3r170jIgot2AF8g9Y9piHd4f7+GiZrdxq+/pyf6NGDG7ShBpOFBcLIURxSMBSCVlnWNKys7lcArOv2pOena1lJUa3agVQYIalrp8f9cwPSnuZH+tF/wCCq1Rh7ciRLBgwgKUPPlji7bcI8vLShurusZqPxXpkkqN1Jd3NAVbubqFF+/YBMLplywoxkZklYIlJSLBZKuHjHTuAgrNZOp2OFUOGsHzw4ArxXoQQtwcJWCoh6xoWKHhUTnHsunyZbJOJMG9vbVG0q6mpNlkKuDmkubAMy0E7a+i4GQw83q4dLZycl8RZuedjcXQodW6WUUzWAcuxuDi2XriAQadjeIsWJdXkYgn38cGg05GRk6MV/56Ij+cX83pMz3fqVJ7NE0KIPCRgqYQsGRbLZ9/SqmPZZO726Bwejo+7OyFVqgB5gxHrLiHLTKm523Q1NZWrqanoKJ9CTi1gMWeMTly/zukbN3DV6/OMHCqIJWDZffkyKeZJ2b40Z1f61qtHqLd3STa7yFwNBi2rZPn9zN26FQUYUL++1rUlhBAVhQQslZAlw2KZrr20RgpZJozrHB4O3CzGzN0tZFPDYhWwWHdFHLhyBYDIgAC7E8+VNkvhrSVgsQyl7la7NlVzTU9fkHBfX2r7+mJUFLacP4/RZOJr88ggS7dZRWFdx3I9PZ0vzDMVT5LsihCiApKApZJRFEUruu1h/rRfGgGLoihawa0lYLEEI9ZdUClZWdpCenX9/ant54eLXk9GTo5Nrc1BJ1coLmmWDMvx+HiSMjOL1B1kYd0t9FdMDBeSkvD38CCqQYOSa3AJsAQsp65fZ8HOnaTn5NAqNJQ7S3lmZCGEKAoJWCqZGxkZZJpniLU8OEujS+jk9evEpaXhbjDQ2pzJ0TIsVteLMWdXAjw98fXwwEWvp455ZlnrwCZ3wW1ZC65SRVvAcMv586y3DGcuTsBy7pxWbDu0WTOHJ70rK5Zhy0fi4vjQvFDkC506SSGtEKJCkoClkrFkVwI9PbWHf2kMbbZkV9rXqKE9iLWCWqtAxLo7yMJeHUt5Z1jg5vDm/2zZQqbRSLiPT5HqaSwBy7YLF/jxyBGg4nUHwc3fyYojR4hNSaFG1ao81LRpObdKCCHsk4ClkrF0s1SvWpUIPz8MOl2pDG3eZOkOqllT22Zdw2IJkOwFLFrXkTlgMSmK3RFCZc3SLbTm9GnAueHM1uoHBBBSpQqZRiPpOTk0DgqinblGpiKx/E6M5t/VMx06lOlsu0II4QwJWCoZS8FtDR8f3AwGatvpfikJuetX4GYXQ2JmJnFpaYDtHCwW9XIFLGcSEkjNzsbdYNBeKw9tcwUVjsxua49Op7NZpHF0q1YVspvFOois4urK+LZty7E1QghRMAlYKhlLl5BlBtL6+QwjLo6EjAwOXbsGQCergMXT1VUbKmsZKWQ9B4uFpevI0iZLdqVxcLC23lB5sGRYAFz1eu5yYjhzbpYZevU6HY9UkLlXcvP39MTPwwOAR1u3xt9qKQEhhKhoJGCpZKy7hCBvNqMkbDUPZ64XEEA189wrFrm7ewqrYTEpijakubwKbi1CvL21QK9rrVpODWfObWCjRgR5eTG2VSvtd1ERPdi4MdWrVpWhzEKICq9iDVsQxaZ1CZVihsVed5BFg8BAomNiOB4fj0lRtFFC1gFLRK6hzQcqQMGtRafwcL4/fJh7ijkEOdzXl2svvVSq6ziVhP/dey8mRUFfAbushBDCmgQslUxpZ1hMikJ0TAwAXfIJWCzXu5ycTKbRiIteb7Mys4teT4SfHyevX+dEfHyFGCFk8Z/evelZu3aJ1XNUxNqV3CRYEULcCqRLqJKxLroF23qR4n7az8zJYfiKFWw+fx69Tmd3ynpLRud4fLzWHVTb1zdPbYplv8PXrnHMXO9S3l1CALV8fXm6QwdcZbSMEEJUKBKwVCI5JhNXzMOXLV1CEX5+6EtgaHNiRgb9Fi/m24MHcdHr+XLgQLsjehpYBUiWbijr7iALy7G/nThBjsmEr7s7Nc1BlhBCCJGbBCyVSGxKCgpql0uwuRjWzWAgwjykuKh1LJeSk+m+aBHrzpzB282NVcOG5TvyxXrul43mxRHtBSyWDEu0ec6T5iEht0T3iRBCiPIhNSyViGVIc5i3t01dQr2AAE7fuMGJ+Hib+UHsyTIaOREfT0xCAmcSEoi5cYPvDh/mfFISod7erBo2jNZWw39zczUYqOvvz4nr11l96hRQcIYl22QCoFk5rNAshBDi1lGkDMtHH31EREQEHh4edOzYke3mdUjyM3fuXBo2bIinpyfh4eE8//zzZGRk2Oxz8eJFHnnkEQIDA/H09KR58+bs3LmzKM27beUuuLVwdKTQgStXiPzgA5rNn0/U0qU88/vvzNm6lfNJSTQIDGTz2LEFBiva9czdQpZ6GrsZFvM+FuU5w60QQoiKz+kMy7Jly5g0aRILFiygY8eOzJ07lz59+nDs2DGq2SmaXLJkCZMnT2bhwoV07tyZ48ePM3r0aHQ6HXPmzAHgxo0bdOnShTvvvJPff/+d4OBgTpw4gb+dB53IX+6CWwtHRgrtvHSJPt98w/X0dLzd3KgXEEAdPz8i/PyoHxDA0ObNtUnGCtMgIIBVVj/bC1hq+/pi0Om0aeErQsGtEEKIisvpgGXOnDmMGzeOMWPGALBgwQJWrlzJwoULmTx5cp79N2/eTJcuXRg2bBgAERERDB06lG3btmn7/Pvf/yY8PJwvvvhC21anGLOM3q4u5ZqDxaKwDMumc+fov2QJSZmZdKxRg9+HDy/WrKe5syf2AhZXc23NKfNIooowpFkIIUTF5VSXUFZWFrt27aJXr143T6DX06tXL7Zs2WL3mM6dO7Nr1y6t2+j06dOsWrWK/v37a/v88ssvtGvXjsGDB1OtWjVat27NZ599VmBbMjMzSUpKsvm63V3Mp0vIembZ3EObo0+fpvc335CUmUn32rVZM2JEsadob2AVsPh7eOSbmbEENjWqVpVp4YUQQhTIqYAlLi4Oo9FISK56g5CQEGJjY+0eM2zYMN566y26du2Kq6srkZGR9OzZk1dffVXb5/Tp08yfP5/69euzevVqnnzySZ599lm+/PLLfNsye/ZsfH19ta9wO5OY3W7yy7DU8fdHr9ORmp1NrNXQ5l+PHWPAkiWkZWfTJzKS34cPL9Z09Bb1rYY728uuWNQzvybdQUIIIQpT6sOa169fz6xZs/j444/ZvXs3K1asYOXKlcyYMUPbx2Qy0aZNG2bNmkXr1q0ZP34848aNY8GCBfmed8qUKSQmJmpf583Txd/OLKOEcmdY3AwGaptnmrXUsfxv924GLltGptHIwEaN+Pnhh/FydS2RdoT7+uJunnitoIClb716uOj13NewYYlcVwghROXlVA1LUFAQBoOBK+bF6iyuXLlCaGio3WOmTZvGiBEjeOyxxwBo3rw5qampjB8/ntdeew29Xk9YWBhNmjSxOa5x48b88MMP+bbF3d0d9xLIBlQm+RXdgtr9EpOQwIn4eNbFxPDG338DMKZVKz65554SndlVr9NRPzCQg1evFhiwDGjQgOQpU/BwkdH1QgghCuZUhsXNzY22bdsSHR2tbTOZTERHR9Mpn9Ve09LS0Oealt1gfjha6im6dOnCsWPHbPY5fvw4tQuZM0TclJKVRVJmJpA3wwI3u19e++svLViZ2q0bn997b6lMQ9/S3G1YWHePBCtCCCEc4fTTYtKkSYwaNYp27drRoUMH5s6dS2pqqjZqaOTIkdSoUYPZs2cDEBUVxZw5c2jdujUdO3bk5MmTTJs2jaioKC1wef755+ncuTOzZs3ioYceYvv27Xz66ad8+umnJfhWKzdL/Yq3mxs+djJPlgLXK6mp6HU6PurfnyfatSu19rzXuzcD6tdnUK7MmRBCCFEUTgcsQ4YM4dq1a0yfPp3Y2FhatWrFH3/8oRXinjt3ziajMnXqVHQ6HVOnTuXixYsEBwcTFRXFzJkztX3at2/Pjz/+yJQpU3jrrbeoU6cOc+fOZfjw4SXwFm8P+RXcWlgyHR4uLix98EEGNmpUqu0J9fZmaPPmpXoNIYQQtw+dUtwlfCuIpKQkfH19SUxMxOc2XERv8f79PPLjj9wZEcFfo0bleV1RFL7Yu5d21avTQmaVFUIIUUE4+vyWAoJKoqCCWwCdTsfY1q3LsklCCCFEiZHVmisJbR0hb+9ybokQQghR8iRgqSQKy7AIIYQQtzIJWCqJwopuhRBCiFuZBCy3EJOisOrECaKWLuXJ334jx2TSXstvllshhBCiMpCi21tAenY2X+/fz3+3buVoXJzNax8PGABYZVikS0gIIUQlJAFLBRd9+jQP//ADcWlpAPi4u3Nvw4Ys3r+fBbt2UcffnzGtWpFtzraEStGtEEKISkgClgrupTVriEtLo7avL8/dcQdjW7fGx92dtmFhPL96Na+sXUtCRgYA1apUwa0UptkXQgghypsELBVYbEoKe2JjAdg+bhzVqlTRXnvujjuIuXGDD7ZvZ/bGjYAU3AohhKi8pOi2Avvj5EkA2lWvbhOsWMzp08dmin0puBVCCFFZScBSgf1uDlj61atn93WDXs/iBx6gQ40aAESaV2QWQgghKhvpEqqgckwm/jx1Csg/YAHwcnXl9+HDWbx/P4ObNi2r5gkhhBBlSgKWCmrbhQskZGQQ4OmpZVDyE+DpyTMdO5ZRy4QQQoiyJ11CFZSlO6h3ZCQGvfyahBBC3N7kSVhBFVa/IoQQQtxOJGCpgGJTUth9+TIAfSIjy7k1QgghRPmTgKUCWm3OrrQNCyNEZq4VQgghJGCpiKQ7SAghhLAlAUsZuZCUxPAVK/hg2zaSMzPz3c9mOHP9+mXVPCGEEKJCk4CljHy8YwdLDhxg4h9/EP7f//LymjWcT0zMs9/2ixe5kZGBv4cHHQsZziyEEELcLiRgKSOnb9wA1IneEjMzeXfzZuq8/z7DfviBnZcuafv9fuIEIMOZhRBCCGsycVwZiUlIAOCrgQNxd3FhzpYtrDtzhqUHD7L04EG61arFpE6dWCX1K0IIIUQeErCUkTPmgKWuvz+tw8K4p0ED9ly+zJytW/n24EH+OXeOf86d0/bvKwGLEEIIoZE+hzKQlp3N1dRUACL8/LTtrcPC+Pr++zkzcSKvdOmCn4cHAJ1q1pThzEIIIYQVybCUAUt2xdfdHX9Pzzyv1/Dx4e1evZjavTt/njpF++rVy7iFQgghRMUmAUsZsAQs1tkVe7zd3HigcePSb5AQQghxi5EuoTIQYx4hVMffv5xbIoQQQtyaJGApA1qGxde3fBsihBBC3KIkYCkDZ8wTxBXWJSSEEEII+yRgKQPSJSSEEEIUjwQsJUBRFJIKWB/I0aJbIYQQQtgnAUsJmPrXX/i9/TabrCZ+s0jOzCQ+PR2QgEUIIYQoKglYSsCm8+dRgFXmdYCsWbIrAZ6e+Li7l23DhBBCiEpCApYSEJeWBsDu2Ng8r0l3kBBCCFF8ErCUAEuXz+7Ll1EUxeY1y6KHdSRgEUIIIYpMApZiUhRFy7BcTU3lckqKzeuSYRFCCCGKTwKWYkrOyiLHZNJ+3n35ss3rkmERQgghik8ClmKyZFcs9uQKWCTDIoQQQhSfBCzFFJ8rYMldeCsBixBCCFF8ErAUkyXDotfpANsuoYSMDBIyMgAJWIQQQojikIClmCwBS9uwMADOJSZqWRdLdiXYy4sqbm7l0j4hhBCiMpCApZgsQ5ojAwKINK8VtMfcLWRZQ0iyK0IIIUTxSMBSTJYMS6CnJ63NWRZL4a0lwyKLHgohhBDFIwFLMVm6f4K8vGgTGgrcLLzVCm59fculbUIIIURl4VLeDbjVxZm7hIK8vKgfEADczLDESIZFCCGEKBGSYSkme11Cx+PjSc7MlCHNQgghRAmRgKWYrLuEqlWpQo2qVVGAfVeuaBkWCViEEEKI4pGApZi0DIuXF4CWZVl7+jQpWVkA1JYaFiGEEKJYJGApBkVRtGHNQeaAxVJ4u+LIEQBCvb3xdHUtnwYKIYQQlYQELMWQkpVFltEIqDUscDPDcuDqVUAWPRRCCCFKggQsxWDJrni4uOBlzqK0MQcsFlK/IoQQQhRfkQKWjz76iIiICDw8POjYsSPbt28vcP+5c+fSsGFDPD09CQ8P5/nnnyfDvMYOwBtvvIFOp7P5atSoUVGaVqbirApudea1hMJ9fAgwZ1tAAhYhhBCiJDg9D8uyZcuYNGkSCxYsoGPHjsydO5c+ffpw7NgxqlWrlmf/JUuWMHnyZBYuXEjnzp05fvw4o0ePRqfTMWfOHG2/pk2bsnbt2psNc6n4U8RYD2m20Ol0tAkLY+3p04B0CQkhhBAlwekMy5w5cxg3bhxjxoyhSZMmLFiwAC8vLxYuXGh3/82bN9OlSxeGDRtGREQEvXv3ZujQoXmyMi4uLoSGhmpfQUFBBbYjMzOTpKQkm6+yZj2k2Zql8BYkwyKEEEKUBKcClqysLHbt2kWvXr1unkCvp1evXmzZssXuMZ07d2bXrl1agHL69GlWrVpF//79bfY7ceIE1atXp27dugwfPpxz584V2JbZs2fj6+urfYWHhzvzVkpE7iHNFq2t6lhkllshhBCi+JwKWOLi4jAajYSEhNhsDwkJIda8fk5uw4YN46233qJr1664uroSGRlJz549efXVV7V9OnbsyKJFi/jjjz+YP38+MTExdOvWjeTk5HzbMmXKFBITE7Wv8+fPO/NWSoQ2pNmqSwigrTlgMeh0hPv4lHm7hBBCiMqm1AtF1q9fz6xZs/j444/p2LEjJ0+eZOLEicyYMYNp06YB0K9fP23/Fi1a0LFjR2rXrs3y5ct59NFH7Z7X3d0dd3f30m5+geLy6RKqHxjIjDvvJNDTE/dboBZHCCGEqOicepoGBQVhMBi4cuWKzfYrV64QalW3YW3atGmMGDGCxx57DIDmzZuTmprK+PHjee2119Dr8yZ5/Pz8aNCgASdPnnSmeWXOkmHJ3SUEMLV797JujhBCCFFpOdUl5ObmRtu2bYmOjta2mUwmoqOj6dSpk91j0tLS8gQlBoMBUGeKtSclJYVTp04RlmtOk4omvwyLEEIIIUqW0/0VkyZNYtSoUbRr144OHTowd+5cUlNTGTNmDAAjR46kRo0azJ49G4CoqCjmzJlD69attS6hadOmERUVpQUuL774IlFRUdSuXZtLly7x+uuvYzAYGDp0aAm+1ZJnb1izEEIIIUqe0wHLkCFDuHbtGtOnTyc2NpZWrVrxxx9/aIW4586ds8moTJ06FZ1Ox9SpU7l48SLBwcFERUUxc+ZMbZ8LFy4wdOhQ4uPjCQ4OpmvXrmzdupXg4OASeIulJ79hzUIIIYQoWTolv36ZW0xSUhK+vr4kJibiUwYjcxRFwXPmTDKNRs5MnEhtmW9FCCGEcJqjz29ZS6iI0rKzybQsfCgZFiGEEKJUScBSRJb6FXeDgSrmhQ+FEEIIUTokYCki6yHNloUPhRBCCFE6JGApIhnSLIQQQpQdCViKSAIWIYQQouxIwFJE8TIHixBCCFFmJGApIsmwCCGEEGVHApYi0opuJcMihBBClDoJWIpIMixCCCFE2ZGApYi0dYQkYBFCCCFKnQQsRWTpEpIMixBCCFH6JGApIukSEkIIIcqOBCxFJMOahRBCiLIjAUsRpGVnk56TA0iGRQghhCgLErAUgSW74qrX4+3mVs6tEUIIISo/CViKwLp+RRY+FEIIIUqfBCxFIAW3QgghRNmSgKUItFluJWARQgghyoQELEUgGRYhhBCibEnAUgQypFkIIYQoWxKwFIFkWIQQQoiyJQFLEci0/EIIIUTZkoClCOKkS0gIIYQoUxKwFIF0CQkhhBBlSwKWIpBhzUIIIUTZkoClCCTDIoQQQpQtCViclJ6dTVp2NiABixBCCFFWJGBxkqU7yEWvp6osfCiEEEKUCQlYnBQvCx8KIYQQZU4CFifJkGYhhBCi7EnA4qSrqakABFepUs4tEUIIIW4fErA46Yo5YAn19i7nlgghhBC3DwlYnBSbkgJAiGRYhBBCiDIjAYuTLBkWCViEEEKIsiMBi5OumDMs0iUkhBBClB0JWJykdQlJwCKEEEKUGQlYnCRdQkIIIUTZk4DFCSZF0YY1S5eQEEIIUXYkYHHC9fR0ckwmAKpJhkUIIYQoMxKwOMFScBvg6YmrwVDOrRFCCCFuHxKwOEEmjRNCCCHKhwQsTpBJ44QQQojyIQGLE67IkGYhhBCiXLiUdwNuJVqXkGRYhBC3EZPJRFZWVnk3Q9yiXF1dMZRA3acELE6QSeOEELebrKwsYmJiMJlHSApRFH5+foSGhqLT6Yp8DglYnCCTxgkhbieKonD58mUMBgPh4eHo9VJFIJyjKAppaWlcvXoVgLCwsCKfSwIWJ8g6QkKI20lOTg5paWlUr14dLy+v8m6OuEV5enoCcPXqVapVq1bk7iEJl50gXUJCiNuJ0WgEwM3NrZxbIm51loA3Ozu7yOeQgMVB1tPyS5eQEOJ2Upy6AyGgZP6GJGBx0PX0dIyKAsi0/EIIIURZK1LA8tFHHxEREYGHhwcdO3Zk+/btBe4/d+5cGjZsiKenJ+Hh4Tz//PNkZGTY3fftt99Gp9Px3HPPFaVppcbSHRQo0/ILIcRtJyIigrlz5zq8//r169HpdCQkJJRam243Tgcsy5YtY9KkSbz++uvs3r2bli1b0qdPH60COLclS5YwefJkXn/9dY4cOcLnn3/OsmXLePXVV/Psu2PHDj755BNatGjh/DspZTJpnBBCVHw6na7ArzfeeKNI592xYwfjx493eP/OnTtz+fJlfH19i3Q9kZfTAcucOXMYN24cY8aMoUmTJixYsAAvLy8WLlxod//NmzfTpUsXhg0bRkREBL1792bo0KF5sjIpKSkMHz6czz77DH9//6K9m1IUKyOEhBCiwrt8+bL2NXfuXHx8fGy2vfjii9q+iqKQk5Pj0HmDg4OdGinl5uZW7HlHhC2nApasrCx27dpFr169bp5Ar6dXr15s2bLF7jGdO3dm165dWoBy+vRpVq1aRf/+/W32e/rppxkwYIDNuQuSmZlJUlKSzVdpkjlYhBCi4gsNDdW+fH190el02s9Hjx6latWq/P7777Rt2xZ3d3c2btzIqVOnuO+++wgJCcHb25v27duzdu1am/Pm7hLS6XT873//4/7778fLy4v69evzyy+/aK/n7hJatGgRfn5+rF69msaNG+Pt7U3fvn25fPmydkxOTg7PPvssfn5+BAYG8sorrzBq1CgGDhyY7/uNj49n6NCh1KhRAy8vL5o3b87SpUtt9jGZTLzzzjvUq1cPd3d3atWqxcyZM7XXL1y4wNChQwkICKBKlSq0a9eObdu2FeHuly6nApa4uDiMRiMhISE220NCQoiNjbV7zLBhw3jrrbfo2rUrrq6uREZG0rNnT5suoW+//Zbdu3cze/Zsh9sye/ZsfH19ta/w8HBn3orTrsjCh0KI25yiKKRmZZXLl2Ie9FASJk+ezNtvv82RI0do0aIFKSkp9O/fn+joaPbs2UPfvn2Jiori3LlzBZ7nzTff5KGHHmL//v3079+f4cOHc/369Xz3T0tL47333uPrr79mw4YNnDt3zibj8+9//5vFixfzxRdfsGnTJpKSkvjpp58KbENGRgZt27Zl5cqVHDx4kPHjxzNixAibXowpU6bw9ttvM23aNA4fPsySJUu053hKSgo9evTg4sWL/PLLL+zbt4+XX365Qs5sXOoTx61fv55Zs2bx8ccf07FjR06ePMnEiROZMWMG06ZN4/z580ycOJE1a9bg4eHh8HmnTJnCpEmTtJ+TkpJKNWiJtawjJF1CQojbVFp2Nt5OfLAsSSlTplClhOaDeeutt7j77ru1nwMCAmjZsqX284wZM/jxxx/55ZdfmDBhQr7nGT16NEOHDgVg1qxZfPDBB2zfvp2+ffva3T87O5sFCxYQGRkJwIQJE3jrrbe01z/88EOmTJnC/fffD8C8efNYtWpVge+lRo0aNkHPM888w+rVq1m+fDkdOnQgOTmZ999/n3nz5jFq1CgAIiMj6dq1K6DWmV67do0dO3YQEBAAQL169Qq8ZnlxKmAJCgrCYDBw5coVm+1XrlwhNDTU7jHTpk1jxIgRPPbYYwA0b96c1NRUxo8fz2uvvcauXbu4evUqbdq00Y4xGo1s2LCBefPmkZmZaXdWPHd3d9zd3Z1pfrFI0a0QQlQO7dq1s/k5JSWFN954g5UrV3L58mVycnJIT08vNMNiPUCkSpUq+Pj45DsABdTJ0yzBCqjT1Fv2T0xM5MqVK3To0EF73WAw0LZt2wKzHUajkVmzZrF8+XIuXrxIVlYWmZmZWr3NkSNHyMzM5K677rJ7/N69e2ndurUWrFRkTgUsbm5utG3blujoaK1PzWQyER0dnW8UmpaWlmf9CUsAoigKd911FwcOHLB5fcyYMTRq1IhXXnmlRFZ4LAlSwyKEuN15ubqSMmVKuV27pFTJ9e/4iy++yJo1a3jvvfeoV68enp6eDBo0qNAVql1ztUmn0xUYXNjbv7hdXe+++y7vv/8+c+fOpXnz5lSpUoXnnntOa7tlWvz8FPZ6ReJ0l9CkSZMYNWoU7dq1o0OHDsydO5fU1FTGjBkDwMiRI6lRo4ZWjxIVFcWcOXNo3bq11iU0bdo0oqKiMBgMVK1alWbNmtlco0qVKgQGBubZXp5klJAQ4nan0+lKrFumItm0aROjR4/WumJSUlI4c+ZMmbbB19eXkJAQduzYQffu3QE1e7J7925atWqV73GbNm3ivvvu45FHHgHUJMLx48dp0qQJAPXr18fT05Po6Gitp8NaixYt+N///sf169crfJbF6YBlyJAhXLt2jenTpxMbG0urVq34448/tAKec+fO2WRUpk6dik6nY+rUqVy8eJHg4GCioqJsKpQrOpOicM2SYZGARQghKpX69euzYsUKoqKi0Ol0TJs2rVyKTp955hlmz55NvXr1aNSoER9++CE3btwocGh0/fr1+f7779m8eTP+/v7MmTOHK1euaAGLh4cHr7zyCi+//DJubm506dKFa9eucejQIR599FGGDh3KrFmzGDhwILNnzyYsLIw9e/ZQvXp1OnXqVFZv3SFFKrqdMGFCvl1A69evt72Aiwuvv/46r7/+usPnz32O8haflqZNyx8sK5YKIUSlMmfOHMaOHUvnzp0JCgrilVdeKfWpMux55ZVXiI2NZeTIkRgMBsaPH0+fPn0KLI2YOnUqp0+fpk+fPnh5eTF+/HgGDhxIYmKits+0adNwcXFh+vTpXLp0ibCwMJ544glALfX4888/eeGFF+jfvz85OTk0adKEjz76qNTfr7N0SkmOFStHSUlJ+Pr6kpiYiI+PT4me+8CVK7RYsIAgLy+uvfRSiZ5bCCEqqoyMDGJiYqhTp45TozhFyTCZTDRu3JiHHnqIGTNmlHdziqWgvyVHn9+lPqy5MpCCWyGEEKXt7Nmz/Pnnn/To0YPMzEzmzZtHTEwMw4YNK++mVQiyWrMDZEizEEKI0qbX61m0aBHt27enS5cuHDhwgLVr19K4cePyblqFIBkWB8gIISGEEKUtPDycTZs2lXczKizJsDhAuoSEEEKI8iUBiwMkYBFCCCHKlwQsDpAuISGEEKJ8ScDiACm6FUIIIcqXBCwOuCIrNQshhBDlSgKWQhhNJq5KDYsQQghRriRgKUR8ejomRUEHBEvAIoQQt4WePXvy3HPPaT9HREQwd+7cAo/R6XT89NNPxb52SZ2nspGApRCWgtsgLy9c9HK7hBCiIouKiqJv3752X/vnn3/Q6XTs37/f6fPu2LGD8ePHF7d5Nt544w27KzFfvnyZfv36lei1KgN5AhdCCm6FEOLW8eijj7JmzRouXLiQ57UvvviCdu3a0aJFC6fPGxwcjFcZLX4bGhqKu7t7mVzrViIBSyFkDhYhhLh13HPPPQQHB7No0SKb7SkpKXz33Xc8+uijxMfHM3ToUGrUqIGXlxfNmzdn6dKlBZ43d5fQiRMn6N69Ox4eHjRp0oQ1a9bkOeaVV16hQYMGeHl5UbduXaZNm0Z2djYAixYt4s0332Tfvn3odDp0Op3W5txdQgcOHOBf//oXnp6eBAYGMn78eFLMH6YBRo8ezcCBA3nvvfcICwsjMDCQp59+WruWPadOneK+++4jJCQEb29v2rdvz9q1a232yczM5JVXXiE8PBx3d3fq1avH559/rr1+6NAh7rnnHnx8fKhatSrdunXj1KlTBd7H4pCp+Qshc7AIIYSZooAxrXyubfACna7Q3VxcXBg5ciSLFi3itddeQ2c+5rvvvsNoNDJ06FBSUlJo27Ytr7zyCj4+PqxcuZIRI0YQGRlJhw4dCr2GyWTigQceICQkhG3btpGYmGhT72JRtWpVFi1aRPXq1Tlw4ADjxo2jatWqvPzyywwZMoSDBw/yxx9/aIGCr69vnnOkpqbSp08fOnXqxI4dO7h69SqPPfYYEyZMsAnK1q1bR1hYGOvWrePkyZMMGTKEVq1aMW7cOLvvISUlhf79+zNz5kzc3d356quviIqK4tixY9SqVQuAkSNHsmXLFj744ANatmxJTEwMcXFxAFy8eJHu3bvTs2dP/vrrL3x8fNi0aRM5OTmF3r+ikoClEFqXkGRYhBC3O2MaLC+nD28PpYCLY/8Ojx07lnfffZe///6bnj17Amp30IMPPoivry++vr68+OKL2v7PPPMMq1evZvny5Q4FLGvXruXo0aOsXr2a6tWrAzBr1qw8dSdTp07Vvo+IiODFF1/k22+/5eWXX8bT0xNvb29cXFwIDQ3N91pLliwhIyODr776iirm59C8efOIiori3//+NyEhIQD4+/szb948DAYDjRo1YsCAAURHR+cbsLRs2ZKWLVtqP8+YMYMff/yRX375hQkTJnD8+HGWL1/OmjVr6NWrFwB169bV9v/oo4/w9fXl22+/xdXVFYAGDRoUeu+KQ7qECqF1CUmGRQghbgmNGjWic+fOLFy4EICTJ0/yzz//8OijjwJgNBqZMWMGzZs3JyAgAG9vb1avXs25c+ccOv+RI0cIDw/XghWATp065dlv2bJldOnShdDQULy9vZk6darD17C+VsuWLbVgBaBLly6YTCaOHTumbWvatCkGg0H7OSwsjKtXr+Z73pSUFF588UUaN26Mn58f3t7eHDlyRGvf3r17MRgM9OjRw+7xe/fupVu3blqwUhYkw1II6RISQggzg5ea6Sivazvh0Ucf5ZlnnuGjjz7iiy++IDIyUnv4vvvuu7z//vvMnTuX5s2bU6VKFZ577jmysrJKrLlbtmxh+PDhvPnmm/Tp00fLRvznP/8psWtYyx046HQ6TCZTvvu/+OKLrFmzhvfee4969erh6enJoEGDtHvg6elZ4PUKe700SMBSCCm6FUIIM53O4W6Z8vbQQw8xceJElixZwldffcWTTz6p1bNs2rSJ++67j0ceeQRQa1KOHz9OkyZNHDp348aNOX/+PJcvXyYsLAyArVu32uyzefNmateuzWuvvaZtO3v2rM0+bm5uGI3GQq+1aNEiUlNTtSzLpk2b0Ov1NGzY0KH22rNp0yZGjx7N/fffD6gZlzNnzmivN2/eHJPJxN9//611CVlr0aIFX375JdnZ2WWWZZEuoULIsGYhhLj1eHt7M2TIEKZMmcLly5cZPXq09lr9+vVZs2YNmzdv5siRIzz++ONcuXLF4XP36tWLBg0aMGrUKPbt28c///xjE5hYrnHu3Dm+/fZbTp06xQcffMCPP/5os09ERAQxMTHs3buXuLg4MjMz81xr+PDheHh4MGrUKA4ePMi6det45plnGDFihFa/UhT169dnxYoV7N27l3379jFs2DCbjExERASjRo1i7Nix/PTTT8TExLB+/XqWL18OwIQJE0hKSuLhhx9m586dnDhxgq+//tqmm6qkScBSiBc7d+b5O+6glp3qbSGEEBXXo48+yo0bN+jTp49NvcnUqVNp06YNffr0oWfPnoSGhjJw4ECHz6vX6/nxxx9JT0+nQ4cOPPbYY8ycOdNmn3vvvZfnn3+eCRMm0KpVKzZv3sy0adNs9nnwwQfp27cvd955J8HBwXaHVnt5ebF69WquX79O+/btGTRoEHfddRfz5s1z7mbkMmfOHPz9/encuTNRUVH06dOHNm3a2Owzf/58Bg0axFNPPUWjRo0YN24cqeZeh8DAQP766y9SUlLo0aMHbdu25bPPPivVbItOURSl1M5ehpKSkvD19SUxMREfH5/ybo4QQtzyMjIyiImJoU6dOnh4eJR3c8QtrKC/JUef35JhEUIIIUSFJwGLEEIIISo8CViEEEIIUeFJwCKEEEKICk8CFiGEEEJUeBKwCCGEKFAlGUwqylFBs+46Sma6FUIIYZerqys6nY5r164RHByszRQrhKMURSErK4tr166h1+txc3Mr8rkkYBFCCGGXwWCgZs2aXLhwwWbadiGc5eXlRa1atdDri96xIwGLEEKIfHl7e1O/fn2ys7PLuyniFmUwGHBxcSl2hk4CFiGEEAUyGAwYDIbyboa4zUnRrRBCCCEqPAlYhBBCCFHhScAihBBCiAqv0tSwWOYJSEpKKueWCCGEEMJRlud2YfP9VJqAJTk5GYDw8PBybokQQgghnJWcnIyvr2++r+uUSjKFoclk4tKlS1StWrVEJzdKSkoiPDyc8+fP4+PjU2LnFfbJ/S5bcr/LltzvsiX3u2wV9X4rikJycjLVq1cvcJ6WSpNh0ev11KxZs9TO7+PjI3/wZUjud9mS+1225H6XLbnfZaso97ugzIqFFN0KIYQQosKTgEUIIYQQFZ4ELIVwd3fn9ddfx93dvbybcluQ+1225H6XLbnfZUvud9kq7ftdaYpuhRBCCFF5SYZFCCGEEBWeBCxCCCGEqPAkYBFCCCFEhScBixBCCCEqPAlYhBBCCFHhScBSiI8++oiIiAg8PDzo2LEj27dvL+8m3fJmz55N+/btqVq1KtWqVWPgwIEcO3bMZp+MjAyefvppAgMD8fb25sEHH+TKlSvl1OLK5e2330an0/Hcc89p2+R+l6yLFy/yyCOPEBgYiKenJ82bN2fnzp3a64qiMH36dMLCwvD09KRXr16cOHGiHFt86zIajUybNo06derg6elJZGQkM2bMsFlIT+538WzYsIGoqCiqV6+OTqfjp59+snndkft7/fp1hg8fjo+PD35+fjz66KOkpKQ41xBF5Ovbb79V3NzclIULFyqHDh1Sxo0bp/j5+SlXrlwp76bd0vr06aN88cUXysGDB5W9e/cq/fv3V2rVqqWkpKRo+zzxxBNKeHi4Eh0drezcuVO54447lM6dO5djqyuH7du3KxEREUqLFi2UiRMnatvlfpec69evK7Vr11ZGjx6tbNu2TTl9+rSyevVq5eTJk9o+b7/9tuLr66v89NNPyr59+5R7771XqVOnjpKenl6OLb81zZw5UwkMDFR+++03JSYmRvnuu+8Ub29v5f3339f2kftdPKtWrVJee+01ZcWKFQqg/PjjjzavO3J/+/btq7Rs2VLZunWr8s8//yj16tVThg4d6lQ7JGApQIcOHZSnn35a+9loNCrVq1dXZs+eXY6tqnyuXr2qAMrff/+tKIqiJCQkKK6ursp3332n7XPkyBEFULZs2VJezbzlJScnK/Xr11fWrFmj9OjRQwtY5H6XrFdeeUXp2rVrvq+bTCYlNDRUeffdd7VtCQkJiru7u7J06dKyaGKlMmDAAGXs2LE22x544AFl+PDhiqLI/S5puQMWR+7v4cOHFUDZsWOHts/vv/+u6HQ65eLFiw5fW7qE8pGVlcWuXbvo1auXtk2v19OrVy+2bNlSji2rfBITEwEICAgAYNeuXWRnZ9vc+0aNGlGrVi2598Xw9NNPM2DAAJv7CnK/S9ovv/xCu3btGDx4MNWqVaN169Z89tln2usxMTHExsba3G9fX186duwo97sIOnfuTHR0NMePHwdg3759bNy4kX79+gFyv0ubI/d3y5Yt+Pn50a5dO22fXr16odfr2bZtm8PXqjSrNZe0uLg4jEYjISEhNttDQkI4evRoObWq8jGZTDz33HN06dKFZs2aARAbG4ubmxt+fn42+4aEhBAbG1sOrbz1ffvtt+zevZsdO3bkeU3ud8k6ffo08+fPZ9KkSbz66qvs2LGDZ599Fjc3N0aNGqXdU3v/tsj9dt7kyZNJSkqiUaNGGAwGjEYjM2fOZPjw4QByv0uZI/c3NjaWatWq2bzu4uJCQECAU78DCVhEuXr66ac5ePAgGzduLO+mVFrnz59n4sSJrFmzBg8Pj/JuTqVnMplo164ds2bNAqB169YcPHiQBQsWMGrUqHJuXeWzfPlyFi9ezJIlS2jatCl79+7lueeeo3r16nK/KxnpEspHUFAQBoMhz0iJK1euEBoaWk6tqlwmTJjAb7/9xrp166hZs6a2PTQ0lKysLBISEmz2l3tfNLt27eLq1au0adMGFxcXXFxc+Pvvv/nggw9wcXEhJCRE7ncJCgsLo0mTJjbbGjduzLlz5wC0eyr/tpSMl156icmTJ/Pwww/TvHlzRowYwfPPP8/s2bMBud+lzZH7GxoaytWrV21ez8nJ4fr16079DiRgyYebmxtt27YlOjpa22YymYiOjqZTp07l2LJbn6IoTJgwgR9//JG//vqLOnXq2Lzetm1bXF1dbe79sWPHOHfunNz7Irjrrrs4cOAAe/fu1b7atWvH8OHDte/lfpecLl265Bmmf/z4cWrXrg1AnTp1CA0NtbnfSUlJbNu2Te53EaSlpaHX2z7KDAYDJpMJkPtd2hy5v506dSIhIYFdu3Zp+/z111+YTCY6duzo+MWKXTJciX377beKu7u7smjRIuXw4cPK+PHjFT8/PyU2Nra8m3ZLe/LJJxVfX19l/fr1yuXLl7WvtLQ0bZ8nnnhCqVWrlvLXX38pO3fuVDp16qR06tSpHFtduViPElIUud8lafv27YqLi4syc+ZM5cSJE8rixYsVLy8v5ZtvvtH2efvttxU/Pz/l559/Vvbv36/cd999Msy2iEaNGqXUqFFDG9a8YsUKJSgoSHn55Ze1feR+F09ycrKyZ88eZc+ePQqgzJkzR9mzZ49y9uxZRVEcu799+/ZVWrdurWzbtk3ZuHGjUr9+fRnWXNI+/PBDpVatWoqbm5vSoUMHZevWreXdpFseYPfriy++0PZJT09XnnrqKcXf31/x8vJS7r//fuXy5cvl1+hKJnfAIve7ZP36669Ks2bNFHd3d6VRo0bKp59+avO6yWRSpk2bpoSEhCju7u7KXXfdpRw7dqycWntrS0pKUiZOnKjUqlVL8fDwUOrWrau89tprSmZmpraP3O/iWbdund1/s0eNGqUoimP3Nz4+Xhk6dKji7e2t+Pj4KGPGjFGSk5OdaodOUaymAxRCCCGEqICkhkUIIYQQFZ4ELEIIIYSo8CRgEUIIIUSFJwGLEEIIISo8CViEEEIIUeFJwCKEEEKICk8CFiGEEEJUeBKwCCGEEKLCk4BFCCGEEBWeBCxCCCGEqPAkYBFCCCFEhff/FkF9iQRu4iAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc = histPreT.history['accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "val_acc = histPreT.history['val_accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "loss = histPreT.history['loss'][START_PLOT_FROM_EPOCH:]\n",
        "val_loss = histPreT.history['val_loss'][START_PLOT_FROM_EPOCH:]\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, color='teal', label='Training acc')\n",
        "plt.plot(epochs, val_acc, color='orange', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, color='teal', label='Training loss')\n",
        "plt.plot(epochs, val_loss, color='orange', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 87\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading best epoch in our model using the checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dir= r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints' # C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model file: model-87-0.8903.keras\n"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = max(val_acc_per_epoch)\n",
        "best_model_file = f'model-{best_epoch:02d}-{best_val_accuracy:.4f}.keras'\n",
        "\n",
        "print(f'Best model file: {best_model_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\checkpoints'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(model_dir)\n",
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['checkpoints.lnk',\n",
              " 'ConvNextTiny_FT20-01-0.8195.keras',\n",
              " 'ConvNextTiny_FT20-04-0.8350.keras',\n",
              " 'ConvNextTiny_FT20-06-0.8462.keras',\n",
              " 'ConvNextTiny_FT20-07-0.8566.keras',\n",
              " 'ConvNextTiny_FT20-09-0.8584.keras',\n",
              " 'ConvNextTiny_FT20-27-0.8608.keras',\n",
              " 'ConvNextTiny_FT20-70-0.8611.keras',\n",
              " 'model-01-0.8824.keras',\n",
              " 'model-02-0.8867.keras',\n",
              " 'model-03-0.8893.keras',\n",
              " 'model-05-0.8895.keras',\n",
              " 'model-06-0.8934.keras',\n",
              " 'model-09-0.8961.keras',\n",
              " 'model-11-0.8966.keras',\n",
              " 'modelAlexNetFT10-01-0.8759.keras',\n",
              " 'modelAlexNetFT10-02-0.8841.keras',\n",
              " 'modelAlexNetFT10-06-0.8904.keras',\n",
              " 'modelAlexNetFT10-08-0.8968.keras',\n",
              " 'modelAlexNetFT10-13-0.8987.keras',\n",
              " 'modelAlexNetFT10-14-0.9022.keras',\n",
              " 'modelAlexNetFT10-24-0.9043.keras',\n",
              " 'modelDenseNet-01-0.8676.keras',\n",
              " 'modelDenseNet-02-0.8737.keras',\n",
              " 'modelDenseNet-03-0.8803.keras',\n",
              " 'modelDenseNet-04-0.8824.keras',\n",
              " 'modelDenseNet-05-0.8826.keras',\n",
              " 'modelDenseNet-08-0.8837.keras',\n",
              " 'modelDenseNet-12-0.8843.keras',\n",
              " 'modelDenseNet-14-0.8854.keras',\n",
              " 'modelDenseNet-15-0.8857.keras',\n",
              " 'modelDenseNet-16-0.8862.keras',\n",
              " 'modelDenseNet-22-0.8863.keras',\n",
              " 'modelDenseNet-23-0.8875.keras',\n",
              " 'modelDenseNet-39-0.8878.keras',\n",
              " 'modelDenseNet-40-0.8884.keras',\n",
              " 'modelDenseNet-43-0.8886.keras',\n",
              " 'modelDenseNet-49-0.8888.keras',\n",
              " 'modelDenseNet-59-0.8893.keras',\n",
              " 'modelDenseNet-75-0.8897.keras',\n",
              " 'modelDenseNet-81-0.8901.keras',\n",
              " 'modelDenseNet-87-0.8903.keras',\n",
              " 'modelMobileNetV2FT20-01-0.7942.keras',\n",
              " 'modelMobileNetV2FT20-02-0.8239.keras',\n",
              " 'modelMobileNetV2FT20-03-0.8364.keras',\n",
              " 'modelMobileNetV2FT20-04-0.8528.keras',\n",
              " 'modelMobileNetV2FT20-05-0.8658.keras',\n",
              " 'modelMobileNetV2FT20-06-0.8661.keras',\n",
              " 'modelMobileNetV2FT20-07-0.8704.keras',\n",
              " 'modelMobileNetV2FT20-08-0.8721.keras',\n",
              " 'modelMobileNetV2FT20-09-0.8774.keras',\n",
              " 'modelMobileNetV2FT20-10-0.8797.keras',\n",
              " 'modelMobileNetV2FT20-11-0.8807.keras',\n",
              " 'modelMobileNetV2FT20-12-0.8820.keras',\n",
              " 'modelMobileNetV2FT20-13-0.8822.keras',\n",
              " 'modelMobileNetV2FT20-14-0.8833.keras',\n",
              " 'modelMobileNetV2FT20-15-0.8838.keras',\n",
              " 'modelMobileNetV2FT20-16-0.8851.keras',\n",
              " 'modelMobileNetV2FT20-18-0.8858.keras',\n",
              " 'modelMobileNetV2FT20-19-0.8859.keras',\n",
              " 'modelMobileNetV2FT20-21-0.8876.keras',\n",
              " 'modelMobileNetV2FT20-23-0.8879.keras',\n",
              " 'modelMobileNetV2FT20-24-0.8880.keras',\n",
              " 'modelMobileNetV2FT20-26-0.8882.keras',\n",
              " 'modelMobileNetV2FT20-27-0.8887.keras',\n",
              " 'modelMobileNetV2FT20-31-0.8888.keras',\n",
              " 'modelMobileNetV2FT20-32-0.8891.keras',\n",
              " 'modelMobileNetV2FT20-33-0.8892.keras',\n",
              " 'modelMobileNetV2FT20-36-0.8901.keras',\n",
              " 'modelMobileNetV2FT20-47-0.8905.keras',\n",
              " 'modelMobileNetV2FT20-54-0.8907.keras',\n",
              " 'modelMobileNetV2FT20-57-0.8908.keras',\n",
              " 'modelMobileNetV2FT20-58-0.8911.keras',\n",
              " 'modelMobileNetV2FT20-62-0.8914.keras',\n",
              " 'modelMobileNetV2FT20-64-0.8916.keras',\n",
              " 'modelMobileNetV2FT20-66-0.8918.keras',\n",
              " 'modelMobileNetV2FT20-68-0.8924.keras',\n",
              " 'modelResNet50_FT20-01-0.8026.keras',\n",
              " 'modelResNet50_FT20-03-0.8136.keras',\n",
              " 'modelResNet50_FT20-08-0.8170.keras',\n",
              " 'modelResNet50_FT20-20-0.8295.keras',\n",
              " 'modelResNet50_FT20-24-0.8329.keras',\n",
              " 'modelResNet50_FT20-44-0.8339.keras',\n",
              " 'model_AlexNet-86-0.8629.keras']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(model_dir) if isfile(join(model_dir, f))]\n",
        "onlyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at modelMobileNetV2-56-0.8792.keras",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[64], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#loaded_model = load_model(os.path.join('checkpoints',best_model_file))\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodelMobileNetV2-56-0.8792.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39msummary()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
            "\u001b[1;31mOSError\u001b[0m: No file or directory found at modelMobileNetV2-56-0.8792.keras"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "#loaded_model = load_model(os.path.join('checkpoints',best_model_file))\n",
        "loaded_model = load_model('modelDenseNet-87-0.8903.keras') \n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Nq7Xip7rrJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgHLiCoC-6Jt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "60/60 [==============================] - 8s 108ms/step - loss: 3.4205 - accuracy: 0.8853\n",
            "test acc: 0.8853333592414856\n",
            "test loss: 3.420464515686035\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.EPOCHS,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = loaded_model.evaluate(test_generator, steps=len(test_generator))  # steps_per_epoch * epochs\n",
        "print('test acc:', test_acc)\n",
        "print('test loss:', test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 8.640947818756104 Training set > seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s Training set > seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize lists to collect true labels and predictions\n",
        "true_labels = []\n",
        "predicted_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 35ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 40ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "4/4 [==============================] - 0s 36ms/step\n"
          ]
        }
      ],
      "source": [
        "for _ in range(len(test_generator)):\n",
        "    X, y = next(test_generator)\n",
        "\n",
        "    yhat = modelPreTMob.predict(X)\n",
        "    \n",
        "    y_true_batch = y # Labels\n",
        "    \n",
        "    # Convert probabilities to class labels using a threshold of 0.5\n",
        "    y_pred_batch = (yhat > 0.5).astype(int)\n",
        "\n",
        "    # Append the true labels and predictions for this batch to the lists\n",
        "    true_labels.extend(y_true_batch)\n",
        "    predicted_labels.extend(y_pred_batch)\n",
        "\n",
        "    if len(true_labels) >= test_generator.n:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2664,  336],\n",
              "       [ 337, 2663]], dtype=int64)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the confusion matrix\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm/cm_sum.astype(float), display_labels=['Ads', 'non-Ads'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8878146357726288"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "f1_score(true_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8879626542180727"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8876666666666667"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.887833\n"
          ]
        }
      ],
      "source": [
        "# ROC AUC\n",
        "auc = roc_auc_score(true_labels, predicted_labels)\n",
        "print('ROC AUC: %f' % auc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
