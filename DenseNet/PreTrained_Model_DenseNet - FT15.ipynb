{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DenseNet fine tuning 15\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this run for the MobileNet, we froze all layers and added two dense layers after the conv_base.\n",
        "\n",
        "Results>\n",
        "\n",
        "Best Epoch: 86 \n",
        "\n",
        "test acc: 0.89016\n",
        "\n",
        "test loss: 3.0893\n",
        "\n",
        "f1_score: 0.89664\n",
        "\n",
        "Precision: 0.87997\n",
        "\n",
        "Recall: 0.914\n",
        "\n",
        "ROC AUC: 0.89466\n",
        "\n",
        "---Training 100 Epochs:  seconds --- 20769 s\n",
        "---Inferense (6000 images):  seconds --- 21.59 s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9F-3tLoS-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install \"tensorflow<2.11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Q0sXDdr-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ze2HI0C1-6Jk"
      },
      "outputs": [],
      "source": [
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eHaZm8sS-6Jk"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip list\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VTJsjK8k-6Jl"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pc4Ak-MX-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9qmltHoh-6Jl"
      },
      "outputs": [],
      "source": [
        "# add headings with ##(space) on the markdowns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oefqb7pK-6Jl"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflor keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9_5zqcvh-6Jl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp9-KNO_XLJk",
        "outputId": "6744d109-58a8-4e55-860f-55eb54942aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jul 31 17:56:31 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1660 ...  WDDM  | 00000000:2D:00.0  On |                  N/A |\n",
            "|  0%   47C    P8              16W / 125W |    681MiB /  6144MiB |     32%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1644    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A      4640    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A      5860    C+G   ...soft Office\\root\\Office16\\EXCEL.EXE    N/A      |\n",
            "|    0   N/A  N/A      6600    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      8028    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A      8172    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     10264    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A     13432    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     14268    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     16152    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     17224    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     18028    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     19896    C+G   ...e Stream\\94.0.1.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A     20052    C+G   ...n\\126.0.2592.113\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     21260    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     22492    C+G   ...am Files\\CyberGhost 8\\Dashboard.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkjlmr5C-6Jl",
        "outputId": "ee4947bd-e593-4a95-d056-cd5c5a96edb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig6dym2M-6Jm",
        "outputId": "9fc23f8a-8818-4670-8a29-5ad344823bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3w44-mIA-6Jm"
      },
      "outputs": [],
      "source": [
        "#! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TuXlkzYf-6Jm"
      },
      "outputs": [],
      "source": [
        "#!pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3sJDXlu-6Jm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-2RGi19W-6Jm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NqDqKYkQ-6Jm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingConfig:\n",
        "    BATCH_SIZE:       int   = 64\n",
        "    EPOCHS:           int   = 100\n",
        "    LEARNING_RATE:    float = 0.001\n",
        "    DROPOUT:          float = 0.5\n",
        "    LAYERS_FINE_TUNE: int   = 16\n",
        "    EPSILON:          float = 1e-07\n",
        "    MOMENTUM:         float = 0.9   \n",
        "    WEIGHT_DECAY:     float = 0.0005 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ0UVyCQ-6Jq"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = r\"C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\READY_BALANCED_SAME_SIZE_Random_Split\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knV1jDUD-6Jq",
        "outputId": "50f1446d-6355-4acd-f509-c5440328e53e"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hf-N_1PI-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\train\\\\Ads'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Ads_dir = os.path.join(train_dir, 'Ads')\n",
        "train_sample_dir = os.path.join(train_dir, 'Sample')\n",
        "train_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4lk-PK-6Jq",
        "outputId": "d9fbbdec-e425-4bd2-af75-32f3fbb86936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\validation\\\\Ads'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_Ads_dir = os.path.join(validation_dir, 'Ads')\n",
        "validation_sample_dir = os.path.join(validation_dir, 'Sample')\n",
        "validation_Ads_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JwHehlf4-6Jq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\READY_BALANCED_SAME_SIZE_Random_Split\\\\test\\\\Ads'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Ads_dir = os.path.join(test_dir, 'Ads')\n",
        "test_sample_dir = os.path.join(test_dir, 'Sample')\n",
        "test_Ads_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fbi_AoAO-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training Ads images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training Ads images:', len(os.listdir(train_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h4bgQrIL-6Jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training sample images: 10500\n"
          ]
        }
      ],
      "source": [
        "print('total training sample images:', len(os.listdir(train_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YHrO9Y-6Jq",
        "outputId": "15bf628d-bf34-4ce7-ad11-fe568bf61432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation Ads images: 3650\n"
          ]
        }
      ],
      "source": [
        "print('total validation Ads images:', len(os.listdir(validation_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total validation sample images: 3950\n"
          ]
        }
      ],
      "source": [
        "print('total validation sample images:', len(os.listdir(validation_sample_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test Ads images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test Ads images:', len(os.listdir(test_Ads_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total test sample images: 3000\n"
          ]
        }
      ],
      "source": [
        "print('total test sample images:', len(os.listdir(test_sample_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using data augmentation/ datagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "from tensorflow.keras.utils import img_to_array, array_to_img,  load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for color augmentation\n",
        "def color_jitter(image):\n",
        "    image = ImageEnhance.Brightness(image).enhance(np.random.uniform(0.4, 1.6)) # from -60% to +60%\n",
        "    image = ImageEnhance.Contrast(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    image = ImageEnhance.Color(image).enhance(np.random.uniform(0.4, 1.6))\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom preprocessing function for ImageDataGenerator\n",
        "def custom_preprocessing_function(image):\n",
        "    # Convert array to PIL image\n",
        "    image = array_to_img(image)\n",
        "    # Apply color jitter\n",
        "    image = color_jitter(image)\n",
        "    # Convert PIL image back to array\n",
        "    image = img_to_array(image)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 images belonging to 2 classes.\n",
            "Found 7600 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "## with Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=custom_preprocessing_function)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretrained Model Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l38QgkUe-6Js"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4AL2-e8-6Js"
      },
      "source": [
        "# Appling a Pre-trained CNN on our Dataset for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcDjEV1-6Jt"
      },
      "source": [
        "The MobileNet model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OcyKdKno-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras.applications import DenseNet121\n",
        "\n",
        "conv_base = DenseNet121(weights='imagenet',\n",
        "                 include_top=False,\n",
        "                 input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRiAZIlI-6Jt",
        "outputId": "9254a8c6-9f28-4ea9-9b11-6553544bb4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVx8qd9U-6Jt"
      },
      "source": [
        "We will add a dense layer after our conv_base NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NwbCTdFB-6Jt"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, AveragePooling2D\n",
        "\n",
        "modelPreTMob = models.Sequential()\n",
        "modelPreTMob.add(conv_base)\n",
        "\n",
        "modelPreTMob.add(layers.AveragePooling2D())\n",
        "modelPreTMob.add(layers.Flatten())\n",
        "modelPreTMob.add(layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "modelPreTMob.add(BatchNormalization())\n",
        "modelPreTMob.add(layers.Dropout(TrainingConfig.DROPOUT))\n",
        "modelPreTMob.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULwwwLKQ-6Jt",
        "outputId": "bca81ce0-c589-438d-d7f7-ddc78c5df1fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 9,314,177\n",
            "Non-trainable params: 84,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 True\n",
            "1 zero_padding2d True\n",
            "2 conv1/conv True\n",
            "3 conv1/bn True\n",
            "4 conv1/relu True\n",
            "5 zero_padding2d_1 True\n",
            "6 pool1 True\n",
            "7 conv2_block1_0_bn True\n",
            "8 conv2_block1_0_relu True\n",
            "9 conv2_block1_1_conv True\n",
            "10 conv2_block1_1_bn True\n",
            "11 conv2_block1_1_relu True\n",
            "12 conv2_block1_2_conv True\n",
            "13 conv2_block1_concat True\n",
            "14 conv2_block2_0_bn True\n",
            "15 conv2_block2_0_relu True\n",
            "16 conv2_block2_1_conv True\n",
            "17 conv2_block2_1_bn True\n",
            "18 conv2_block2_1_relu True\n",
            "19 conv2_block2_2_conv True\n",
            "20 conv2_block2_concat True\n",
            "21 conv2_block3_0_bn True\n",
            "22 conv2_block3_0_relu True\n",
            "23 conv2_block3_1_conv True\n",
            "24 conv2_block3_1_bn True\n",
            "25 conv2_block3_1_relu True\n",
            "26 conv2_block3_2_conv True\n",
            "27 conv2_block3_concat True\n",
            "28 conv2_block4_0_bn True\n",
            "29 conv2_block4_0_relu True\n",
            "30 conv2_block4_1_conv True\n",
            "31 conv2_block4_1_bn True\n",
            "32 conv2_block4_1_relu True\n",
            "33 conv2_block4_2_conv True\n",
            "34 conv2_block4_concat True\n",
            "35 conv2_block5_0_bn True\n",
            "36 conv2_block5_0_relu True\n",
            "37 conv2_block5_1_conv True\n",
            "38 conv2_block5_1_bn True\n",
            "39 conv2_block5_1_relu True\n",
            "40 conv2_block5_2_conv True\n",
            "41 conv2_block5_concat True\n",
            "42 conv2_block6_0_bn True\n",
            "43 conv2_block6_0_relu True\n",
            "44 conv2_block6_1_conv True\n",
            "45 conv2_block6_1_bn True\n",
            "46 conv2_block6_1_relu True\n",
            "47 conv2_block6_2_conv True\n",
            "48 conv2_block6_concat True\n",
            "49 pool2_bn True\n",
            "50 pool2_relu True\n",
            "51 pool2_conv True\n",
            "52 pool2_pool True\n",
            "53 conv3_block1_0_bn True\n",
            "54 conv3_block1_0_relu True\n",
            "55 conv3_block1_1_conv True\n",
            "56 conv3_block1_1_bn True\n",
            "57 conv3_block1_1_relu True\n",
            "58 conv3_block1_2_conv True\n",
            "59 conv3_block1_concat True\n",
            "60 conv3_block2_0_bn True\n",
            "61 conv3_block2_0_relu True\n",
            "62 conv3_block2_1_conv True\n",
            "63 conv3_block2_1_bn True\n",
            "64 conv3_block2_1_relu True\n",
            "65 conv3_block2_2_conv True\n",
            "66 conv3_block2_concat True\n",
            "67 conv3_block3_0_bn True\n",
            "68 conv3_block3_0_relu True\n",
            "69 conv3_block3_1_conv True\n",
            "70 conv3_block3_1_bn True\n",
            "71 conv3_block3_1_relu True\n",
            "72 conv3_block3_2_conv True\n",
            "73 conv3_block3_concat True\n",
            "74 conv3_block4_0_bn True\n",
            "75 conv3_block4_0_relu True\n",
            "76 conv3_block4_1_conv True\n",
            "77 conv3_block4_1_bn True\n",
            "78 conv3_block4_1_relu True\n",
            "79 conv3_block4_2_conv True\n",
            "80 conv3_block4_concat True\n",
            "81 conv3_block5_0_bn True\n",
            "82 conv3_block5_0_relu True\n",
            "83 conv3_block5_1_conv True\n",
            "84 conv3_block5_1_bn True\n",
            "85 conv3_block5_1_relu True\n",
            "86 conv3_block5_2_conv True\n",
            "87 conv3_block5_concat True\n",
            "88 conv3_block6_0_bn True\n",
            "89 conv3_block6_0_relu True\n",
            "90 conv3_block6_1_conv True\n",
            "91 conv3_block6_1_bn True\n",
            "92 conv3_block6_1_relu True\n",
            "93 conv3_block6_2_conv True\n",
            "94 conv3_block6_concat True\n",
            "95 conv3_block7_0_bn True\n",
            "96 conv3_block7_0_relu True\n",
            "97 conv3_block7_1_conv True\n",
            "98 conv3_block7_1_bn True\n",
            "99 conv3_block7_1_relu True\n",
            "100 conv3_block7_2_conv True\n",
            "101 conv3_block7_concat True\n",
            "102 conv3_block8_0_bn True\n",
            "103 conv3_block8_0_relu True\n",
            "104 conv3_block8_1_conv True\n",
            "105 conv3_block8_1_bn True\n",
            "106 conv3_block8_1_relu True\n",
            "107 conv3_block8_2_conv True\n",
            "108 conv3_block8_concat True\n",
            "109 conv3_block9_0_bn True\n",
            "110 conv3_block9_0_relu True\n",
            "111 conv3_block9_1_conv True\n",
            "112 conv3_block9_1_bn True\n",
            "113 conv3_block9_1_relu True\n",
            "114 conv3_block9_2_conv True\n",
            "115 conv3_block9_concat True\n",
            "116 conv3_block10_0_bn True\n",
            "117 conv3_block10_0_relu True\n",
            "118 conv3_block10_1_conv True\n",
            "119 conv3_block10_1_bn True\n",
            "120 conv3_block10_1_relu True\n",
            "121 conv3_block10_2_conv True\n",
            "122 conv3_block10_concat True\n",
            "123 conv3_block11_0_bn True\n",
            "124 conv3_block11_0_relu True\n",
            "125 conv3_block11_1_conv True\n",
            "126 conv3_block11_1_bn True\n",
            "127 conv3_block11_1_relu True\n",
            "128 conv3_block11_2_conv True\n",
            "129 conv3_block11_concat True\n",
            "130 conv3_block12_0_bn True\n",
            "131 conv3_block12_0_relu True\n",
            "132 conv3_block12_1_conv True\n",
            "133 conv3_block12_1_bn True\n",
            "134 conv3_block12_1_relu True\n",
            "135 conv3_block12_2_conv True\n",
            "136 conv3_block12_concat True\n",
            "137 pool3_bn True\n",
            "138 pool3_relu True\n",
            "139 pool3_conv True\n",
            "140 pool3_pool True\n",
            "141 conv4_block1_0_bn True\n",
            "142 conv4_block1_0_relu True\n",
            "143 conv4_block1_1_conv True\n",
            "144 conv4_block1_1_bn True\n",
            "145 conv4_block1_1_relu True\n",
            "146 conv4_block1_2_conv True\n",
            "147 conv4_block1_concat True\n",
            "148 conv4_block2_0_bn True\n",
            "149 conv4_block2_0_relu True\n",
            "150 conv4_block2_1_conv True\n",
            "151 conv4_block2_1_bn True\n",
            "152 conv4_block2_1_relu True\n",
            "153 conv4_block2_2_conv True\n",
            "154 conv4_block2_concat True\n",
            "155 conv4_block3_0_bn True\n",
            "156 conv4_block3_0_relu True\n",
            "157 conv4_block3_1_conv True\n",
            "158 conv4_block3_1_bn True\n",
            "159 conv4_block3_1_relu True\n",
            "160 conv4_block3_2_conv True\n",
            "161 conv4_block3_concat True\n",
            "162 conv4_block4_0_bn True\n",
            "163 conv4_block4_0_relu True\n",
            "164 conv4_block4_1_conv True\n",
            "165 conv4_block4_1_bn True\n",
            "166 conv4_block4_1_relu True\n",
            "167 conv4_block4_2_conv True\n",
            "168 conv4_block4_concat True\n",
            "169 conv4_block5_0_bn True\n",
            "170 conv4_block5_0_relu True\n",
            "171 conv4_block5_1_conv True\n",
            "172 conv4_block5_1_bn True\n",
            "173 conv4_block5_1_relu True\n",
            "174 conv4_block5_2_conv True\n",
            "175 conv4_block5_concat True\n",
            "176 conv4_block6_0_bn True\n",
            "177 conv4_block6_0_relu True\n",
            "178 conv4_block6_1_conv True\n",
            "179 conv4_block6_1_bn True\n",
            "180 conv4_block6_1_relu True\n",
            "181 conv4_block6_2_conv True\n",
            "182 conv4_block6_concat True\n",
            "183 conv4_block7_0_bn True\n",
            "184 conv4_block7_0_relu True\n",
            "185 conv4_block7_1_conv True\n",
            "186 conv4_block7_1_bn True\n",
            "187 conv4_block7_1_relu True\n",
            "188 conv4_block7_2_conv True\n",
            "189 conv4_block7_concat True\n",
            "190 conv4_block8_0_bn True\n",
            "191 conv4_block8_0_relu True\n",
            "192 conv4_block8_1_conv True\n",
            "193 conv4_block8_1_bn True\n",
            "194 conv4_block8_1_relu True\n",
            "195 conv4_block8_2_conv True\n",
            "196 conv4_block8_concat True\n",
            "197 conv4_block9_0_bn True\n",
            "198 conv4_block9_0_relu True\n",
            "199 conv4_block9_1_conv True\n",
            "200 conv4_block9_1_bn True\n",
            "201 conv4_block9_1_relu True\n",
            "202 conv4_block9_2_conv True\n",
            "203 conv4_block9_concat True\n",
            "204 conv4_block10_0_bn True\n",
            "205 conv4_block10_0_relu True\n",
            "206 conv4_block10_1_conv True\n",
            "207 conv4_block10_1_bn True\n",
            "208 conv4_block10_1_relu True\n",
            "209 conv4_block10_2_conv True\n",
            "210 conv4_block10_concat True\n",
            "211 conv4_block11_0_bn True\n",
            "212 conv4_block11_0_relu True\n",
            "213 conv4_block11_1_conv True\n",
            "214 conv4_block11_1_bn True\n",
            "215 conv4_block11_1_relu True\n",
            "216 conv4_block11_2_conv True\n",
            "217 conv4_block11_concat True\n",
            "218 conv4_block12_0_bn True\n",
            "219 conv4_block12_0_relu True\n",
            "220 conv4_block12_1_conv True\n",
            "221 conv4_block12_1_bn True\n",
            "222 conv4_block12_1_relu True\n",
            "223 conv4_block12_2_conv True\n",
            "224 conv4_block12_concat True\n",
            "225 conv4_block13_0_bn True\n",
            "226 conv4_block13_0_relu True\n",
            "227 conv4_block13_1_conv True\n",
            "228 conv4_block13_1_bn True\n",
            "229 conv4_block13_1_relu True\n",
            "230 conv4_block13_2_conv True\n",
            "231 conv4_block13_concat True\n",
            "232 conv4_block14_0_bn True\n",
            "233 conv4_block14_0_relu True\n",
            "234 conv4_block14_1_conv True\n",
            "235 conv4_block14_1_bn True\n",
            "236 conv4_block14_1_relu True\n",
            "237 conv4_block14_2_conv True\n",
            "238 conv4_block14_concat True\n",
            "239 conv4_block15_0_bn True\n",
            "240 conv4_block15_0_relu True\n",
            "241 conv4_block15_1_conv True\n",
            "242 conv4_block15_1_bn True\n",
            "243 conv4_block15_1_relu True\n",
            "244 conv4_block15_2_conv True\n",
            "245 conv4_block15_concat True\n",
            "246 conv4_block16_0_bn True\n",
            "247 conv4_block16_0_relu True\n",
            "248 conv4_block16_1_conv True\n",
            "249 conv4_block16_1_bn True\n",
            "250 conv4_block16_1_relu True\n",
            "251 conv4_block16_2_conv True\n",
            "252 conv4_block16_concat True\n",
            "253 conv4_block17_0_bn True\n",
            "254 conv4_block17_0_relu True\n",
            "255 conv4_block17_1_conv True\n",
            "256 conv4_block17_1_bn True\n",
            "257 conv4_block17_1_relu True\n",
            "258 conv4_block17_2_conv True\n",
            "259 conv4_block17_concat True\n",
            "260 conv4_block18_0_bn True\n",
            "261 conv4_block18_0_relu True\n",
            "262 conv4_block18_1_conv True\n",
            "263 conv4_block18_1_bn True\n",
            "264 conv4_block18_1_relu True\n",
            "265 conv4_block18_2_conv True\n",
            "266 conv4_block18_concat True\n",
            "267 conv4_block19_0_bn True\n",
            "268 conv4_block19_0_relu True\n",
            "269 conv4_block19_1_conv True\n",
            "270 conv4_block19_1_bn True\n",
            "271 conv4_block19_1_relu True\n",
            "272 conv4_block19_2_conv True\n",
            "273 conv4_block19_concat True\n",
            "274 conv4_block20_0_bn True\n",
            "275 conv4_block20_0_relu True\n",
            "276 conv4_block20_1_conv True\n",
            "277 conv4_block20_1_bn True\n",
            "278 conv4_block20_1_relu True\n",
            "279 conv4_block20_2_conv True\n",
            "280 conv4_block20_concat True\n",
            "281 conv4_block21_0_bn True\n",
            "282 conv4_block21_0_relu True\n",
            "283 conv4_block21_1_conv True\n",
            "284 conv4_block21_1_bn True\n",
            "285 conv4_block21_1_relu True\n",
            "286 conv4_block21_2_conv True\n",
            "287 conv4_block21_concat True\n",
            "288 conv4_block22_0_bn True\n",
            "289 conv4_block22_0_relu True\n",
            "290 conv4_block22_1_conv True\n",
            "291 conv4_block22_1_bn True\n",
            "292 conv4_block22_1_relu True\n",
            "293 conv4_block22_2_conv True\n",
            "294 conv4_block22_concat True\n",
            "295 conv4_block23_0_bn True\n",
            "296 conv4_block23_0_relu True\n",
            "297 conv4_block23_1_conv True\n",
            "298 conv4_block23_1_bn True\n",
            "299 conv4_block23_1_relu True\n",
            "300 conv4_block23_2_conv True\n",
            "301 conv4_block23_concat True\n",
            "302 conv4_block24_0_bn True\n",
            "303 conv4_block24_0_relu True\n",
            "304 conv4_block24_1_conv True\n",
            "305 conv4_block24_1_bn True\n",
            "306 conv4_block24_1_relu True\n",
            "307 conv4_block24_2_conv True\n",
            "308 conv4_block24_concat True\n",
            "309 pool4_bn True\n",
            "310 pool4_relu True\n",
            "311 pool4_conv True\n",
            "312 pool4_pool True\n",
            "313 conv5_block1_0_bn True\n",
            "314 conv5_block1_0_relu True\n",
            "315 conv5_block1_1_conv True\n",
            "316 conv5_block1_1_bn True\n",
            "317 conv5_block1_1_relu True\n",
            "318 conv5_block1_2_conv True\n",
            "319 conv5_block1_concat True\n",
            "320 conv5_block2_0_bn True\n",
            "321 conv5_block2_0_relu True\n",
            "322 conv5_block2_1_conv True\n",
            "323 conv5_block2_1_bn True\n",
            "324 conv5_block2_1_relu True\n",
            "325 conv5_block2_2_conv True\n",
            "326 conv5_block2_concat True\n",
            "327 conv5_block3_0_bn True\n",
            "328 conv5_block3_0_relu True\n",
            "329 conv5_block3_1_conv True\n",
            "330 conv5_block3_1_bn True\n",
            "331 conv5_block3_1_relu True\n",
            "332 conv5_block3_2_conv True\n",
            "333 conv5_block3_concat True\n",
            "334 conv5_block4_0_bn True\n",
            "335 conv5_block4_0_relu True\n",
            "336 conv5_block4_1_conv True\n",
            "337 conv5_block4_1_bn True\n",
            "338 conv5_block4_1_relu True\n",
            "339 conv5_block4_2_conv True\n",
            "340 conv5_block4_concat True\n",
            "341 conv5_block5_0_bn True\n",
            "342 conv5_block5_0_relu True\n",
            "343 conv5_block5_1_conv True\n",
            "344 conv5_block5_1_bn True\n",
            "345 conv5_block5_1_relu True\n",
            "346 conv5_block5_2_conv True\n",
            "347 conv5_block5_concat True\n",
            "348 conv5_block6_0_bn True\n",
            "349 conv5_block6_0_relu True\n",
            "350 conv5_block6_1_conv True\n",
            "351 conv5_block6_1_bn True\n",
            "352 conv5_block6_1_relu True\n",
            "353 conv5_block6_2_conv True\n",
            "354 conv5_block6_concat True\n",
            "355 conv5_block7_0_bn True\n",
            "356 conv5_block7_0_relu True\n",
            "357 conv5_block7_1_conv True\n",
            "358 conv5_block7_1_bn True\n",
            "359 conv5_block7_1_relu True\n",
            "360 conv5_block7_2_conv True\n",
            "361 conv5_block7_concat True\n",
            "362 conv5_block8_0_bn True\n",
            "363 conv5_block8_0_relu True\n",
            "364 conv5_block8_1_conv True\n",
            "365 conv5_block8_1_bn True\n",
            "366 conv5_block8_1_relu True\n",
            "367 conv5_block8_2_conv True\n",
            "368 conv5_block8_concat True\n",
            "369 conv5_block9_0_bn True\n",
            "370 conv5_block9_0_relu True\n",
            "371 conv5_block9_1_conv True\n",
            "372 conv5_block9_1_bn True\n",
            "373 conv5_block9_1_relu True\n",
            "374 conv5_block9_2_conv True\n",
            "375 conv5_block9_concat True\n",
            "376 conv5_block10_0_bn True\n",
            "377 conv5_block10_0_relu True\n",
            "378 conv5_block10_1_conv True\n",
            "379 conv5_block10_1_bn True\n",
            "380 conv5_block10_1_relu True\n",
            "381 conv5_block10_2_conv True\n",
            "382 conv5_block10_concat True\n",
            "383 conv5_block11_0_bn True\n",
            "384 conv5_block11_0_relu True\n",
            "385 conv5_block11_1_conv True\n",
            "386 conv5_block11_1_bn True\n",
            "387 conv5_block11_1_relu True\n",
            "388 conv5_block11_2_conv True\n",
            "389 conv5_block11_concat True\n",
            "390 conv5_block12_0_bn True\n",
            "391 conv5_block12_0_relu True\n",
            "392 conv5_block12_1_conv True\n",
            "393 conv5_block12_1_bn True\n",
            "394 conv5_block12_1_relu True\n",
            "395 conv5_block12_2_conv True\n",
            "396 conv5_block12_concat True\n",
            "397 conv5_block13_0_bn True\n",
            "398 conv5_block13_0_relu True\n",
            "399 conv5_block13_1_conv True\n",
            "400 conv5_block13_1_bn True\n",
            "401 conv5_block13_1_relu True\n",
            "402 conv5_block13_2_conv True\n",
            "403 conv5_block13_concat True\n",
            "404 conv5_block14_0_bn True\n",
            "405 conv5_block14_0_relu True\n",
            "406 conv5_block14_1_conv True\n",
            "407 conv5_block14_1_bn True\n",
            "408 conv5_block14_1_relu True\n",
            "409 conv5_block14_2_conv True\n",
            "410 conv5_block14_concat True\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the number of layers to fine tune at the end of the convolutional base.\n",
        "num_layers_fine_tune = TrainingConfig.LAYERS_FINE_TUNE\n",
        "num_layers = len(conv_base.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg5O_dq-6Jt",
        "outputId": "0b8e8703-9f13-4415-d6a7-fc5af46bc1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 368\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'before freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FREEZING LAYER: <keras.engine.input_layer.InputLayer object at 0x0000016A61404F70>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x0000016A0BDBF9D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A614102B0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A61418310>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A61410C10>\n",
            "FREEZING LAYER: <keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x0000016A6141E130>\n",
            "FREEZING LAYER: <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000016A614236D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A614232E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A61423160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A6142BD00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7703F790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A6142B100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A77042C70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A77050760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A77050D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770459A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A7705A520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7705AF10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7705A370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A7705D8B0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A7706A610>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7706AD60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A77067D60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A77072760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A77077460>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A77072730>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A77067880>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A7705D130>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A77080F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7707EEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A77089940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7708ECA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A77089160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A77080400>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A7707EC10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7709B520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A77098EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770A29D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770A7E80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770A7190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A7709B550>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A77089280>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770B21F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770AFFD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770BABB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770C0E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770C0370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770B27F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A770773D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7706A940>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A77089250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A77050160>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x0000016A770C4E50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770505E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A61423B80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770C6B50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A77060E50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7706A5E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A6142BDC0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A770D0E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770D0AC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770D0400>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770D4E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770D8820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770D4280>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770DDEB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A770D04C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770E5670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770DDA60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770EAD60>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770EF880>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770EFD00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770F5340>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A770FEA60>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770FEFD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770F5370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9700A3A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9700DE20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9700DD00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97006610>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A970197C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97019D90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97016A30>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97022580>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97027130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97022040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970190D0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A97033640>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97033D90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97033C10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970196A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770FECD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770DD730>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770D4190>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A6142BBE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770C62E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7707E160>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9703C220>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9703CE50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7706A760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9703E460>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A97040340>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970409A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7706A820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9704A4F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9704FF70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9704AFA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97044F40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A9705C910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9705CE50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97059BE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970626D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970683A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9704A2E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9705C250>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A97072760>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97072EB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97070EB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9707C850>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97081CA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9707C190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97072310>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A97070070>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9708C460>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9708BFD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97094940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9709A3A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97094250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9708C1F0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A9709EB20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9709E3A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970A4340>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97072AC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770C6520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9707C6A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9708CB80>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A97027400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970AFAF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970AFA90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970A77F0>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x0000016A970B40D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970A7670>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970B4070>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970B6A00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970B9CA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970B62B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970A75B0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A970A7730>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970C4820>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970C48B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970CCCA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970D14F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970CC070>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970C4550>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A970DB6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970DB5B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970DB490>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970E3E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970E86D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A58F50820>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970DB550>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A58F67670>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970F2F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A61418D60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970FE310>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970EDE20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970F2F40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970F2D00>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD10190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD102B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970EDF70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD16370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD1EEE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD1EEB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD166A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A970ED7C0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970E3040>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970D64F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970B9E20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97068EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970E3F10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A9708CA90>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A970C4F10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD10EB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A970C4D00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970B6040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970BF430>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD16790>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD2CAC0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD2C9D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD37DF0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD2CD60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD2FA90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD46C10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD2FDC0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD46E50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD04370>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD4DEB0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD3EE80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD55040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD2A910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD37940>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD5DF70>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD4D400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD619D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD55FD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD71160>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD46190>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD61FA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD71700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD5DEE0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD81220>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD71340>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD716A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD90F40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD81A60>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD88220>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD55CD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD46A30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD900D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD71580>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970B4460>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD553D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A970DBFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A970E8BB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD98D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD783D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD98490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD88F40>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD3EC40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD98850>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9AD9CAC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD2A9D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD9CE50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADAF0A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADB5CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADB5CA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADB5F10>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9ADA6C40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD2C1F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADAFF70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADC60D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD2CB20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADB8F10>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADC6700>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9ADB5AC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADAF760>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADB81F0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADDC3A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADE6EE0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADD6040>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADC6100>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9ADC6F70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADCD880>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADD6370>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADC6FA0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADFE160>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADEFBB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADEFFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9ADC6EB0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADB5D30>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADFE310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADE6D30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADEFAC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADC6460>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9AD4DC40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9ADA6DC0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B207D60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADF66D0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B20B040>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD9C5E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADB5430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B20DEB0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B207490>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B211F10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B20BEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B21D070>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD98FA0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B211EE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B223FD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B211520>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B20D550>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B21D250>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B235190>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B20D520>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B22F430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B223670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B223F40>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B21DDC0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B22F310>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B223340>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B255130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B246B50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B23E6A0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B261400>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B261610>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B255100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2357F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B26E9D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B26E190>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B264CD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B235F10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B22FF70>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B26E430>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2550A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADAF400>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2355B0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9ADB5610>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B211C10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9ADCD790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B20DBB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B27D040>\n",
            "FREEZING LAYER: <keras.layers.pooling.average_pooling2d.AveragePooling2D object at 0x0000016B9B27BD00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970941F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2649A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B27D6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B207CD0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B207DF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B287A00>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B207820>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B293A60>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9ADCDB50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B293B50>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B29C8E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B20BE50>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B29CBE0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B29C7F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2AE250>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B29CB80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2AEB20>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2B62E0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B29FD90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2AEC40>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B2B6910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2C7100>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2B6CA0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B29F6D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2CFB50>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2B6D00>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2CF460>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B2D8910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2D8130>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2CFDF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2CF1F0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B293910>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B293760>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B287040>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B2BA940>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9AD2A310>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2C7C40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B28B280>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2C79D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9AD78790>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2E6A30>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B2C7A30>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2EF9D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2D8BB0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B223C70>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2E67C0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B235220>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2EDB50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B2EF9A0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B303790>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2F4AF0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B303610>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B28B5B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B2F4850>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B30BCD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B30B880>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B31C370>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B30BC70>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B2EDC10>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B303E20>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B303400>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B325CA0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B325A00>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B3330D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B325D90>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B32AA90>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B345C10>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B32AEE0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B345E50>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016B9B34C9D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B34C1F0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016B9B3450A0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016B9B3339D0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016B9B2FB8B0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A0BDBFE80>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A7707E670>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A770AF550>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A77067B80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7707ECD0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A7705A430>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A770673D0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A7705A2E0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A7706AFD0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A770E55B0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A7706AA90>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A770EF7C0>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770D02E0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A9700AB80>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9700A100>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A770725B0>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A9703C910>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A970169A0>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A97016C40>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97062FD0>\n",
            "FREEZING LAYER: <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000016A97062310>\n",
            "FREEZING LAYER: <keras.layers.core.activation.Activation object at 0x0000016A9704F610>\n",
            "FREEZING LAYER: <keras.layers.convolutional.conv2d.Conv2D object at 0x0000016A97044430>\n",
            "FREEZING LAYER: <keras.layers.merging.concatenate.Concatenate object at 0x0000016A97044700>\n"
          ]
        }
      ],
      "source": [
        "# Freeze the initial layers in the convolutional base.\n",
        "for model_layer in conv_base.layers[:num_layers - num_layers_fine_tune]:\n",
        "    print(f\"FREEZING LAYER: {model_layer}\")\n",
        "    model_layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 False\n",
            "1 zero_padding2d False\n",
            "2 conv1/conv False\n",
            "3 conv1/bn False\n",
            "4 conv1/relu False\n",
            "5 zero_padding2d_1 False\n",
            "6 pool1 False\n",
            "7 conv2_block1_0_bn False\n",
            "8 conv2_block1_0_relu False\n",
            "9 conv2_block1_1_conv False\n",
            "10 conv2_block1_1_bn False\n",
            "11 conv2_block1_1_relu False\n",
            "12 conv2_block1_2_conv False\n",
            "13 conv2_block1_concat False\n",
            "14 conv2_block2_0_bn False\n",
            "15 conv2_block2_0_relu False\n",
            "16 conv2_block2_1_conv False\n",
            "17 conv2_block2_1_bn False\n",
            "18 conv2_block2_1_relu False\n",
            "19 conv2_block2_2_conv False\n",
            "20 conv2_block2_concat False\n",
            "21 conv2_block3_0_bn False\n",
            "22 conv2_block3_0_relu False\n",
            "23 conv2_block3_1_conv False\n",
            "24 conv2_block3_1_bn False\n",
            "25 conv2_block3_1_relu False\n",
            "26 conv2_block3_2_conv False\n",
            "27 conv2_block3_concat False\n",
            "28 conv2_block4_0_bn False\n",
            "29 conv2_block4_0_relu False\n",
            "30 conv2_block4_1_conv False\n",
            "31 conv2_block4_1_bn False\n",
            "32 conv2_block4_1_relu False\n",
            "33 conv2_block4_2_conv False\n",
            "34 conv2_block4_concat False\n",
            "35 conv2_block5_0_bn False\n",
            "36 conv2_block5_0_relu False\n",
            "37 conv2_block5_1_conv False\n",
            "38 conv2_block5_1_bn False\n",
            "39 conv2_block5_1_relu False\n",
            "40 conv2_block5_2_conv False\n",
            "41 conv2_block5_concat False\n",
            "42 conv2_block6_0_bn False\n",
            "43 conv2_block6_0_relu False\n",
            "44 conv2_block6_1_conv False\n",
            "45 conv2_block6_1_bn False\n",
            "46 conv2_block6_1_relu False\n",
            "47 conv2_block6_2_conv False\n",
            "48 conv2_block6_concat False\n",
            "49 pool2_bn False\n",
            "50 pool2_relu False\n",
            "51 pool2_conv False\n",
            "52 pool2_pool False\n",
            "53 conv3_block1_0_bn False\n",
            "54 conv3_block1_0_relu False\n",
            "55 conv3_block1_1_conv False\n",
            "56 conv3_block1_1_bn False\n",
            "57 conv3_block1_1_relu False\n",
            "58 conv3_block1_2_conv False\n",
            "59 conv3_block1_concat False\n",
            "60 conv3_block2_0_bn False\n",
            "61 conv3_block2_0_relu False\n",
            "62 conv3_block2_1_conv False\n",
            "63 conv3_block2_1_bn False\n",
            "64 conv3_block2_1_relu False\n",
            "65 conv3_block2_2_conv False\n",
            "66 conv3_block2_concat False\n",
            "67 conv3_block3_0_bn False\n",
            "68 conv3_block3_0_relu False\n",
            "69 conv3_block3_1_conv False\n",
            "70 conv3_block3_1_bn False\n",
            "71 conv3_block3_1_relu False\n",
            "72 conv3_block3_2_conv False\n",
            "73 conv3_block3_concat False\n",
            "74 conv3_block4_0_bn False\n",
            "75 conv3_block4_0_relu False\n",
            "76 conv3_block4_1_conv False\n",
            "77 conv3_block4_1_bn False\n",
            "78 conv3_block4_1_relu False\n",
            "79 conv3_block4_2_conv False\n",
            "80 conv3_block4_concat False\n",
            "81 conv3_block5_0_bn False\n",
            "82 conv3_block5_0_relu False\n",
            "83 conv3_block5_1_conv False\n",
            "84 conv3_block5_1_bn False\n",
            "85 conv3_block5_1_relu False\n",
            "86 conv3_block5_2_conv False\n",
            "87 conv3_block5_concat False\n",
            "88 conv3_block6_0_bn False\n",
            "89 conv3_block6_0_relu False\n",
            "90 conv3_block6_1_conv False\n",
            "91 conv3_block6_1_bn False\n",
            "92 conv3_block6_1_relu False\n",
            "93 conv3_block6_2_conv False\n",
            "94 conv3_block6_concat False\n",
            "95 conv3_block7_0_bn False\n",
            "96 conv3_block7_0_relu False\n",
            "97 conv3_block7_1_conv False\n",
            "98 conv3_block7_1_bn False\n",
            "99 conv3_block7_1_relu False\n",
            "100 conv3_block7_2_conv False\n",
            "101 conv3_block7_concat False\n",
            "102 conv3_block8_0_bn False\n",
            "103 conv3_block8_0_relu False\n",
            "104 conv3_block8_1_conv False\n",
            "105 conv3_block8_1_bn False\n",
            "106 conv3_block8_1_relu False\n",
            "107 conv3_block8_2_conv False\n",
            "108 conv3_block8_concat False\n",
            "109 conv3_block9_0_bn False\n",
            "110 conv3_block9_0_relu False\n",
            "111 conv3_block9_1_conv False\n",
            "112 conv3_block9_1_bn False\n",
            "113 conv3_block9_1_relu False\n",
            "114 conv3_block9_2_conv False\n",
            "115 conv3_block9_concat False\n",
            "116 conv3_block10_0_bn False\n",
            "117 conv3_block10_0_relu False\n",
            "118 conv3_block10_1_conv False\n",
            "119 conv3_block10_1_bn False\n",
            "120 conv3_block10_1_relu False\n",
            "121 conv3_block10_2_conv False\n",
            "122 conv3_block10_concat False\n",
            "123 conv3_block11_0_bn False\n",
            "124 conv3_block11_0_relu False\n",
            "125 conv3_block11_1_conv False\n",
            "126 conv3_block11_1_bn False\n",
            "127 conv3_block11_1_relu False\n",
            "128 conv3_block11_2_conv False\n",
            "129 conv3_block11_concat False\n",
            "130 conv3_block12_0_bn False\n",
            "131 conv3_block12_0_relu False\n",
            "132 conv3_block12_1_conv False\n",
            "133 conv3_block12_1_bn False\n",
            "134 conv3_block12_1_relu False\n",
            "135 conv3_block12_2_conv False\n",
            "136 conv3_block12_concat False\n",
            "137 pool3_bn False\n",
            "138 pool3_relu False\n",
            "139 pool3_conv False\n",
            "140 pool3_pool False\n",
            "141 conv4_block1_0_bn False\n",
            "142 conv4_block1_0_relu False\n",
            "143 conv4_block1_1_conv False\n",
            "144 conv4_block1_1_bn False\n",
            "145 conv4_block1_1_relu False\n",
            "146 conv4_block1_2_conv False\n",
            "147 conv4_block1_concat False\n",
            "148 conv4_block2_0_bn False\n",
            "149 conv4_block2_0_relu False\n",
            "150 conv4_block2_1_conv False\n",
            "151 conv4_block2_1_bn False\n",
            "152 conv4_block2_1_relu False\n",
            "153 conv4_block2_2_conv False\n",
            "154 conv4_block2_concat False\n",
            "155 conv4_block3_0_bn False\n",
            "156 conv4_block3_0_relu False\n",
            "157 conv4_block3_1_conv False\n",
            "158 conv4_block3_1_bn False\n",
            "159 conv4_block3_1_relu False\n",
            "160 conv4_block3_2_conv False\n",
            "161 conv4_block3_concat False\n",
            "162 conv4_block4_0_bn False\n",
            "163 conv4_block4_0_relu False\n",
            "164 conv4_block4_1_conv False\n",
            "165 conv4_block4_1_bn False\n",
            "166 conv4_block4_1_relu False\n",
            "167 conv4_block4_2_conv False\n",
            "168 conv4_block4_concat False\n",
            "169 conv4_block5_0_bn False\n",
            "170 conv4_block5_0_relu False\n",
            "171 conv4_block5_1_conv False\n",
            "172 conv4_block5_1_bn False\n",
            "173 conv4_block5_1_relu False\n",
            "174 conv4_block5_2_conv False\n",
            "175 conv4_block5_concat False\n",
            "176 conv4_block6_0_bn False\n",
            "177 conv4_block6_0_relu False\n",
            "178 conv4_block6_1_conv False\n",
            "179 conv4_block6_1_bn False\n",
            "180 conv4_block6_1_relu False\n",
            "181 conv4_block6_2_conv False\n",
            "182 conv4_block6_concat False\n",
            "183 conv4_block7_0_bn False\n",
            "184 conv4_block7_0_relu False\n",
            "185 conv4_block7_1_conv False\n",
            "186 conv4_block7_1_bn False\n",
            "187 conv4_block7_1_relu False\n",
            "188 conv4_block7_2_conv False\n",
            "189 conv4_block7_concat False\n",
            "190 conv4_block8_0_bn False\n",
            "191 conv4_block8_0_relu False\n",
            "192 conv4_block8_1_conv False\n",
            "193 conv4_block8_1_bn False\n",
            "194 conv4_block8_1_relu False\n",
            "195 conv4_block8_2_conv False\n",
            "196 conv4_block8_concat False\n",
            "197 conv4_block9_0_bn False\n",
            "198 conv4_block9_0_relu False\n",
            "199 conv4_block9_1_conv False\n",
            "200 conv4_block9_1_bn False\n",
            "201 conv4_block9_1_relu False\n",
            "202 conv4_block9_2_conv False\n",
            "203 conv4_block9_concat False\n",
            "204 conv4_block10_0_bn False\n",
            "205 conv4_block10_0_relu False\n",
            "206 conv4_block10_1_conv False\n",
            "207 conv4_block10_1_bn False\n",
            "208 conv4_block10_1_relu False\n",
            "209 conv4_block10_2_conv False\n",
            "210 conv4_block10_concat False\n",
            "211 conv4_block11_0_bn False\n",
            "212 conv4_block11_0_relu False\n",
            "213 conv4_block11_1_conv False\n",
            "214 conv4_block11_1_bn False\n",
            "215 conv4_block11_1_relu False\n",
            "216 conv4_block11_2_conv False\n",
            "217 conv4_block11_concat False\n",
            "218 conv4_block12_0_bn False\n",
            "219 conv4_block12_0_relu False\n",
            "220 conv4_block12_1_conv False\n",
            "221 conv4_block12_1_bn False\n",
            "222 conv4_block12_1_relu False\n",
            "223 conv4_block12_2_conv False\n",
            "224 conv4_block12_concat False\n",
            "225 conv4_block13_0_bn False\n",
            "226 conv4_block13_0_relu False\n",
            "227 conv4_block13_1_conv False\n",
            "228 conv4_block13_1_bn False\n",
            "229 conv4_block13_1_relu False\n",
            "230 conv4_block13_2_conv False\n",
            "231 conv4_block13_concat False\n",
            "232 conv4_block14_0_bn False\n",
            "233 conv4_block14_0_relu False\n",
            "234 conv4_block14_1_conv False\n",
            "235 conv4_block14_1_bn False\n",
            "236 conv4_block14_1_relu False\n",
            "237 conv4_block14_2_conv False\n",
            "238 conv4_block14_concat False\n",
            "239 conv4_block15_0_bn False\n",
            "240 conv4_block15_0_relu False\n",
            "241 conv4_block15_1_conv False\n",
            "242 conv4_block15_1_bn False\n",
            "243 conv4_block15_1_relu False\n",
            "244 conv4_block15_2_conv False\n",
            "245 conv4_block15_concat False\n",
            "246 conv4_block16_0_bn False\n",
            "247 conv4_block16_0_relu False\n",
            "248 conv4_block16_1_conv False\n",
            "249 conv4_block16_1_bn False\n",
            "250 conv4_block16_1_relu False\n",
            "251 conv4_block16_2_conv False\n",
            "252 conv4_block16_concat False\n",
            "253 conv4_block17_0_bn False\n",
            "254 conv4_block17_0_relu False\n",
            "255 conv4_block17_1_conv False\n",
            "256 conv4_block17_1_bn False\n",
            "257 conv4_block17_1_relu False\n",
            "258 conv4_block17_2_conv False\n",
            "259 conv4_block17_concat False\n",
            "260 conv4_block18_0_bn False\n",
            "261 conv4_block18_0_relu False\n",
            "262 conv4_block18_1_conv False\n",
            "263 conv4_block18_1_bn False\n",
            "264 conv4_block18_1_relu False\n",
            "265 conv4_block18_2_conv False\n",
            "266 conv4_block18_concat False\n",
            "267 conv4_block19_0_bn False\n",
            "268 conv4_block19_0_relu False\n",
            "269 conv4_block19_1_conv False\n",
            "270 conv4_block19_1_bn False\n",
            "271 conv4_block19_1_relu False\n",
            "272 conv4_block19_2_conv False\n",
            "273 conv4_block19_concat False\n",
            "274 conv4_block20_0_bn False\n",
            "275 conv4_block20_0_relu False\n",
            "276 conv4_block20_1_conv False\n",
            "277 conv4_block20_1_bn False\n",
            "278 conv4_block20_1_relu False\n",
            "279 conv4_block20_2_conv False\n",
            "280 conv4_block20_concat False\n",
            "281 conv4_block21_0_bn False\n",
            "282 conv4_block21_0_relu False\n",
            "283 conv4_block21_1_conv False\n",
            "284 conv4_block21_1_bn False\n",
            "285 conv4_block21_1_relu False\n",
            "286 conv4_block21_2_conv False\n",
            "287 conv4_block21_concat False\n",
            "288 conv4_block22_0_bn False\n",
            "289 conv4_block22_0_relu False\n",
            "290 conv4_block22_1_conv False\n",
            "291 conv4_block22_1_bn False\n",
            "292 conv4_block22_1_relu False\n",
            "293 conv4_block22_2_conv False\n",
            "294 conv4_block22_concat False\n",
            "295 conv4_block23_0_bn False\n",
            "296 conv4_block23_0_relu False\n",
            "297 conv4_block23_1_conv False\n",
            "298 conv4_block23_1_bn False\n",
            "299 conv4_block23_1_relu False\n",
            "300 conv4_block23_2_conv False\n",
            "301 conv4_block23_concat False\n",
            "302 conv4_block24_0_bn False\n",
            "303 conv4_block24_0_relu False\n",
            "304 conv4_block24_1_conv False\n",
            "305 conv4_block24_1_bn False\n",
            "306 conv4_block24_1_relu False\n",
            "307 conv4_block24_2_conv False\n",
            "308 conv4_block24_concat False\n",
            "309 pool4_bn False\n",
            "310 pool4_relu False\n",
            "311 pool4_conv False\n",
            "312 pool4_pool False\n",
            "313 conv5_block1_0_bn False\n",
            "314 conv5_block1_0_relu False\n",
            "315 conv5_block1_1_conv False\n",
            "316 conv5_block1_1_bn False\n",
            "317 conv5_block1_1_relu False\n",
            "318 conv5_block1_2_conv False\n",
            "319 conv5_block1_concat False\n",
            "320 conv5_block2_0_bn False\n",
            "321 conv5_block2_0_relu False\n",
            "322 conv5_block2_1_conv False\n",
            "323 conv5_block2_1_bn False\n",
            "324 conv5_block2_1_relu False\n",
            "325 conv5_block2_2_conv False\n",
            "326 conv5_block2_concat False\n",
            "327 conv5_block3_0_bn False\n",
            "328 conv5_block3_0_relu False\n",
            "329 conv5_block3_1_conv False\n",
            "330 conv5_block3_1_bn False\n",
            "331 conv5_block3_1_relu False\n",
            "332 conv5_block3_2_conv False\n",
            "333 conv5_block3_concat False\n",
            "334 conv5_block4_0_bn False\n",
            "335 conv5_block4_0_relu False\n",
            "336 conv5_block4_1_conv False\n",
            "337 conv5_block4_1_bn False\n",
            "338 conv5_block4_1_relu False\n",
            "339 conv5_block4_2_conv False\n",
            "340 conv5_block4_concat False\n",
            "341 conv5_block5_0_bn False\n",
            "342 conv5_block5_0_relu False\n",
            "343 conv5_block5_1_conv False\n",
            "344 conv5_block5_1_bn False\n",
            "345 conv5_block5_1_relu False\n",
            "346 conv5_block5_2_conv False\n",
            "347 conv5_block5_concat False\n",
            "348 conv5_block6_0_bn False\n",
            "349 conv5_block6_0_relu False\n",
            "350 conv5_block6_1_conv False\n",
            "351 conv5_block6_1_bn False\n",
            "352 conv5_block6_1_relu False\n",
            "353 conv5_block6_2_conv False\n",
            "354 conv5_block6_concat False\n",
            "355 conv5_block7_0_bn False\n",
            "356 conv5_block7_0_relu False\n",
            "357 conv5_block7_1_conv False\n",
            "358 conv5_block7_1_bn False\n",
            "359 conv5_block7_1_relu False\n",
            "360 conv5_block7_2_conv False\n",
            "361 conv5_block7_concat False\n",
            "362 conv5_block8_0_bn False\n",
            "363 conv5_block8_0_relu False\n",
            "364 conv5_block8_1_conv False\n",
            "365 conv5_block8_1_bn False\n",
            "366 conv5_block8_1_relu False\n",
            "367 conv5_block8_2_conv False\n",
            "368 conv5_block8_concat False\n",
            "369 conv5_block9_0_bn False\n",
            "370 conv5_block9_0_relu False\n",
            "371 conv5_block9_1_conv False\n",
            "372 conv5_block9_1_bn False\n",
            "373 conv5_block9_1_relu False\n",
            "374 conv5_block9_2_conv False\n",
            "375 conv5_block9_concat False\n",
            "376 conv5_block10_0_bn False\n",
            "377 conv5_block10_0_relu False\n",
            "378 conv5_block10_1_conv False\n",
            "379 conv5_block10_1_bn False\n",
            "380 conv5_block10_1_relu False\n",
            "381 conv5_block10_2_conv False\n",
            "382 conv5_block10_concat False\n",
            "383 conv5_block11_0_bn False\n",
            "384 conv5_block11_0_relu False\n",
            "385 conv5_block11_1_conv False\n",
            "386 conv5_block11_1_bn False\n",
            "387 conv5_block11_1_relu False\n",
            "388 conv5_block11_2_conv False\n",
            "389 conv5_block11_concat False\n",
            "390 conv5_block12_0_bn False\n",
            "391 conv5_block12_0_relu False\n",
            "392 conv5_block12_1_conv False\n",
            "393 conv5_block12_1_bn False\n",
            "394 conv5_block12_1_relu False\n",
            "395 conv5_block12_2_conv False\n",
            "396 conv5_block12_concat False\n",
            "397 conv5_block13_0_bn False\n",
            "398 conv5_block13_0_relu False\n",
            "399 conv5_block13_1_conv False\n",
            "400 conv5_block13_1_bn False\n",
            "401 conv5_block13_1_relu False\n",
            "402 conv5_block13_2_conv False\n",
            "403 conv5_block13_concat False\n",
            "404 conv5_block14_0_bn False\n",
            "405 conv5_block14_0_relu False\n",
            "406 conv5_block14_1_conv False\n",
            "407 conv5_block14_1_bn False\n",
            "408 conv5_block14_1_relu False\n",
            "409 conv5_block14_2_conv False\n",
            "410 conv5_block14_concat False\n",
            "411 conv5_block15_0_bn True\n",
            "412 conv5_block15_0_relu True\n",
            "413 conv5_block15_1_conv True\n",
            "414 conv5_block15_1_bn True\n",
            "415 conv5_block15_1_relu True\n",
            "416 conv5_block15_2_conv True\n",
            "417 conv5_block15_concat True\n",
            "418 conv5_block16_0_bn True\n",
            "419 conv5_block16_0_relu True\n",
            "420 conv5_block16_1_conv True\n",
            "421 conv5_block16_1_bn True\n",
            "422 conv5_block16_1_relu True\n",
            "423 conv5_block16_2_conv True\n",
            "424 conv5_block16_concat True\n",
            "425 bn True\n",
            "426 relu True\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(conv_base.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KcDo2VlW-6Jt"
      },
      "outputs": [],
      "source": [
        "#conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6prLuQV--6Jt",
        "outputId": "21272876-2976-4870-ca8a-f63126fc18c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 20\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(modelPreTMob.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 2,690,369\n",
            "Non-trainable params: 6,707,968\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelPreTMob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "adagrad = optimizers.Adagrad(learning_rate=TrainingConfig.LEARNING_RATE, initial_accumulator_value=0.1, epsilon=TrainingConfig.EPSILON, decay =TrainingConfig.WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "P4qDSomz-6Jt"
      },
      "outputs": [],
      "source": [
        "modelPreTMob.compile(optimizer= adagrad, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])# Adagrad, adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add checkpoint to store the model on the best epoch for Val acc.\n",
        "checkpoint_filepath = r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-{epoch:02d}-{val_accuracy:.4f}.keras'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "print(TrainingConfig.EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.3857 - accuracy: 0.7960\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86092, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-01-0.8609.keras\n",
            "329/329 [==============================] - 248s 727ms/step - loss: 5.3857 - accuracy: 0.7960 - val_loss: 5.1601 - val_accuracy: 0.8609\n",
            "Epoch 2/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 5.1302 - accuracy: 0.8389\n",
            "Epoch 2: val_accuracy improved from 0.86092 to 0.87500, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-02-0.8750.keras\n",
            "329/329 [==============================] - 210s 637ms/step - loss: 5.1302 - accuracy: 0.8389 - val_loss: 4.9864 - val_accuracy: 0.8750\n",
            "Epoch 3/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.9814 - accuracy: 0.8449\n",
            "Epoch 3: val_accuracy improved from 0.87500 to 0.87829, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-03-0.8783.keras\n",
            "329/329 [==============================] - 207s 630ms/step - loss: 4.9814 - accuracy: 0.8449 - val_loss: 4.8446 - val_accuracy: 0.8783\n",
            "Epoch 4/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.8543 - accuracy: 0.8478\n",
            "Epoch 4: val_accuracy improved from 0.87829 to 0.87961, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-04-0.8796.keras\n",
            "329/329 [==============================] - 211s 642ms/step - loss: 4.8543 - accuracy: 0.8478 - val_loss: 4.7302 - val_accuracy: 0.8796\n",
            "Epoch 5/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.7403 - accuracy: 0.8512\n",
            "Epoch 5: val_accuracy improved from 0.87961 to 0.88158, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-05-0.8816.keras\n",
            "329/329 [==============================] - 210s 638ms/step - loss: 4.7403 - accuracy: 0.8512 - val_loss: 4.6296 - val_accuracy: 0.8816\n",
            "Epoch 6/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.6431 - accuracy: 0.8558\n",
            "Epoch 6: val_accuracy improved from 0.88158 to 0.88263, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-06-0.8826.keras\n",
            "329/329 [==============================] - 210s 638ms/step - loss: 4.6431 - accuracy: 0.8558 - val_loss: 4.5389 - val_accuracy: 0.8826\n",
            "Epoch 7/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.5606 - accuracy: 0.8569\n",
            "Epoch 7: val_accuracy improved from 0.88263 to 0.88329, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-07-0.8833.keras\n",
            "329/329 [==============================] - 208s 632ms/step - loss: 4.5606 - accuracy: 0.8569 - val_loss: 4.4662 - val_accuracy: 0.8833\n",
            "Epoch 8/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4857 - accuracy: 0.8573\n",
            "Epoch 8: val_accuracy improved from 0.88329 to 0.88579, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-08-0.8858.keras\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 4.4857 - accuracy: 0.8573 - val_loss: 4.3936 - val_accuracy: 0.8858\n",
            "Epoch 9/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.4159 - accuracy: 0.8598\n",
            "Epoch 9: val_accuracy improved from 0.88579 to 0.88645, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-09-0.8864.keras\n",
            "329/329 [==============================] - 238s 724ms/step - loss: 4.4159 - accuracy: 0.8598 - val_loss: 4.3269 - val_accuracy: 0.8864\n",
            "Epoch 10/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.3524 - accuracy: 0.8621\n",
            "Epoch 10: val_accuracy did not improve from 0.88645\n",
            "329/329 [==============================] - 220s 668ms/step - loss: 4.3524 - accuracy: 0.8621 - val_loss: 4.2701 - val_accuracy: 0.8857\n",
            "Epoch 11/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2979 - accuracy: 0.8612\n",
            "Epoch 11: val_accuracy improved from 0.88645 to 0.88868, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-11-0.8887.keras\n",
            "329/329 [==============================] - 232s 706ms/step - loss: 4.2979 - accuracy: 0.8612 - val_loss: 4.2157 - val_accuracy: 0.8887\n",
            "Epoch 12/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.2479 - accuracy: 0.8606\n",
            "Epoch 12: val_accuracy did not improve from 0.88868\n",
            "329/329 [==============================] - 220s 667ms/step - loss: 4.2479 - accuracy: 0.8606 - val_loss: 4.1672 - val_accuracy: 0.8872\n",
            "Epoch 13/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1949 - accuracy: 0.8600\n",
            "Epoch 13: val_accuracy did not improve from 0.88868\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 4.1949 - accuracy: 0.8600 - val_loss: 4.1220 - val_accuracy: 0.8882\n",
            "Epoch 14/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1558 - accuracy: 0.8632\n",
            "Epoch 14: val_accuracy improved from 0.88868 to 0.88882, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-14-0.8888.keras\n",
            "329/329 [==============================] - 208s 633ms/step - loss: 4.1558 - accuracy: 0.8632 - val_loss: 4.0782 - val_accuracy: 0.8888\n",
            "Epoch 15/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.1132 - accuracy: 0.8639\n",
            "Epoch 15: val_accuracy did not improve from 0.88882\n",
            "329/329 [==============================] - 209s 634ms/step - loss: 4.1132 - accuracy: 0.8639 - val_loss: 4.0386 - val_accuracy: 0.8880\n",
            "Epoch 16/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0725 - accuracy: 0.8633\n",
            "Epoch 16: val_accuracy improved from 0.88882 to 0.89000, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-16-0.8900.keras\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 4.0725 - accuracy: 0.8633 - val_loss: 4.0021 - val_accuracy: 0.8900\n",
            "Epoch 17/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 4.0361 - accuracy: 0.8633\n",
            "Epoch 17: val_accuracy did not improve from 0.89000\n",
            "329/329 [==============================] - 209s 635ms/step - loss: 4.0361 - accuracy: 0.8633 - val_loss: 3.9664 - val_accuracy: 0.8899\n",
            "Epoch 18/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9937 - accuracy: 0.8692\n",
            "Epoch 18: val_accuracy did not improve from 0.89000\n",
            "329/329 [==============================] - 210s 637ms/step - loss: 3.9937 - accuracy: 0.8692 - val_loss: 3.9337 - val_accuracy: 0.8900\n",
            "Epoch 19/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9691 - accuracy: 0.8668\n",
            "Epoch 19: val_accuracy improved from 0.89000 to 0.89171, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-19-0.8917.keras\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 3.9691 - accuracy: 0.8668 - val_loss: 3.9014 - val_accuracy: 0.8917\n",
            "Epoch 20/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9359 - accuracy: 0.8683\n",
            "Epoch 20: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.9359 - accuracy: 0.8683 - val_loss: 3.8719 - val_accuracy: 0.8892\n",
            "Epoch 21/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.9040 - accuracy: 0.8687\n",
            "Epoch 21: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.9040 - accuracy: 0.8687 - val_loss: 3.8435 - val_accuracy: 0.8900\n",
            "Epoch 22/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8750 - accuracy: 0.8692\n",
            "Epoch 22: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.8750 - accuracy: 0.8692 - val_loss: 3.8160 - val_accuracy: 0.8901\n",
            "Epoch 23/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8515 - accuracy: 0.8687\n",
            "Epoch 23: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.8515 - accuracy: 0.8687 - val_loss: 3.7909 - val_accuracy: 0.8904\n",
            "Epoch 24/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8291 - accuracy: 0.8690\n",
            "Epoch 24: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.8291 - accuracy: 0.8690 - val_loss: 3.7667 - val_accuracy: 0.8905\n",
            "Epoch 25/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.8078 - accuracy: 0.8692\n",
            "Epoch 25: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.8078 - accuracy: 0.8692 - val_loss: 3.7436 - val_accuracy: 0.8901\n",
            "Epoch 26/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7784 - accuracy: 0.8674\n",
            "Epoch 26: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.7784 - accuracy: 0.8674 - val_loss: 3.7207 - val_accuracy: 0.8897\n",
            "Epoch 27/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7619 - accuracy: 0.8692\n",
            "Epoch 27: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.7619 - accuracy: 0.8692 - val_loss: 3.6992 - val_accuracy: 0.8896\n",
            "Epoch 28/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7399 - accuracy: 0.8670\n",
            "Epoch 28: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.7399 - accuracy: 0.8670 - val_loss: 3.6789 - val_accuracy: 0.8896\n",
            "Epoch 29/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.7179 - accuracy: 0.8686\n",
            "Epoch 29: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.7179 - accuracy: 0.8686 - val_loss: 3.6584 - val_accuracy: 0.8897\n",
            "Epoch 30/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6962 - accuracy: 0.8708\n",
            "Epoch 30: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.6962 - accuracy: 0.8708 - val_loss: 3.6394 - val_accuracy: 0.8901\n",
            "Epoch 31/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6780 - accuracy: 0.8713\n",
            "Epoch 31: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.6780 - accuracy: 0.8713 - val_loss: 3.6205 - val_accuracy: 0.8907\n",
            "Epoch 32/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6589 - accuracy: 0.8686\n",
            "Epoch 32: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.6589 - accuracy: 0.8686 - val_loss: 3.6039 - val_accuracy: 0.8907\n",
            "Epoch 33/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6375 - accuracy: 0.8728\n",
            "Epoch 33: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.6375 - accuracy: 0.8728 - val_loss: 3.5860 - val_accuracy: 0.8917\n",
            "Epoch 34/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6238 - accuracy: 0.8693\n",
            "Epoch 34: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.6238 - accuracy: 0.8693 - val_loss: 3.5698 - val_accuracy: 0.8913\n",
            "Epoch 35/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.6096 - accuracy: 0.8675\n",
            "Epoch 35: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 621ms/step - loss: 3.6096 - accuracy: 0.8675 - val_loss: 3.5531 - val_accuracy: 0.8911\n",
            "Epoch 36/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5899 - accuracy: 0.8740\n",
            "Epoch 36: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.5899 - accuracy: 0.8740 - val_loss: 3.5372 - val_accuracy: 0.8914\n",
            "Epoch 37/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5755 - accuracy: 0.8712\n",
            "Epoch 37: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.5755 - accuracy: 0.8712 - val_loss: 3.5225 - val_accuracy: 0.8917\n",
            "Epoch 38/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5569 - accuracy: 0.8715\n",
            "Epoch 38: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.5569 - accuracy: 0.8715 - val_loss: 3.5079 - val_accuracy: 0.8909\n",
            "Epoch 39/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5454 - accuracy: 0.8703\n",
            "Epoch 39: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.5454 - accuracy: 0.8703 - val_loss: 3.4937 - val_accuracy: 0.8913\n",
            "Epoch 40/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5313 - accuracy: 0.8696\n",
            "Epoch 40: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.5313 - accuracy: 0.8696 - val_loss: 3.4798 - val_accuracy: 0.8917\n",
            "Epoch 41/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5156 - accuracy: 0.8732\n",
            "Epoch 41: val_accuracy did not improve from 0.89171\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.5156 - accuracy: 0.8732 - val_loss: 3.4663 - val_accuracy: 0.8912\n",
            "Epoch 42/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.5039 - accuracy: 0.8726\n",
            "Epoch 42: val_accuracy improved from 0.89171 to 0.89224, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-42-0.8922.keras\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.5039 - accuracy: 0.8726 - val_loss: 3.4530 - val_accuracy: 0.8922\n",
            "Epoch 43/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4898 - accuracy: 0.8738\n",
            "Epoch 43: val_accuracy did not improve from 0.89224\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.4898 - accuracy: 0.8738 - val_loss: 3.4412 - val_accuracy: 0.8918\n",
            "Epoch 44/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4747 - accuracy: 0.8752\n",
            "Epoch 44: val_accuracy did not improve from 0.89224\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.4747 - accuracy: 0.8752 - val_loss: 3.4291 - val_accuracy: 0.8920\n",
            "Epoch 45/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4678 - accuracy: 0.8699\n",
            "Epoch 45: val_accuracy did not improve from 0.89224\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.4678 - accuracy: 0.8699 - val_loss: 3.4171 - val_accuracy: 0.8918\n",
            "Epoch 46/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4515 - accuracy: 0.8725\n",
            "Epoch 46: val_accuracy did not improve from 0.89224\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4515 - accuracy: 0.8725 - val_loss: 3.4060 - val_accuracy: 0.8920\n",
            "Epoch 47/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4464 - accuracy: 0.8717\n",
            "Epoch 47: val_accuracy improved from 0.89224 to 0.89237, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-47-0.8924.keras\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.4464 - accuracy: 0.8717 - val_loss: 3.3947 - val_accuracy: 0.8924\n",
            "Epoch 48/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4297 - accuracy: 0.8740\n",
            "Epoch 48: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.4297 - accuracy: 0.8740 - val_loss: 3.3832 - val_accuracy: 0.8917\n",
            "Epoch 49/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4264 - accuracy: 0.8716\n",
            "Epoch 49: val_accuracy did not improve from 0.89237\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.4264 - accuracy: 0.8716 - val_loss: 3.3730 - val_accuracy: 0.8922\n",
            "Epoch 50/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.4114 - accuracy: 0.8736\n",
            "Epoch 50: val_accuracy improved from 0.89237 to 0.89263, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-50-0.8926.keras\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.4114 - accuracy: 0.8736 - val_loss: 3.3623 - val_accuracy: 0.8926\n",
            "Epoch 51/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3997 - accuracy: 0.8737\n",
            "Epoch 51: val_accuracy did not improve from 0.89263\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.3997 - accuracy: 0.8737 - val_loss: 3.3517 - val_accuracy: 0.8922\n",
            "Epoch 52/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3953 - accuracy: 0.8698\n",
            "Epoch 52: val_accuracy did not improve from 0.89263\n",
            "329/329 [==============================] - 205s 622ms/step - loss: 3.3953 - accuracy: 0.8698 - val_loss: 3.3413 - val_accuracy: 0.8921\n",
            "Epoch 53/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3756 - accuracy: 0.8765\n",
            "Epoch 53: val_accuracy improved from 0.89263 to 0.89276, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-53-0.8928.keras\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.3756 - accuracy: 0.8765 - val_loss: 3.3315 - val_accuracy: 0.8928\n",
            "Epoch 54/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3734 - accuracy: 0.8736\n",
            "Epoch 54: val_accuracy did not improve from 0.89276\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.3734 - accuracy: 0.8736 - val_loss: 3.3222 - val_accuracy: 0.8924\n",
            "Epoch 55/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3573 - accuracy: 0.8760\n",
            "Epoch 55: val_accuracy improved from 0.89276 to 0.89303, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-55-0.8930.keras\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.3573 - accuracy: 0.8760 - val_loss: 3.3130 - val_accuracy: 0.8930\n",
            "Epoch 56/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3464 - accuracy: 0.8744\n",
            "Epoch 56: val_accuracy did not improve from 0.89303\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.3464 - accuracy: 0.8744 - val_loss: 3.3045 - val_accuracy: 0.8929\n",
            "Epoch 57/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3414 - accuracy: 0.8720\n",
            "Epoch 57: val_accuracy did not improve from 0.89303\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.3414 - accuracy: 0.8720 - val_loss: 3.2954 - val_accuracy: 0.8930\n",
            "Epoch 58/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3267 - accuracy: 0.8781\n",
            "Epoch 58: val_accuracy did not improve from 0.89303\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.3267 - accuracy: 0.8781 - val_loss: 3.2862 - val_accuracy: 0.8928\n",
            "Epoch 59/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3262 - accuracy: 0.8739\n",
            "Epoch 59: val_accuracy did not improve from 0.89303\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.3262 - accuracy: 0.8739 - val_loss: 3.2777 - val_accuracy: 0.8925\n",
            "Epoch 60/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3117 - accuracy: 0.8780\n",
            "Epoch 60: val_accuracy did not improve from 0.89303\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.3117 - accuracy: 0.8780 - val_loss: 3.2698 - val_accuracy: 0.8928\n",
            "Epoch 61/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3088 - accuracy: 0.8730\n",
            "Epoch 61: val_accuracy improved from 0.89303 to 0.89329, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-61-0.8933.keras\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.3088 - accuracy: 0.8730 - val_loss: 3.2613 - val_accuracy: 0.8933\n",
            "Epoch 62/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.3031 - accuracy: 0.8770\n",
            "Epoch 62: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.3031 - accuracy: 0.8770 - val_loss: 3.2539 - val_accuracy: 0.8930\n",
            "Epoch 63/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2910 - accuracy: 0.8739\n",
            "Epoch 63: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.2910 - accuracy: 0.8739 - val_loss: 3.2451 - val_accuracy: 0.8930\n",
            "Epoch 64/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2785 - accuracy: 0.8751\n",
            "Epoch 64: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.2785 - accuracy: 0.8751 - val_loss: 3.2376 - val_accuracy: 0.8930\n",
            "Epoch 65/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2685 - accuracy: 0.8771\n",
            "Epoch 65: val_accuracy did not improve from 0.89329\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.2685 - accuracy: 0.8771 - val_loss: 3.2305 - val_accuracy: 0.8933\n",
            "Epoch 66/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2621 - accuracy: 0.8775\n",
            "Epoch 66: val_accuracy improved from 0.89329 to 0.89355, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-66-0.8936.keras\n",
            "329/329 [==============================] - 207s 629ms/step - loss: 3.2621 - accuracy: 0.8775 - val_loss: 3.2224 - val_accuracy: 0.8936\n",
            "Epoch 67/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2580 - accuracy: 0.8750\n",
            "Epoch 67: val_accuracy improved from 0.89355 to 0.89395, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-67-0.8939.keras\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.2580 - accuracy: 0.8750 - val_loss: 3.2147 - val_accuracy: 0.8939\n",
            "Epoch 68/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2593 - accuracy: 0.8714\n",
            "Epoch 68: val_accuracy did not improve from 0.89395\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2593 - accuracy: 0.8714 - val_loss: 3.2073 - val_accuracy: 0.8934\n",
            "Epoch 69/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2474 - accuracy: 0.8714\n",
            "Epoch 69: val_accuracy did not improve from 0.89395\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2474 - accuracy: 0.8714 - val_loss: 3.2006 - val_accuracy: 0.8939\n",
            "Epoch 70/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2390 - accuracy: 0.8722\n",
            "Epoch 70: val_accuracy did not improve from 0.89395\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.2390 - accuracy: 0.8722 - val_loss: 3.1941 - val_accuracy: 0.8934\n",
            "Epoch 71/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2317 - accuracy: 0.8757\n",
            "Epoch 71: val_accuracy did not improve from 0.89395\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2317 - accuracy: 0.8757 - val_loss: 3.1864 - val_accuracy: 0.8932\n",
            "Epoch 72/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2238 - accuracy: 0.8755\n",
            "Epoch 72: val_accuracy did not improve from 0.89395\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2238 - accuracy: 0.8755 - val_loss: 3.1795 - val_accuracy: 0.8934\n",
            "Epoch 73/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2186 - accuracy: 0.8751\n",
            "Epoch 73: val_accuracy did not improve from 0.89395\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.2186 - accuracy: 0.8751 - val_loss: 3.1732 - val_accuracy: 0.8934\n",
            "Epoch 74/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2174 - accuracy: 0.8733\n",
            "Epoch 74: val_accuracy improved from 0.89395 to 0.89421, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-74-0.8942.keras\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.2174 - accuracy: 0.8733 - val_loss: 3.1671 - val_accuracy: 0.8942\n",
            "Epoch 75/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.2015 - accuracy: 0.8765\n",
            "Epoch 75: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 205s 623ms/step - loss: 3.2015 - accuracy: 0.8765 - val_loss: 3.1613 - val_accuracy: 0.8936\n",
            "Epoch 76/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1947 - accuracy: 0.8770\n",
            "Epoch 76: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1947 - accuracy: 0.8770 - val_loss: 3.1541 - val_accuracy: 0.8936\n",
            "Epoch 77/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1917 - accuracy: 0.8757\n",
            "Epoch 77: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.1917 - accuracy: 0.8757 - val_loss: 3.1482 - val_accuracy: 0.8938\n",
            "Epoch 78/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1859 - accuracy: 0.8734\n",
            "Epoch 78: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 206s 626ms/step - loss: 3.1859 - accuracy: 0.8734 - val_loss: 3.1422 - val_accuracy: 0.8939\n",
            "Epoch 79/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1744 - accuracy: 0.8775\n",
            "Epoch 79: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.1744 - accuracy: 0.8775 - val_loss: 3.1362 - val_accuracy: 0.8933\n",
            "Epoch 80/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1760 - accuracy: 0.8741\n",
            "Epoch 80: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1760 - accuracy: 0.8741 - val_loss: 3.1300 - val_accuracy: 0.8941\n",
            "Epoch 81/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1625 - accuracy: 0.8760\n",
            "Epoch 81: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.1625 - accuracy: 0.8760 - val_loss: 3.1243 - val_accuracy: 0.8939\n",
            "Epoch 82/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1608 - accuracy: 0.8762\n",
            "Epoch 82: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1608 - accuracy: 0.8762 - val_loss: 3.1186 - val_accuracy: 0.8936\n",
            "Epoch 83/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1523 - accuracy: 0.8761\n",
            "Epoch 83: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1523 - accuracy: 0.8761 - val_loss: 3.1127 - val_accuracy: 0.8939\n",
            "Epoch 84/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1499 - accuracy: 0.8764\n",
            "Epoch 84: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 205s 625ms/step - loss: 3.1499 - accuracy: 0.8764 - val_loss: 3.1068 - val_accuracy: 0.8933\n",
            "Epoch 85/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1459 - accuracy: 0.8737\n",
            "Epoch 85: val_accuracy did not improve from 0.89421\n",
            "329/329 [==============================] - 205s 624ms/step - loss: 3.1459 - accuracy: 0.8737 - val_loss: 3.1015 - val_accuracy: 0.8938\n",
            "Epoch 86/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1354 - accuracy: 0.8794\n",
            "Epoch 86: val_accuracy improved from 0.89421 to 0.89434, saving model to C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints\\modelDenseNetFT15-86-0.8943.keras\n",
            "329/329 [==============================] - 207s 629ms/step - loss: 3.1354 - accuracy: 0.8794 - val_loss: 3.0963 - val_accuracy: 0.8943\n",
            "Epoch 87/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1311 - accuracy: 0.8768\n",
            "Epoch 87: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 206s 627ms/step - loss: 3.1311 - accuracy: 0.8768 - val_loss: 3.0911 - val_accuracy: 0.8939\n",
            "Epoch 88/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1257 - accuracy: 0.8769\n",
            "Epoch 88: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1257 - accuracy: 0.8769 - val_loss: 3.0862 - val_accuracy: 0.8938\n",
            "Epoch 89/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1239 - accuracy: 0.8752\n",
            "Epoch 89: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 206s 624ms/step - loss: 3.1239 - accuracy: 0.8752 - val_loss: 3.0811 - val_accuracy: 0.8938\n",
            "Epoch 90/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1213 - accuracy: 0.8747\n",
            "Epoch 90: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 206s 625ms/step - loss: 3.1213 - accuracy: 0.8747 - val_loss: 3.0759 - val_accuracy: 0.8939\n",
            "Epoch 91/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1112 - accuracy: 0.8767\n",
            "Epoch 91: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 210s 637ms/step - loss: 3.1112 - accuracy: 0.8767 - val_loss: 3.0705 - val_accuracy: 0.8942\n",
            "Epoch 92/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1068 - accuracy: 0.8769\n",
            "Epoch 92: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 209s 636ms/step - loss: 3.1068 - accuracy: 0.8769 - val_loss: 3.0653 - val_accuracy: 0.8937\n",
            "Epoch 93/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1050 - accuracy: 0.8730\n",
            "Epoch 93: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 209s 634ms/step - loss: 3.1050 - accuracy: 0.8730 - val_loss: 3.0606 - val_accuracy: 0.8941\n",
            "Epoch 94/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.1036 - accuracy: 0.8750\n",
            "Epoch 94: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 208s 633ms/step - loss: 3.1036 - accuracy: 0.8750 - val_loss: 3.0557 - val_accuracy: 0.8939\n",
            "Epoch 95/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0913 - accuracy: 0.8757\n",
            "Epoch 95: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 208s 631ms/step - loss: 3.0913 - accuracy: 0.8757 - val_loss: 3.0517 - val_accuracy: 0.8943\n",
            "Epoch 96/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0893 - accuracy: 0.8743\n",
            "Epoch 96: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 208s 633ms/step - loss: 3.0893 - accuracy: 0.8743 - val_loss: 3.0467 - val_accuracy: 0.8938\n",
            "Epoch 97/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0854 - accuracy: 0.8754\n",
            "Epoch 97: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 209s 634ms/step - loss: 3.0854 - accuracy: 0.8754 - val_loss: 3.0418 - val_accuracy: 0.8938\n",
            "Epoch 98/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0770 - accuracy: 0.8767\n",
            "Epoch 98: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 209s 635ms/step - loss: 3.0770 - accuracy: 0.8767 - val_loss: 3.0372 - val_accuracy: 0.8937\n",
            "Epoch 99/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0697 - accuracy: 0.8764\n",
            "Epoch 99: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 209s 634ms/step - loss: 3.0697 - accuracy: 0.8764 - val_loss: 3.0330 - val_accuracy: 0.8941\n",
            "Epoch 100/100\n",
            "329/329 [==============================] - ETA: 0s - loss: 3.0635 - accuracy: 0.8790\n",
            "Epoch 100: val_accuracy did not improve from 0.89434\n",
            "329/329 [==============================] - 207s 628ms/step - loss: 3.0635 - accuracy: 0.8790 - val_loss: 3.0277 - val_accuracy: 0.8942\n"
          ]
        }
      ],
      "source": [
        "histPreT = modelPreTMob.fit(train_generator, epochs = TrainingConfig.EPOCHS, validation_data=validation_generator, callbacks=[model_checkpoint_callback]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 20769.96422481537 seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(Current_dir, 'History')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(r'c:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\History\\\\HistoryDict_DenseNEt_FT0', 'wb') as file_pi:\n",
        "    pickle.dump(histPreT.history, file_pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 86\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "START_PLOT_FROM_EPOCH= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "e3wZrd90-6Jt",
        "outputId": "0630124c-9747-4688-f755-aaf80997102f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc = histPreT.history['accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "val_acc = histPreT.history['val_accuracy'][START_PLOT_FROM_EPOCH:]\n",
        "loss = histPreT.history['loss'][START_PLOT_FROM_EPOCH:]\n",
        "val_loss = histPreT.history['val_loss'][START_PLOT_FROM_EPOCH:]\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, color='teal', label='Training acc')\n",
        "plt.plot(epochs, val_acc, color='orange', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, color='teal', label='Training loss')\n",
        "plt.plot(epochs, val_loss, color='orange', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best epoch: 86\n"
          ]
        }
      ],
      "source": [
        "val_acc_per_epoch = histPreT.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading best epoch in our model using the checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dir= r'C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints' # C:\\Users\\YannisPC\\PycharmProjects\\Thesis\\Thesis\\checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model file: model-86-0.8943.keras\n"
          ]
        }
      ],
      "source": [
        "best_val_accuracy = max(val_acc_per_epoch)\n",
        "best_model_file = f'model-{best_epoch:02d}-{best_val_accuracy:.4f}.keras'\n",
        "\n",
        "print(f'Best model file: {best_model_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\YannisPC\\\\PycharmProjects\\\\Thesis\\\\Thesis\\\\checkpoints'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(model_dir)\n",
        "Current_dir = os.getcwd()\n",
        "Current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['checkpoints.lnk',\n",
              " 'ConvNextTiny_FT20-01-0.8195.keras',\n",
              " 'ConvNextTiny_FT20-04-0.8350.keras',\n",
              " 'ConvNextTiny_FT20-06-0.8462.keras',\n",
              " 'ConvNextTiny_FT20-07-0.8566.keras',\n",
              " 'ConvNextTiny_FT20-09-0.8584.keras',\n",
              " 'ConvNextTiny_FT20-27-0.8608.keras',\n",
              " 'ConvNextTiny_FT20-70-0.8611.keras',\n",
              " 'model-01-0.8824.keras',\n",
              " 'model-02-0.8867.keras',\n",
              " 'model-03-0.8893.keras',\n",
              " 'model-05-0.8895.keras',\n",
              " 'model-06-0.8934.keras',\n",
              " 'model-09-0.8961.keras',\n",
              " 'model-11-0.8966.keras',\n",
              " 'modelAlexNetFT10-01-0.8759.keras',\n",
              " 'modelAlexNetFT10-02-0.8841.keras',\n",
              " 'modelAlexNetFT10-06-0.8904.keras',\n",
              " 'modelAlexNetFT10-08-0.8968.keras',\n",
              " 'modelAlexNetFT10-13-0.8987.keras',\n",
              " 'modelAlexNetFT10-14-0.9022.keras',\n",
              " 'modelAlexNetFT10-24-0.9043.keras',\n",
              " 'modelDenseNet-01-0.8676.keras',\n",
              " 'modelDenseNet-02-0.8737.keras',\n",
              " 'modelDenseNet-03-0.8803.keras',\n",
              " 'modelDenseNet-04-0.8824.keras',\n",
              " 'modelDenseNet-05-0.8826.keras',\n",
              " 'modelDenseNet-08-0.8837.keras',\n",
              " 'modelDenseNet-12-0.8843.keras',\n",
              " 'modelDenseNet-14-0.8854.keras',\n",
              " 'modelDenseNet-15-0.8857.keras',\n",
              " 'modelDenseNet-16-0.8862.keras',\n",
              " 'modelDenseNet-22-0.8863.keras',\n",
              " 'modelDenseNet-23-0.8875.keras',\n",
              " 'modelDenseNet-39-0.8878.keras',\n",
              " 'modelDenseNet-40-0.8884.keras',\n",
              " 'modelDenseNet-43-0.8886.keras',\n",
              " 'modelDenseNet-49-0.8888.keras',\n",
              " 'modelDenseNet-59-0.8893.keras',\n",
              " 'modelDenseNet-75-0.8897.keras',\n",
              " 'modelDenseNet-81-0.8901.keras',\n",
              " 'modelDenseNet-87-0.8903.keras',\n",
              " 'modelDenseNetFT15-01-0.8609.keras',\n",
              " 'modelDenseNetFT15-02-0.8750.keras',\n",
              " 'modelDenseNetFT15-03-0.8783.keras',\n",
              " 'modelDenseNetFT15-04-0.8796.keras',\n",
              " 'modelDenseNetFT15-05-0.8816.keras',\n",
              " 'modelDenseNetFT15-06-0.8826.keras',\n",
              " 'modelDenseNetFT15-07-0.8833.keras',\n",
              " 'modelDenseNetFT15-08-0.8858.keras',\n",
              " 'modelDenseNetFT15-09-0.8864.keras',\n",
              " 'modelDenseNetFT15-11-0.8887.keras',\n",
              " 'modelDenseNetFT15-14-0.8888.keras',\n",
              " 'modelDenseNetFT15-16-0.8900.keras',\n",
              " 'modelDenseNetFT15-19-0.8917.keras',\n",
              " 'modelDenseNetFT15-42-0.8922.keras',\n",
              " 'modelDenseNetFT15-47-0.8924.keras',\n",
              " 'modelDenseNetFT15-50-0.8926.keras',\n",
              " 'modelDenseNetFT15-53-0.8928.keras',\n",
              " 'modelDenseNetFT15-55-0.8930.keras',\n",
              " 'modelDenseNetFT15-61-0.8933.keras',\n",
              " 'modelDenseNetFT15-66-0.8936.keras',\n",
              " 'modelDenseNetFT15-67-0.8939.keras',\n",
              " 'modelDenseNetFT15-74-0.8942.keras',\n",
              " 'modelDenseNetFT15-86-0.8943.keras',\n",
              " 'modelMobileNetV2FT20-01-0.7942.keras',\n",
              " 'modelMobileNetV2FT20-02-0.8239.keras',\n",
              " 'modelMobileNetV2FT20-03-0.8364.keras',\n",
              " 'modelMobileNetV2FT20-04-0.8528.keras',\n",
              " 'modelMobileNetV2FT20-05-0.8658.keras',\n",
              " 'modelMobileNetV2FT20-06-0.8661.keras',\n",
              " 'modelMobileNetV2FT20-07-0.8704.keras',\n",
              " 'modelMobileNetV2FT20-08-0.8721.keras',\n",
              " 'modelMobileNetV2FT20-09-0.8774.keras',\n",
              " 'modelMobileNetV2FT20-10-0.8797.keras',\n",
              " 'modelMobileNetV2FT20-11-0.8807.keras',\n",
              " 'modelMobileNetV2FT20-12-0.8820.keras',\n",
              " 'modelMobileNetV2FT20-13-0.8822.keras',\n",
              " 'modelMobileNetV2FT20-14-0.8833.keras',\n",
              " 'modelMobileNetV2FT20-15-0.8838.keras',\n",
              " 'modelMobileNetV2FT20-16-0.8851.keras',\n",
              " 'modelMobileNetV2FT20-18-0.8858.keras',\n",
              " 'modelMobileNetV2FT20-19-0.8859.keras',\n",
              " 'modelMobileNetV2FT20-21-0.8876.keras',\n",
              " 'modelMobileNetV2FT20-23-0.8879.keras',\n",
              " 'modelMobileNetV2FT20-24-0.8880.keras',\n",
              " 'modelMobileNetV2FT20-26-0.8882.keras',\n",
              " 'modelMobileNetV2FT20-27-0.8887.keras',\n",
              " 'modelMobileNetV2FT20-31-0.8888.keras',\n",
              " 'modelMobileNetV2FT20-32-0.8891.keras',\n",
              " 'modelMobileNetV2FT20-33-0.8892.keras',\n",
              " 'modelMobileNetV2FT20-36-0.8901.keras',\n",
              " 'modelMobileNetV2FT20-47-0.8905.keras',\n",
              " 'modelMobileNetV2FT20-54-0.8907.keras',\n",
              " 'modelMobileNetV2FT20-57-0.8908.keras',\n",
              " 'modelMobileNetV2FT20-58-0.8911.keras',\n",
              " 'modelMobileNetV2FT20-62-0.8914.keras',\n",
              " 'modelMobileNetV2FT20-64-0.8916.keras',\n",
              " 'modelMobileNetV2FT20-66-0.8918.keras',\n",
              " 'modelMobileNetV2FT20-68-0.8924.keras',\n",
              " 'modelResNet50_FT20-01-0.8026.keras',\n",
              " 'modelResNet50_FT20-03-0.8136.keras',\n",
              " 'modelResNet50_FT20-08-0.8170.keras',\n",
              " 'modelResNet50_FT20-20-0.8295.keras',\n",
              " 'modelResNet50_FT20-24-0.8329.keras',\n",
              " 'modelResNet50_FT20-44-0.8339.keras',\n",
              " 'model_AlexNet-86-0.8629.keras']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(model_dir) if isfile(join(model_dir, f))]\n",
        "onlyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 3, 3, 1024)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,398,337\n",
            "Trainable params: 2,360,321\n",
            "Non-trainable params: 7,038,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "#loaded_model = load_model(os.path.join('checkpoints',best_model_file))\n",
        "loaded_model = load_model('modelDenseNetFT15-86-0.8943.keras') \n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "r_Nq7Xip7rrJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "tgHLiCoC-6Jt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "60/60 [==============================] - 21s 269ms/step - loss: 3.0893 - accuracy: 0.8902\n",
            "test acc: 0.8901666402816772\n",
            "test loss: 3.089348077774048\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=TrainingConfig.EPOCHS,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = loaded_model.evaluate(test_generator, steps=len(test_generator))  # steps_per_epoch * epochs\n",
        "print('test acc:', test_acc)\n",
        "print('test loss:', test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 21.590293884277344 Training set > seconds ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- %s Training set > seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize lists to collect true labels and predictions\n",
        "true_labels = []\n",
        "predicted_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 451ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 86ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 86ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 86ms/step\n",
            "4/4 [==============================] - 0s 86ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 87ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n",
            "4/4 [==============================] - 0s 85ms/step\n"
          ]
        }
      ],
      "source": [
        "for _ in range(len(test_generator)):\n",
        "    X, y = next(test_generator)\n",
        "\n",
        "    yhat = modelPreTMob.predict(X)\n",
        "    \n",
        "    y_true_batch = y # Labels\n",
        "    \n",
        "    # Convert probabilities to class labels using a threshold of 0.5\n",
        "    y_pred_batch = (yhat > 0.5).astype(int)\n",
        "\n",
        "    # Append the true labels and predictions for this batch to the lists\n",
        "    true_labels.extend(y_true_batch)\n",
        "    predicted_labels.extend(y_pred_batch)\n",
        "\n",
        "    if len(true_labels) >= test_generator.n:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2626,  374],\n",
              "       [ 258, 2742]], dtype=int64)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the confusion matrix\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm/cm_sum.astype(float), display_labels=['Ads', 'non-Ads'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8966644865925442"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "f1_score(true_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.87997432605905"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.914"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.894667\n"
          ]
        }
      ],
      "source": [
        "# ROC AUC\n",
        "auc = roc_auc_score(true_labels, predicted_labels)\n",
        "print('ROC AUC: %f' % auc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
